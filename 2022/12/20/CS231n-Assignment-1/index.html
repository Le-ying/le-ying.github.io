<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>CS231n Assignment 1 | Kung's Blog</title><meta name="author" content="龚泽颖"><meta name="copyright" content="龚泽颖"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="CS231n Assignment 1 作业1分为五个部分：knn、SVM、Softmax classifier、2层神经网络、Higher Level Representations: Image Features. 建议作业完成顺序：  k近邻分类：knn.ipynb &amp; k_nearest_neighbor.py svm线性分类：svm.ipynb &amp; linea">
<meta property="og:type" content="article">
<meta property="og:title" content="CS231n Assignment 1">
<meta property="og:url" content="https://serika-onoe.github.io/2022/12/20/CS231n-Assignment-1/index.html">
<meta property="og:site_name" content="Kung&#39;s Blog">
<meta property="og:description" content="CS231n Assignment 1 作业1分为五个部分：knn、SVM、Softmax classifier、2层神经网络、Higher Level Representations: Image Features. 建议作业完成顺序：  k近邻分类：knn.ipynb &amp; k_nearest_neighbor.py svm线性分类：svm.ipynb &amp; linea">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/cs231n_assignment1.png">
<meta property="article:published_time" content="2022-12-20T14:49:13.000Z">
<meta property="article:modified_time" content="2022-12-22T06:03:13.538Z">
<meta property="article:author" content="龚泽颖">
<meta property="article:tag" content="介绍">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="cs231n">
<meta property="article:tag" content="作业">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/cs231n_assignment1.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://serika-onoe.github.io/2022/12/20/CS231n-Assignment-1/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"W5J7GO3HT8","apiKey":"53b7d5d068605c78d1a20d7f3671629a","indexName":"test_serika","hits":{"per_page":3},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容：${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'CS231n Assignment 1',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-12-22 14:03:13'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/CodeByZach/pace/themes/green/pace-theme-flash.css"><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Kung's Blog" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 总览</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/en"><span> English</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/cs231n_assignment1.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Kung's Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 总览</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/en"><span> English</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">CS231n Assignment 1</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-12-20T14:49:13.000Z" title="发表于 2022-12-20 22:49:13">2022-12-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-12-22T06:03:13.538Z" title="更新于 2022-12-22 14:03:13">2022-12-22</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%AC%94%E8%AE%B0/">笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="CS231n Assignment 1"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="cs231n-assignment-1">CS231n Assignment 1</h1>
<p>作业1分为五个部分：knn、SVM、Softmax classifier、2层神经网络、Higher
Level Representations: Image Features.</p>
<p>建议作业完成顺序：</p>
<ol type="1">
<li>k近邻分类：knn.ipynb &amp; k_nearest_neighbor.py</li>
<li>svm线性分类：svm.ipynb &amp; linear_svm.py &amp;
linear_classifier.py</li>
<li>softmax线性分类：softmax.ipynb &amp; softmax.py</li>
<li>两层神经网络：two_layer_net.ipynb &amp; neural_net.py</li>
</ol>
<h1 id="k-nearest-neighbor-knn-exercise">k-Nearest Neighbor (kNN)
exercise</h1>
<p>在knn.ipynb中，调用了k_nearest_neighbor.py文件。</p>
<p>k近邻分类算法步骤如下介绍：</p>
<ol type="1">
<li>记住所有训练图像</li>
<li>计算测试图像与所有训练图像的距离（常用L2距离）</li>
<li>选择与测试图像距离最小的k张训练图像</li>
<li>计算这k张图像所对应的类别出现的次数，选择出现次数最多的类别记为预测类别</li>
</ol>
<h2 id="k_nearest_neighbor.py">k_nearest_neighbor.py</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">KNearestNeighbor</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; a kNN classifier with L2 distance &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">#定义一个k近邻分类器的类</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<h3 id="训练">训练</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, X, y</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Train the classifier. For k-nearest neighbors this is just</span></span><br><span class="line"><span class="string">    memorizing the training data.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - X: A numpy array of shape (num_train, D) containing the training data</span></span><br><span class="line"><span class="string">      consisting of num_train samples each of dimension D.</span></span><br><span class="line"><span class="string">    - y: A numpy array of shape (N,) containing the training labels, where</span></span><br><span class="line"><span class="string">         y[i] is the label for X[i].</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">#self.X_train 是训练数据，维度是 (N,D)，训练集有N个样本，每个样本特征是D维</span></span><br><span class="line">    <span class="comment">#self.y_train 是标签，维度是（N,）,即N个训练样本对应的标签</span></span><br><span class="line">    self.X_train = X</span><br><span class="line">    self.y_train = y</span><br></pre></td></tr></table></figure>
<h3
id="预测计算测试图像和所有训练图像的l2距离">预测：计算测试图像和所有训练图像的L2距离</h3>
<p>预测时首先需要计算测试样本与所有训练样本的距离,然后根据距离判断样本的类别。</p>
<p>计算距离需要我们实现三种方法，分别为需要双重循环，单循环，不需要循环。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X, k=<span class="number">1</span>, num_loops=<span class="number">0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Predict labels for test data using this classifier.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - X: A numpy array of shape (num_test, D) containing test data consisting</span></span><br><span class="line"><span class="string">         of num_test samples each of dimension D.</span></span><br><span class="line"><span class="string">    - k: The number of nearest neighbors that vote for the predicted labels.</span></span><br><span class="line"><span class="string">    - num_loops: Determines which implementation to use to compute distances</span></span><br><span class="line"><span class="string">      between training points and testing points.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    - y: A numpy array of shape (num_test,) containing predicted labels for the</span></span><br><span class="line"><span class="string">      test data, where y[i] is the predicted label for the test point X[i].</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> num_loops == <span class="number">0</span>:</span><br><span class="line">        dists = self.compute_distances_no_loops(X)</span><br><span class="line">    <span class="keyword">elif</span> num_loops == <span class="number">1</span>:</span><br><span class="line">        dists = self.compute_distances_one_loop(X)</span><br><span class="line">    <span class="keyword">elif</span> num_loops == <span class="number">2</span>:</span><br><span class="line">        dists = self.compute_distances_two_loops(X)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;Invalid value %d for num_loops&quot;</span> % num_loops)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> self.predict_labels(dists, k=k)</span><br></pre></td></tr></table></figure>
<hr />
<h4 id="双重循环实现">双重循环实现</h4>
<p>第i个测试样本与第j个训练样本的距离<span
class="math inline">\(dist[i,j]\)</span>等于用第i个测试图像的特征向量减去第j个训练图像的特征向量的值</p>
<p><span
class="math inline">\(\sum_ndist[i,j]=\sqrt{(x_{test[i,d]}-x_{train[j,d]})^2}\)</span></p>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/dij.png" /></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_distances_two_loops</span>(<span class="params">self, X</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute the distance between each test point in X and each training point</span></span><br><span class="line"><span class="string">    in self.X_train using a nested loop over both the training data and the</span></span><br><span class="line"><span class="string">    test data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - X: A numpy array of shape (num_test, D) containing test data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]</span></span><br><span class="line"><span class="string">      is the Euclidean distance between the ith test point and the jth training</span></span><br><span class="line"><span class="string">      point.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    num_test = X.shape[<span class="number">0</span>]</span><br><span class="line">    num_train = self.X_train.shape[<span class="number">0</span>]</span><br><span class="line">    dists = np.zeros((num_test, num_train))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_test):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(num_train):</span><br><span class="line">            <span class="comment">#####################################################################</span></span><br><span class="line">            <span class="comment"># <span class="doctag">TODO:</span>                                                             #</span></span><br><span class="line">            <span class="comment"># Compute the l2 distance between the ith test point and the jth    #</span></span><br><span class="line">            <span class="comment"># training point, and store the result in dists[i, j]. You should   #</span></span><br><span class="line">            <span class="comment"># not use a loop over dimension, nor use np.linalg.norm().          #</span></span><br><span class="line">            <span class="comment">#####################################################################</span></span><br><span class="line">            <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">            dists[i][j]=np.sqrt(np.<span class="built_in">sum</span>(np.square(X[i,:]-self.X_train[j,:])))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">    <span class="keyword">return</span> dists</span><br></pre></td></tr></table></figure>
<hr />
<h4 id="单循环实现">单循环实现</h4>
<p>利用numpy的broadcast机制，可以直接计算第i张测试图像与所有训练样本的距离</p>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/dij_single.png" /></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_distances_one_loop</span>(<span class="params">self, X</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute the distance between each test point in X and each training point</span></span><br><span class="line"><span class="string">    in self.X_train using a single loop over the test data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Input / Output: Same as compute_distances_two_loops</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    num_test = X.shape[<span class="number">0</span>]</span><br><span class="line">    num_train = self.X_train.shape[<span class="number">0</span>]</span><br><span class="line">    dists = np.zeros((num_test, num_train))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_test):</span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span>                                                               #</span></span><br><span class="line">        <span class="comment"># Compute the l2 distance between the ith test point and all training #</span></span><br><span class="line">        <span class="comment"># points, and store the result in dists[i, :].                        #</span></span><br><span class="line">        <span class="comment"># Do not use np.linalg.norm().                                        #</span></span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">        <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">        dists[i,:]=np.sqrt(np.<span class="built_in">sum</span>(np.square(X[i,:]-self.X_train),axis=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">    <span class="keyword">return</span> dists</span><br></pre></td></tr></table></figure>
<table style="width:14%;">
<colgroup>
<col style="width: 13%" />
</colgroup>
<tbody>
<tr class="odd">
<td>### 无循环实现</td>
</tr>
<tr class="even">
<td>个矩阵不能直接相减，不用循环计算距离，考虑距离公式，同时需保证最后得到的dists.shape满足(num_test,num_train)</td>
</tr>
<tr class="odd">
<td>(a-b)<sup>2=a</sup>2+b^2-2ab$</td>
</tr>
<tr class="even">
<td><a
target="_blank" rel="noopener" href="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/dij_no.png"></a></td>
</tr>
<tr class="odd">
<td>!--code￼5--&gt;</td>
</tr>
<tr class="even">
<td>## 3. 预测：根据K个最邻近距离中的多数确定标签</td>
</tr>
<tr class="odd">
<td>np.argsort() 返回一个数组排好序后各元素对应的原来的位置序号</td>
</tr>
<tr class="even">
<td>xamples:</td>
</tr>
<tr class="odd">
<td>!--code￼6--&gt;</td>
</tr>
<tr class="even">
<td>np.bincount() 计算非负整数数组中每个值的出现次数。</td>
</tr>
<tr class="odd">
<td>xamples:</td>
</tr>
<tr class="even">
<td>!--code￼7--&gt;</td>
</tr>
</tbody>
</table>
<p>需要实现两个功能</p>
<ol type="1">
<li><p>选择与测试图像最相似（距离最小）的k张训练图像
np.argsort(dists[i])函数是将dist中的i行元素从小到大排列，并得到对应的index。然后再取前k个索引（也就是得到距离最近的k张图像的索引）</p></li>
<li><p>计算这k张图像所对应的类别出现的次数，选择出现次数最多的类别</p></li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict_labels</span>(<span class="params">self, dists, k=<span class="number">1</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Given a matrix of distances between test points and training points,</span></span><br><span class="line"><span class="string">    predict a label for each test point.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]</span></span><br><span class="line"><span class="string">      gives the distance betwen the ith test point and the jth training point.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    - y: A numpy array of shape (num_test,) containing predicted labels for the</span></span><br><span class="line"><span class="string">      test data, where y[i] is the predicted label for the test point X[i].</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    num_test = dists.shape[<span class="number">0</span>]</span><br><span class="line">    y_pred = np.zeros(num_test)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_test):</span><br><span class="line">        <span class="comment"># A list of length k storing the labels of the k nearest neighbors to</span></span><br><span class="line">        <span class="comment"># the ith test point.</span></span><br><span class="line">        closest_y = []</span><br><span class="line">        <span class="comment">#########################################################################</span></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span>                                                                 #</span></span><br><span class="line">        <span class="comment"># Use the distance matrix to find the k nearest neighbors of the ith    #</span></span><br><span class="line">        <span class="comment"># testing point, and use self.y_train to find the labels of these       #</span></span><br><span class="line">        <span class="comment"># neighbors. Store these labels in closest_y.                           #</span></span><br><span class="line">        <span class="comment"># Hint: Look up the function numpy.argsort.                             #</span></span><br><span class="line">        <span class="comment">#########################################################################</span></span><br><span class="line">        <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">        closest_y = self.y_train[np.argsort(dists[i])[:k]]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">        <span class="comment">#########################################################################</span></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span>                                                                 #</span></span><br><span class="line">        <span class="comment"># Now that you have found the labels of the k nearest neighbors, you    #</span></span><br><span class="line">        <span class="comment"># need to find the most common label in the list closest_y of labels.   #</span></span><br><span class="line">        <span class="comment"># Store this label in y_pred[i]. Break ties by choosing the smaller     #</span></span><br><span class="line">        <span class="comment"># label.                                                                #</span></span><br><span class="line">        <span class="comment">#########################################################################</span></span><br><span class="line">        <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">        y_pred[i] = np.argmax(np.bincount(closest_y))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="knn.ipynb">knn.ipynb</h2>
<p>讨论knn中k的取值问题</p>
<ul>
<li>np.array_split() 将一个数组拆分为多个子数组，可以大小不等。</li>
</ul>
<p>Examples:</p>
<h2 id="section"><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">x = np.arange(<span class="number">8.0</span>)</span><br><span class="line">np.array_split(x, <span class="number">3</span>)</span><br><span class="line">[array([<span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>]), array([<span class="number">3.</span>,  <span class="number">4.</span>,  <span class="number">5.</span>]), array([<span class="number">6.</span>,  <span class="number">7.</span>])]</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">9</span>)</span><br><span class="line">np.array_split(x, <span class="number">4</span>)</span><br><span class="line">[array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]), array([<span class="number">3</span>, <span class="number">4</span>]), array([<span class="number">5</span>, <span class="number">6</span>]), array([<span class="number">7</span>, <span class="number">8</span>])]</span><br></pre></td></tr></table></figure></h2>
<p>knn需要选择k个近邻然后进行t投票，那么问题来了，k应该取几效果会比较好呢？</p>
<p>需要做两个任务：</p>
<ol type="1">
<li>划分训练集</li>
<li>交叉验证</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num_folds = <span class="number">5</span></span><br><span class="line">k_choices = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">8</span>, <span class="number">10</span>, <span class="number">12</span>, <span class="number">15</span>, <span class="number">20</span>, <span class="number">50</span>, <span class="number">100</span>]</span><br><span class="line"></span><br><span class="line">X_train_folds = []</span><br><span class="line">y_train_folds = []</span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span>                                                                        #</span></span><br><span class="line"><span class="comment"># Split up the training data into folds. After splitting, X_train_folds and    #</span></span><br><span class="line"><span class="comment"># y_train_folds should each be lists of length num_folds, where                #</span></span><br><span class="line"><span class="comment"># y_train_folds[i] is the label vector for the points in X_train_folds[i].     #</span></span><br><span class="line"><span class="comment"># Hint: Look up the numpy array_split function.                                #</span></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">X_train_folds = np.array_split(X_train,num_folds)</span><br><span class="line">y_train_folds = np.array_split(y_train,num_folds)</span><br><span class="line"></span><br><span class="line"><span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># A dictionary holding the accuracies for different values of k that we find</span></span><br><span class="line"><span class="comment"># when running cross-validation. After running cross-validation,</span></span><br><span class="line"><span class="comment"># k_to_accuracies[k] should be a list of length num_folds giving the different</span></span><br><span class="line"><span class="comment"># accuracy values that we found when using that value of k.</span></span><br><span class="line">k_to_accuracies = &#123;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span>                                                                        #</span></span><br><span class="line"><span class="comment"># Perform k-fold cross validation to find the best value of k. For each        #</span></span><br><span class="line"><span class="comment"># possible value of k, run the k-nearest-neighbor algorithm num_folds times,   #</span></span><br><span class="line"><span class="comment"># where in each case you use all but one of the folds as training data and the #</span></span><br><span class="line"><span class="comment"># last fold as a validation set. Store the accuracies for all fold and all     #</span></span><br><span class="line"><span class="comment"># values of k in the k_to_accuracies dictionary.                               #</span></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> k_choices:</span><br><span class="line">    k_to_accuracies.setdefault(k, [])</span><br><span class="line">    <span class="comment">#print(k_to_accuracies)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_folds):</span><br><span class="line">    classifier = KNearestNeighbor()</span><br><span class="line">    X_val_train = np.vstack(X_train_folds[<span class="number">0</span>:i] + X_train_folds[i+<span class="number">1</span>:])</span><br><span class="line">    y_val_train = np.hstack(y_train_folds[<span class="number">0</span>:i] + y_train_folds[i+<span class="number">1</span>:])</span><br><span class="line">    <span class="comment">#print(X_val_train, y_val_train)</span></span><br><span class="line">    classifier.train(X_val_train, y_val_train)</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> k_choices:</span><br><span class="line">        y_val_pred = classifier.predict(X_train_folds[i], k)</span><br><span class="line">        num_correct = np.<span class="built_in">sum</span>(y_val_pred == y_train_folds[i])</span><br><span class="line">        accuracy = <span class="built_in">float</span>(num_correct) / <span class="built_in">len</span>(y_val_pred)</span><br><span class="line">        k_to_accuracies[k] += [accuracy]</span><br><span class="line">        <span class="comment">#print(k,k_to_accuracies[k])</span></span><br><span class="line">    <span class="comment">#print(k_to_accuracies)</span></span><br><span class="line"><span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Print out the computed accuracies</span></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">sorted</span>(k_to_accuracies):</span><br><span class="line">    <span class="keyword">for</span> accuracy <span class="keyword">in</span> k_to_accuracies[k]:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;k = %d, accuracy = %f&#x27;</span> % (k, accuracy))</span><br></pre></td></tr></table></figure>
<div class="note default no-icon flat"><p>k = 1, accuracy = 0.263000 k = 1, accuracy = 0.257000 k = 1, accuracy
= 0.264000 k = 1, accuracy = 0.278000 k = 1, accuracy = 0.266000 k = 3,
accuracy = 0.239000 k = 3, accuracy = 0.249000 k = 3, accuracy =
0.240000 k = 3, accuracy = 0.266000 k = 3, accuracy = 0.254000 k = 5,
accuracy = 0.248000 k = 5, accuracy = 0.266000 k = 5, accuracy =
0.280000 k = 5, accuracy = 0.292000 k = 5, accuracy = 0.280000 k = 8,
accuracy = 0.262000 k = 8, accuracy = 0.282000 k = 8, accuracy =
0.273000 k = 8, accuracy = 0.290000 k = 8, accuracy = 0.273000 k = 10,
accuracy = 0.265000 k = 10, accuracy = 0.296000 k = 10, accuracy =
0.276000 k = 10, accuracy = 0.284000 k = 10, accuracy = 0.280000 k = 12,
accuracy = 0.260000 k = 12, accuracy = 0.295000 k = 12, accuracy =
0.279000 k = 12, accuracy = 0.283000 k = 12, accuracy = 0.280000 k = 15,
accuracy = 0.252000 k = 15, accuracy = 0.289000 k = 15, accuracy =
0.278000 k = 15, accuracy = 0.282000 k = 15, accuracy = 0.274000 k = 20,
accuracy = 0.270000 k = 20, accuracy = 0.279000 k = 20, accuracy =
0.279000 k = 20, accuracy = 0.282000 k = 20, accuracy = 0.285000 k = 50,
accuracy = 0.271000 k = 50, accuracy = 0.288000 k = 50, accuracy =
0.278000 k = 50, accuracy = 0.269000 k = 50, accuracy = 0.266000 k =
100, accuracy = 0.256000 k = 100, accuracy = 0.270000 k = 100, accuracy
= 0.263000 k = 100, accuracy = 0.256000 k = 100, accuracy = 0.263000</p>
</div>
<p>这里可以选出最好的k值</p>
<ul>
<li>best_k = k_choices[accuracies_mean.argmax()]</li>
</ul>
<h3 id="inline-question-1"><strong>Inline Question 1</strong></h3>
<p>Notice the structured patterns in the distance matrix, where some
rows or columns are visibly brighter. (Note that with the default color
scheme black indicates low distances while white indicates high
distances.)</p>
<ul>
<li>What in the data is the cause behind the distinctly bright
rows?</li>
<li>What causes the columns?</li>
</ul>
<p><span class="math inline">\(\color{blue}{\textit Your
Answer:}\)</span> <em>fill this in.</em></p>
<ol type="1">
<li><p>The test image is far different from all the train
image.</p></li>
<li><p>The train image is unsimilar to all the test image.</p></li>
</ol>
<h3 id="inline-question-2"><strong>Inline Question 2</strong></h3>
<p>We can also use other distance metrics such as L1 distance. For pixel
values <span class="math inline">\(p_{ij}^{(k)}\)</span> at location
<span class="math inline">\((i,j)\)</span> of some image <span
class="math inline">\(I_k\)</span>,</p>
<p>the mean <span class="math inline">\(\mu\)</span> across all pixels
over all images is <span
class="math display">\[\mu=\frac{1}{nhw}\sum_{k=1}^n\sum_{i=1}^{h}\sum_{j=1}^{w}p_{ij}^{(k)}\]</span>
And the pixel-wise mean <span class="math inline">\(\mu_{ij}\)</span>
across all images is <span
class="math display">\[\mu_{ij}=\frac{1}{n}\sum_{k=1}^np_{ij}^{(k)}.\]</span>
The general standard deviation <span
class="math inline">\(\sigma\)</span> and pixel-wise standard deviation
<span class="math inline">\(\sigma_{ij}\)</span> is defined
similarly.</p>
<p>Which of the following preprocessing steps will not change the
performance of a Nearest Neighbor classifier that uses L1 distance?
Select all that apply. 1. Subtracting the mean <span
class="math inline">\(\mu\)</span> (<span
class="math inline">\(\tilde{p}_{ij}^{(k)}=p_{ij}^{(k)}-\mu\)</span>.)
2. Subtracting the per pixel mean <span
class="math inline">\(\mu_{ij}\)</span> (<span
class="math inline">\(\tilde{p}_{ij}^{(k)}=p_{ij}^{(k)}-\mu_{ij}\)</span>.)
3. Subtracting the mean <span class="math inline">\(\mu\)</span> and
dividing by the standard deviation <span
class="math inline">\(\sigma\)</span>. 4. Subtracting the pixel-wise
mean <span class="math inline">\(\mu_{ij}\)</span> and dividing by the
pixel-wise standard deviation <span
class="math inline">\(\sigma_{ij}\)</span>. 5. Rotating the coordinate
axes of the data.</p>
<p><span class="math inline">\(\color{blue}{\textit Your
Answer:}\)</span></p>
<p>1, 3 will not change the L1 Distance.</p>
<p><span class="math inline">\(\color{blue}{\textit Your
Explanation:}\)</span></p>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/inline1.jpg" /></p>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/inline2.jpg" /></p>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/inline3.jpg" /></p>
<h3 id="inline-question-3"><strong>Inline Question 3</strong></h3>
<p>Which of the following statements about <span
class="math inline">\(k\)</span>-Nearest Neighbor (<span
class="math inline">\(k\)</span>-NN) are true in a classification
setting, and for all <span class="math inline">\(k\)</span>? Select all
that apply. 1. The decision boundary of the k-NN classifier is linear.
2. The training error of a 1-NN will always be lower than or equal to
that of 5-NN. 3. The test error of a 1-NN will always be lower than that
of a 5-NN. 4. The time needed to classify a test example with the k-NN
classifier grows with the size of the training set. 5. None of the
above.</p>
<p><span class="math inline">\(\color{blue}{\textit Your
Answer:}\)</span></p>
<p>2, 4.</p>
<p><span class="math inline">\(\color{blue}{\textit Your
Explanation:}\)</span></p>
<ol type="1">
<li><p>False. It depends on the given categories of data, if you give a
category with a circle boundary to its neighborhood, it is
non-linear.</p></li>
<li><p>True. In fact the training error of a 1-NN is always 0, and
5-NN's lower bound is 0. It is because the nearest neighbor of test data
is always going to be itself in 1-NN.</p></li>
<li><p>False. The value of k is thus data-dependent, that is why we need
to perform cross validation to determine the best k for your intended
application and dataset.</p></li>
<li><p>True. At test, KNN needs to make a full pass through the entire
data set and sort points by distance. The time needed thus grows with
the size of the data.</p></li>
</ol>
<p>参考链接:</p>
<ol type="1">
<li>cs231n官网: https://cs231n.github.io/</li>
<li>cs231n作业，assignment1-knn详解（注重算法与代码的结合）:
https://blog.csdn.net/qq_24906797/article/details/89245722</li>
<li>cs231n assignment1 knn:
https://blog.csdn.net/SpicyCoder/article/details/94992552</li>
<li>【本课程配套的代码作业讲解见置顶评论】斯坦福CS231N计算机视觉作业讲解：
https://www.bilibili.com/video/BV1t4411U78z/?spm_id_from=333.337.search-card.all.click&amp;vd_source=f0de9c6453942ba082fa767eb7aa958a</li>
<li>CS231N作业详解零基础版：
https://www.bilibili.com/video/BV19z411b7u9/?p=6&amp;vd_source=f0de9c6453942ba082fa767eb7aa958a</li>
</ol>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E4%BB%8B%E7%BB%8D/">介绍</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/cs231n/">cs231n</a><a class="post-meta__tags" href="/tags/%E4%BD%9C%E4%B8%9A/">作业</a></div><div class="post_share"><div class="social-share" data-image="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/cs231n_assignment1.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2022/12/14/Transformer%E6%A8%A1%E5%9E%8B%E5%88%9D%E6%8E%A2/"><img class="next-cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Transformer模型初探</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2020/02/11/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/" title="我的第一篇博客"><img class="cover" src="https://github.com/serika-onoe/web-img/raw/main/background/wuming.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-02-11</div><div class="title">我的第一篇博客</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div id="comment-switch"><span class="first-comment">Valine</span><span class="switch-btn"></span><span class="second-comment"> Disqus</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div><div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">龚泽颖</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/serika-onoe" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:zgong313@connect.hkust-gz.edu.cn" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">雪融化了，是春天！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#cs231n-assignment-1"><span class="toc-number">1.</span> <span class="toc-text">CS231n Assignment 1</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#k-nearest-neighbor-knn-exercise"><span class="toc-number">2.</span> <span class="toc-text">k-Nearest Neighbor (kNN)
exercise</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#k_nearest_neighbor.py"><span class="toc-number">2.1.</span> <span class="toc-text">k_nearest_neighbor.py</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-number">2.1.1.</span> <span class="toc-text">训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E8%AE%A1%E7%AE%97%E6%B5%8B%E8%AF%95%E5%9B%BE%E5%83%8F%E5%92%8C%E6%89%80%E6%9C%89%E8%AE%AD%E7%BB%83%E5%9B%BE%E5%83%8F%E7%9A%84l2%E8%B7%9D%E7%A6%BB"><span class="toc-number">2.1.2.</span> <span class="toc-text">预测：计算测试图像和所有训练图像的L2距离</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%8C%E9%87%8D%E5%BE%AA%E7%8E%AF%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.1.2.1.</span> <span class="toc-text">双重循环实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%95%E5%BE%AA%E7%8E%AF%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.1.2.2.</span> <span class="toc-text">单循环实现</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#knn.ipynb"><span class="toc-number">2.2.</span> <span class="toc-text">knn.ipynb</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#section"><span class="toc-number">2.3.</span> <span class="toc-text">x &#x3D; np.arange(8.0)np.array_split(x, 3)[array([0.,  1.,  2.]), array([3.,  4.,  5.]), array([6.,  7.])]x &#x3D; np.arange(9)np.array_split(x, 4)[array([0, 1, 2]), array([3, 4]), array([5, 6]), array([7, 8])]</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#inline-question-1"><span class="toc-number">2.3.1.</span> <span class="toc-text">Inline Question 1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#inline-question-2"><span class="toc-number">2.3.2.</span> <span class="toc-text">Inline Question 2</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#inline-question-3"><span class="toc-number">2.3.3.</span> <span class="toc-text">Inline Question 3</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/12/20/CS231n-Assignment-1/" title="CS231n Assignment 1"><img src="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/cs231n_assignment1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CS231n Assignment 1"/></a><div class="content"><a class="title" href="/2022/12/20/CS231n-Assignment-1/" title="CS231n Assignment 1">CS231n Assignment 1</a><time datetime="2022-12-20T14:49:13.000Z" title="发表于 2022-12-20 22:49:13">2022-12-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/14/Transformer%E6%A8%A1%E5%9E%8B%E5%88%9D%E6%8E%A2/" title="Transformer模型初探"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Transformer模型初探"/></a><div class="content"><a class="title" href="/2022/12/14/Transformer%E6%A8%A1%E5%9E%8B%E5%88%9D%E6%8E%A2/" title="Transformer模型初探">Transformer模型初探</a><time datetime="2022-12-14T01:42:13.000Z" title="发表于 2022-12-14 09:42:13">2022-12-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/12/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%9D%E6%8E%A2/" title="强化学习初探"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="强化学习初探"/></a><div class="content"><a class="title" href="/2022/12/12/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%9D%E6%8E%A2/" title="强化学习初探">强化学习初探</a><time datetime="2022-12-12T15:17:01.000Z" title="发表于 2022-12-12 23:17:01">2022-12-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/09/%E6%88%91%E7%9A%84%E7%A7%91%E7%A0%94%E7%BB%8F%E5%8E%86/" title="我的项目经历"><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/uav3(1).png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="我的项目经历"/></a><div class="content"><a class="title" href="/2022/12/09/%E6%88%91%E7%9A%84%E7%A7%91%E7%A0%94%E7%BB%8F%E5%8E%86/" title="我的项目经历">我的项目经历</a><time datetime="2022-12-09T03:10:23.000Z" title="发表于 2022-12-09 11:10:23">2022-12-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/01/13/Python%E7%88%AC%E8%99%AB%E7%88%AC%E5%8F%96%E5%9B%BD%E5%AE%B6%E7%BB%9F%E8%AE%A1%E5%B1%80%E6%95%B0%E6%8D%AE/" title="Python爬虫爬取国家统计局数据"><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/8.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Python爬虫爬取国家统计局数据"/></a><div class="content"><a class="title" href="/2021/01/13/Python%E7%88%AC%E8%99%AB%E7%88%AC%E5%8F%96%E5%9B%BD%E5%AE%B6%E7%BB%9F%E8%AE%A1%E5%B1%80%E6%95%B0%E6%8D%AE/" title="Python爬虫爬取国家统计局数据">Python爬虫爬取国家统计局数据</a><time datetime="2021-01-12T16:12:47.000Z" title="发表于 2021-01-13 00:12:47">2021-01-13</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By 龚泽颖</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="algolia-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="search-wrap"><div id="algolia-search-input"></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-info"><div class="algolia-stats"></div><div class="algolia-poweredBy"></div></div></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/algoliasearch/dist/algoliasearch-lite.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instantsearch.js/dist/instantsearch.production.min.js"></script><script src="/js/search/algolia.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '',
      appKey: '',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script defer src="https://cdn.jsdelivr.net/gh/CodeByZach/pace/pace.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>