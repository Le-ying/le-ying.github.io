<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Kung&#39;s Blog</title>
  
  <subtitle>Welcome to my blog!</subtitle>
  <link href="https://serika-onoe.github.io/en/atom.xml" rel="self"/>
  
  <link href="https://serika-onoe.github.io/en/"/>
  <updated>2022-12-12T14:45:37.714Z</updated>
  <id>https://serika-onoe.github.io/en/</id>
  
  <author>
    <name>Richard Kung</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>My Projects</title>
    <link href="https://serika-onoe.github.io/en/2022/12/09/2022-12-09-My-projects/"/>
    <id>https://serika-onoe.github.io/en/2022/12/09/2022-12-09-My-projects/</id>
    <published>2022-12-09T03:10:23.000Z</published>
    <updated>2022-12-12T14:45:37.714Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Software-Programming-Projects"><a href="#Software-Programming-Projects" class="headerlink" title="Software Programming Projects"></a>Software Programming Projects</h1><h2 id="Cluster-Unmanned-Aerial-Vehicle-Electromagnetic-Calculations-and-Applications"><a href="#Cluster-Unmanned-Aerial-Vehicle-Electromagnetic-Calculations-and-Applications" class="headerlink" title="Cluster Unmanned Aerial Vehicle Electromagnetic Calculations and Applications"></a>Cluster Unmanned Aerial Vehicle Electromagnetic Calculations and Applications</h2><p>2021.1 - 2021.8</p><hr><h3 id="Description"><a href="#Description" class="headerlink" title="Description."></a>Description.</h3><p>We solve the problem of acquiring target electromagnetic characteristic data of UAV cluster by the following steps, and propose an innovative idea to solve the target detection of UAV cluster problem.</p><p>First, a typical single fixed-wing UAV represented by the “Gremlin” UAV is used as an example for electromagnetic calculation based on the multi-stage fast multipole method (MLFMM). Then, radar scattering cross section (RCS) simulation data and two-dimensional inverse synthetic aperture radar (ISAR) imaging are used to verify the accuracy of the results of the above simulations. Finally, we simulated and validated the RCS simulation data for the UAV cluster.</p><p>The programming languages and software tools used are as follow:</p><p>(1) Solidworks - to build 3D models of both types of UAVs<br>(2) Feko electromagnetic simulation software – MLFMM-based electromagnetic simulation calculations for UAVs<br>(3) MATLAB – simulation data cleaning and processing, ISAR imaging algorithm implementation</p><h3 id="Achievements"><a href="#Achievements" class="headerlink" title="Achievements."></a>Achievements.</h3><p>The process and conclusions of the project have been presented at the CIE Radar Conference 2021.</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/uav_prove.jpg"></p><p>We summarize and analyze the EM scattering calculations for the UAV target “Gremlin” in single and clustered cases, which are based on the application requirements and technical difficulties. Fully polarized static EM scattering was calculated for the “Gremlin” in typical frequency bands and the results were used to perform clustered target imaging, where the wingtip characteristics of the “Gremlin” can be clearly seen.</p><h4 id="Fixed-Wing-Representative-1-U-S-Army-Predator-UAV"><a href="#Fixed-Wing-Representative-1-U-S-Army-Predator-UAV" class="headerlink" title="Fixed Wing Representative 1 - U.S. Army Predator UAV"></a>Fixed Wing Representative 1 - U.S. Army Predator UAV</h4><p><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Finews.gtimg.com%2Fnewsapp_match%2F0%2F2985298796%2F0.jpg&refer=http%3A%2F%2Finews.gtimg.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1617869104&t=54d2c95a6f95de01679291e9b76837dd"></p><center>Fixed Wing Representative 1 - U.S. Army Predator drone in action</center><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/uav1.jpg"></p><center>Fixed Wing Representative 1--Model view of U.S. Army Predator drone</center><h4 id="Fixed-wing-representative-2-US-Army-Pixie-drone"><a href="#Fixed-wing-representative-2-US-Army-Pixie-drone" class="headerlink" title="Fixed-wing representative 2 - US Army Pixie drone"></a>Fixed-wing representative 2 - US Army Pixie drone</h4><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/uav2.jpg"></p><center>Fixed Wing Representative 2 - U.S. Army Pixie Drone Physical Image</center><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/uav3.jpg"></p><center>Fixed-wing representative 2 - a model of the U.S. Army Pixie drone</center><h4 id="Rotor-wing-representative-DJI-F450-drone"><a href="#Rotor-wing-representative-DJI-F450-drone" class="headerlink" title="Rotor wing representative - DJI F450 drone"></a>Rotor wing representative - DJI F450 drone</h4><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/uav4.jpg"></p><center>Rotary wing representative - DJI F450 drone physical picture</center><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/uav5.jpg"></p><center>Rotor representation - model image of DJI F450 drone</center> <h2 id="Semantic-understanding-of-point-clouds-under-weakly-supervised-conditions"><a href="#Semantic-understanding-of-point-clouds-under-weakly-supervised-conditions" class="headerlink" title="Semantic understanding of point clouds under weakly supervised conditions"></a>Semantic understanding of point clouds under weakly supervised conditions</h2><p>2020.10 - 2021.1</p><hr><h3 id="Description-1"><a href="#Description-1" class="headerlink" title="Description."></a>Description.</h3><p>To solve the problem of expensive data annotation in semantic segmentation of 3D point clouds, an attempt is made to use a weakly supervised learning approach for research. A review of the paper is presented, and the “PointNet++” code is reproduced.</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/pointcloud%20mind.png"></p><p>The programming languages and software tools used are.</p><p>(1) Python - code reproduction via Jupyter Notebook</p><h3 id="Achievements-1"><a href="#Achievements-1" class="headerlink" title="Achievements."></a>Achievements.</h3><p>Based on the PaddlePaddle framework of the Baidu AI platform, the classification of disordered point clouds generated from ten sets of furniture images reproduced the 91.9% accuracy rate of the “PointNet++” paper.</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/point%20cloud2.jpg"></p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/point%20cloud3.jpg"></p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/point%20cloud4.jpg"></p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/point%20cloud5.jpg"></p><h2 id="Python-crawl-for-country-statistics"><a href="#Python-crawl-for-country-statistics" class="headerlink" title="Python crawl for country statistics"></a>Python crawl for country statistics</h2><p>2021.1</p><hr><h3 id="Description-2"><a href="#Description-2" class="headerlink" title="Description."></a>Description.</h3><p>Independently, crawl the basic information of urban and rural residents’ income and expenditure for eight provinces and six quarters from the “National Bureau of Statistics”.</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/crawl%20mind.jpg"></p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/crawl2.jpg"></p><p>The programming languages and software tools used are.</p><p>(1) Python – crawler functionality through the panda library and table processing through the xlwings library</p><h3 id="Achievements-2"><a href="#Achievements-2" class="headerlink" title="Achievements."></a>Achievements.</h3><p>Crawl the table data of eight provinces and six quarters of the National Bureau of Statistics into excel tables, while the code can sieve invalid data, automatically organize the excel tables, and realize the data centering and adaptive column width through xlwings library.</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/crawl3.jpg"></p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/crawl4.jpg"></p><h2 id="app-creation-and-security-analysis"><a href="#app-creation-and-security-analysis" class="headerlink" title="app creation and security analysis"></a>app creation and security analysis</h2><p>2019.10 - 2020.1</p><hr><h3 id="Description-3"><a href="#Description-3" class="headerlink" title="Description."></a>Description.</h3><p>App Implementation Requirements:The app has a user&#x2F;password login function and is available for user registration. The password for registration is limited in length only (e.g. 8 digits in length), but the strength is not required for now. The user name&#x2F;password is saved on the cell phone, and the password is encrypted when saved (choose your own encryption algorithm).</p><p>The function is relatively simple, a floating window pops up, showing that the app needs to obtain storage space, device information, geolocation permissions prompt, you can choose to authorize or deny. By running the app on the phone, registering several accounts with strong and weak passwords, then analyzing the security and improving it.</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/app1.png"></p><p>Code related to the client login function (Kotlin).</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/app2.png"></p><p>Statements related to obtaining the permissions for storage space, device information, and geolocation permissions.</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/app3.png"></p><p>Screenshot of Androbugs analysis.</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/app5.png"></p><p>The analysis modifies the registration&#x2F;login authentication method of the original app to use the authorization code pattern from the OAuth2 specification: !</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/app6.png"></p><p>Changed external storage to internal storage: !</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/app7.png"></p><p>The programming languages and software tools used are.</p><p>(1) Kotlin – implement app functions through Android Studio<br>(2) Androbugs – analyzing app security</p><h3 id="Accomplishments"><a href="#Accomplishments" class="headerlink" title="Accomplishments."></a>Accomplishments.</h3><p>The full runtime video is as follows.</p> <iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTQwNjUwOA==' frameborder=0 allowfullscreen></iframe>  <h2 id="Experimenting-with-bypassing-authentication-systems"><a href="#Experimenting-with-bypassing-authentication-systems" class="headerlink" title="Experimenting with bypassing authentication systems"></a>Experimenting with bypassing authentication systems</h2><p>2019.9</p><hr><h3 id="Description-4"><a href="#Description-4" class="headerlink" title="Description."></a>Description.</h3><p>Many commercial WIFIs in shopping malls and restaurants use WEB Portal authentication, but some authentication systems are vulnerable and can bypass the gateway billing system using DNS TUNNEL. This vulnerability exists in commercial WIFI environments and can be verified to be able to use DNS TUNNEL to bypass the gateway billing system.</p><p>It is not really practical for DNS Tunnel to be used for “password-free Internet access”. Even though our group had “cut out” the expense of the cloud server (and moved the proxy server locally), the whole experiment ended up costing $6 to purchase the domain name.</p><p>The programming languages and software tools used were</p><p>(1) Raspberry Pi – build a local proxy server<br>(2) Portal – topology analysis and DNS simulation configuration</p><h3 id="Achievements-3"><a href="#Achievements-3" class="headerlink" title="Achievements."></a>Achievements.</h3><p>The whole experiment actually tells us: hackers will “see the needle”, DNS, a protocol dedicated to domain name queries, can also be used to transmit data. If you need to do network application layer protocol design and maintenance work in the future, you must be doubly careful and be very cautious in network security. Also for individuals, if they connect to a public network, they must be vigilant to prevent “high-tech theft” because it is difficult to know where the hackers will target next.</p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg5NzI1OTY0OA==' frameborder=0 allowfullscreen></iframe><h2 id="AI-playing-Tetris"><a href="#AI-playing-Tetris" class="headerlink" title="AI playing Tetris"></a>AI playing Tetris</h2><p>2018.9</p><hr><h3 id="Description-5"><a href="#Description-5" class="headerlink" title="Description."></a>Description.</h3><p>Implementing a tetris game using pygame while setting up an AI (can’t even use machine learning algorithms)</p><p>The programming languages and software tools used are.</p><p>(1) Python - to implement Tetris logic and AI algorithms</p><p>The basic idea of the AI algorithm is to traverse all possible future scenarios consisting of the current operable tetris and the next operable tetris (according to different strategies, i.e., choosing different positions and rotation angles) after they fall to the bottom   </p><p>The merits of future scenes are judged based on.</p><pre><code>1) the number of rows that can be eliminated.2) the number of virtual holes inside the stacked Tetris blocks.3) the number of small squares in the stacked Tetris.(4) the highest point of the stacked tetris.5) the standard deviation of the heights (one height for each column) of the stacked Tetris.6) the first-order forward difference of the heights of the stacked Tetris blocks.7) the standard deviation of the first-order forward difference of the heights of the stacked Tetris blocks.8) the difference between the highest and lowest points of the stacked Tetris.</code></pre><p>Choose the optimal one from these future scenarios, whose corresponding action strategy for the currently operable Tetris is the current solution </p><h3 id="Achievements-4"><a href="#Achievements-4" class="headerlink" title="Achievements."></a>Achievements.</h3><p>Video demonstration of dragging the source code while the game is running automatically to show that it is not a manual operation hh</p> <iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTAwMTY4MA==' frameborder=0 allowfullscreen></iframe>   <h2 id="Handwritten-number-recognition-GUI"><a href="#Handwritten-number-recognition-GUI" class="headerlink" title="Handwritten number recognition GUI"></a>Handwritten number recognition GUI</h2><p>2020.11 - 2021.1</p><hr><h3 id="Description-6"><a href="#Description-6" class="headerlink" title="Description."></a>Description.</h3><p>Handwritten digit recognition GUI development without using frameworks</p><p>The programming languages and software tools used are.</p><p>(1) Python - development of GUI interface (based on Qt5), involving basic bp algorithm implementation and optimization algorithms such as regularization (BN, L2 regularization, RMSProp), and implementation of pyqt interface and three functions: extraction recognition in mnist, upload image recognition, and drawing board handwriting recognition</p><h3 id="Achievements-5"><a href="#Achievements-5" class="headerlink" title="Achievements."></a>Achievements.</h3> <iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTAwMDg3Mg==' frameborder=0 allowfullscreen></iframe>   <h2 id="Mario-DIY-version"><a href="#Mario-DIY-version" class="headerlink" title="Mario DIY version"></a>Mario DIY version</h2><p>2018.4 - 2018.6</p><hr><h3 id="Description-7"><a href="#Description-7" class="headerlink" title="Description."></a>Description.</h3><p>DIY a Mario with changed life settings and map scenes from the original version.</p><p>Life cap can be increased by eating mushrooms and returning a portion of blood, while if the body is in villain form it turns into adult form. When hit, the form does not change and the HP is deducted accordingly.</p><p>The programming language and software tools used are.</p><p>(1) Gamemaker - to develop the game interface, draw the game map and play logic implementation</p><p>Achievements.</p><p><strong>Pass demo and simple function demo</strong></p> <iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTAwMjQxMg==' frameborder=0 allowfullscreen></iframe> <p><strong>If HP is 0, then just die</strong></p> <iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTAwNDE1Mg==' frameborder=0 allowfullscreen></iframe>  <h2 id="Easy-version-of-Magic-Tower"><a href="#Easy-version-of-Magic-Tower" class="headerlink" title="Easy version of Magic Tower"></a>Easy version of Magic Tower</h2><p>2017.11 - 2018.1</p><hr><h3 id="Description-8"><a href="#Description-8" class="headerlink" title="Description."></a>Description.</h3><p>Command line interface, operable simple version of Magic Tower</p><p>The programming languages and software tools used are.</p><p>(1) C++ – drawing game maps and play logic implementation via command line and strings</p><h3 id="Accomplishments-1"><a href="#Accomplishments-1" class="headerlink" title="Accomplishments."></a>Accomplishments.</h3><p><strong>Pass demo and simple functionality demo</strong></p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg5NzU4NDgzMg==' frameborder=0 allowfullscreen></iframe><h2 id="Epidemic-map-applet"><a href="#Epidemic-map-applet" class="headerlink" title="Epidemic map applet"></a>Epidemic map applet</h2><p>2020.6</p><hr><h3 id="Description-9"><a href="#Description-9" class="headerlink" title="Description."></a>Description.</h3><p>An epidemic map made during the epidemic, divided into two sections: domestic and foreign, each section is divided into two subsections: cumulative epidemic of the day and new epidemic of the day, citing the data source of the open class bar, where the darker the color indicates the more infected people.</p><p>The programming languages and software tools used are.</p><p>(1) html – citing the data source of Open Class Bar, trying to visualize the figures</p><h3 id="Results"><a href="#Results" class="headerlink" title="Results."></a>Results.</h3><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg5NzI4NDU0MA==' frameborder=0 allowfullscreen></iframe><h2 id="Hardware-Control-Project"><a href="#Hardware-Control-Project" class="headerlink" title="Hardware Control Project"></a>Hardware Control Project</h2><h2 id="Multiple-switching-methods-for-toy-dogs"><a href="#Multiple-switching-methods-for-toy-dogs" class="headerlink" title="Multiple switching methods for toy dogs"></a>Multiple switching methods for toy dogs</h2><h2 id="GPS-spoofing"><a href="#GPS-spoofing" class="headerlink" title="GPS spoofing"></a>GPS spoofing</h2><p>2019.9 - 2019.11</p><hr><h3 id="Description-10"><a href="#Description-10" class="headerlink" title="Description."></a>Description.</h3><p>In the Linux environment, the cell phone with GPS satellite positioning is applied, and the HackRF One transmits a spoofing signal to achieve point-to-point spoofing or trajectory spoofing, which can successfully spoof to the specified location within 1 or 2 minutes of uninterrupted motion within the specified trajectory based on the given acceleration and speed.</p><p>The programming language and software tools used are.</p><p>(1) Hardware: HackRF One - with TCXO clock module and antenna for transmitting GPS signals<br> (2) Software.</p><table><thead><tr><th>software</th><th>role</th></tr></thead><tbody><tr><td>Google Earth</td><td>Selects the spoofed location and sketches the target trajectory</td></tr><tr><td>SatGen</td><td>Target trajectory and store as motion path</td></tr><tr><td>gps-sdr-sim</td><td>Samples data files to generate GPS data sources</td></tr><tr><td>Gnuradio</td><td>A flowchart-style program to run GPS spoofing</td></tr><tr><td>hackrf-tools</td><td>Run GPS spoofing from the command line via the hackrf_transfer function</td></tr></tbody></table><p><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/gps%20mind.png"></p><h3 id="Achievements-6"><a href="#Achievements-6" class="headerlink" title="Achievements."></a>Achievements.</h3><p>The actual phone is located at a certain point in the living area of Guangzhou University City and is stationary, and the position is spoofed to run at variable speed on the playground track of Shanghai Jiaotong University, 1,000 km away, within 5m accuracy throughout.</p> <iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTAwNDUyOA==' frameborder=0 allowfullscreen></iframe> <p>2020.11 - 2021.1</p><hr><h3 id="Description-11"><a href="#Description-11" class="headerlink" title="Description."></a>Description.</h3><p>According to the toy electronic dog, through its circuit diagram is modified accordingly, can get different switch corresponding way, in addition to the following video has also been achieved magnetic control, small program control, Bluetooth control and other ways</p><p>The hardware modules used are.</p><p> (1) toy electronic dog – with basic walking, barking function<br> (2) circuit board – to achieve different ways to switch and solder the circuit<br>(3) Bluetooth switch module – with WeChat small program control system</p><h3 id="Achievements-7"><a href="#Achievements-7" class="headerlink" title="Achievements."></a>Achievements.</h3><p><strong>keyed switch method</strong></p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg5NzI5MDU0MA==' frameborder=0 allowfullscreen></iframe><p><strong>Temperature control switch method</strong></p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg5NzI5MDcyMA==' frameborder=0 allowfullscreen></iframe><h2 id="Arduino-based-music-player"><a href="#Arduino-based-music-player" class="headerlink" title="Arduino-based music player"></a>Arduino-based music player</h2><p>2020.4 - 2020.6</p><hr><h3 id="Description-12"><a href="#Description-12" class="headerlink" title="Description."></a>Description.</h3><p>The basic functions of MP3 (track switching, multiple playback modes, volume adjustment) are implemented through cell phone (serial port) or computer input control.</p><p>The hardware modules used are.</p><p> (1) Arduino – central processor<br> (2) tf card – storage of tracks<br>(3) speaker – play sound<br> (4) LCD screen – display playback mode, tracks</p><h3 id="Accomplishments-2"><a href="#Accomplishments-2" class="headerlink" title="Accomplishments."></a>Accomplishments.</h3><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTAzMDQwOA==' frameborder=0 allowfullscreen></iframe>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Software-Programming-Projects&quot;&gt;&lt;a href=&quot;#Software-Programming-Projects&quot; class=&quot;headerlink&quot; title=&quot;Software Programming Projects&quot;&gt;&lt;/a</summary>
      
    
    
    
    <category term="summary" scheme="https://serika-onoe.github.io/en/categories/summary/"/>
    
    
    <category term="research" scheme="https://serika-onoe.github.io/en/tags/research/"/>
    
    <category term="project" scheme="https://serika-onoe.github.io/en/tags/project/"/>
    
  </entry>
  
  <entry>
    <title>Develop Web Crawling in A National Statistic Institute</title>
    <link href="https://serika-onoe.github.io/en/2021/01/13/2022-12-09-Python%E7%88%AC%E8%99%AB%E7%88%AC%E5%8F%96%E5%9B%BD%E5%AE%B6%E7%BB%9F%E8%AE%A1%E5%B1%80%E6%95%B0%E6%8D%AE/"/>
    <id>https://serika-onoe.github.io/en/2021/01/13/2022-12-09-Python%E7%88%AC%E8%99%AB%E7%88%AC%E5%8F%96%E5%9B%BD%E5%AE%B6%E7%BB%9F%E8%AE%A1%E5%B1%80%E6%95%B0%E6%8D%AE/</id>
    <published>2021-01-12T16:12:47.000Z</published>
    <updated>2022-12-12T14:38:42.128Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Develop-Web-Crawling-in-A-National-Statistic-Institute"><a href="#Develop-Web-Crawling-in-A-National-Statistic-Institute" class="headerlink" title="Develop Web Crawling in A National Statistic Institute"></a>Develop Web Crawling in A National Statistic Institute</h1><p>**  This experiment is to crawl the home page of “<a href="https://data.stats.gov.cn/index.htm">National Bureau of Statistics</a>“ for the example of [Shanghai urban and rural residents income and expenditure basic information], other pages of the National Bureau of Statistics crawl in a similar way ** </p><h2 id="1-Crawler-basic-process"><a href="#1-Crawler-basic-process" class="headerlink" title="1. Crawler basic process"></a>1. Crawler basic process</h2><ol><li>initiate a request: launch a request to the target site through the http&#x2F;https library, that is, send a request, the request can contain additional information such as headers, waiting for the server to respond</li><li>get the corresponding content: if the server can respond normally, it will get a response, the content of the response is the content of the page to be obtained, the type may be HTML, json string, binary data (such as pictures and videos) and other types</li><li>parsing content: the content may be HTML, you can use regular expressions, web parsing library to parse, may be json, can be directly converted to json objects, may be binary data, you can do to save or further processing<br>** (The parsed content of this experiment is json)** </li><li>save data: can be saved as text, can also be saved to the database, or a specific format file</li></ol><h2 id="2-Open-the-web-page-and-analyze"><a href="#2-Open-the-web-page-and-analyze" class="headerlink" title="2. Open the web page and analyze"></a>2. Open the web page and analyze</h2><p>The website of the National Bureau of Statistics is very strange, it is obviously https but it warns of insecurity, the first time the interface is opened as follows (I use Google Chrome)</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/1.jpg"></p><p>Click on “Advanced” - “Continue to” to enter the home page</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/2.jpg"></p><p>Select “Quarterly Data” - “Quarterly Data by Province”</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/3.jpg"></p><p>Select “People’s Life” - “Urban and Rural Income and Expenditure”</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/4.jpg"></p><p>Change the region to “Shanghai”</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/5.jpg"></p><p>Press F12 to enter browser debugging mode</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/6.jpg"></p><p>Refresh and re-fetch the page information, find easyquery.htm?m&#x3D;Query Data&amp;dbc… file. You can check the “XHR” filter first to narrow the search</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/7.jpg"></p><p>How can we make sure that this file contains the data we are looking for? By clicking on the “response” panel and dragging the slider to the right, you can see that the table data corresponds to each other (but the data does not appear consecutively)</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/8.jpg"></p><p>** Note: here data and strdata look the same, but the actual format is not the same, data is int or double format, strdata is str format, this table has some empty data lines, string format is convenient to do judgment, string to digital use eval () ** </p><h2 id="3-Full-code-and-parsing"><a href="#3-Full-code-and-parsing" class="headerlink" title="3. Full code and parsing"></a>3. Full code and parsing</h2><p>** Note: the missing libraries can be installed at the command line using the pip command, such as the lack of requests library, you can enter the command at the command line ** </p><p>&#96;&#96;&#96;pip install requests&#96;&#96;</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib3 </span><br><span class="line"></span><br><span class="line"><span class="comment"># use urllib3.disable_warnings() with SSL authentication turned off (verify=False)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Disable secure request warnings for requests</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests <span class="comment"># Use Requests to send network requests</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time <span class="comment"># used to get timestamp (calculate current time for web validation)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json <span class="comment"># Process json files</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># Process arrays</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># np.array() to pd.DataFrame format, then use to_excel() to write to excel tables</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get millisecond timestamp for web validation</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getTime</span>():</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">int</span>(<span class="built_in">round</span>(time.time() * <span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># data preprocessing, get the srdata elements (data) wrapped in layers in a json list</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getList</span>(<span class="params">length</span>):</span><br><span class="line"></span><br><span class="line">  <span class="type">List</span>=[]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(length):</span><br><span class="line"></span><br><span class="line">temp = js[<span class="string">&#x27;returndata&#x27;</span>][<span class="string">&#x27;datanodes&#x27;</span>][i][<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;strdata&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># urban and rural residents income and expenditure list, the original site has a year-on-year growth data is empty, if you directly use eval() will report an error, you need to determine first</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(<span class="built_in">len</span>(temp)! =<span class="number">0</span>):</span><br><span class="line"></span><br><span class="line"><span class="comment"># eval() number to string</span></span><br><span class="line"></span><br><span class="line"><span class="type">List</span>.append(<span class="built_in">eval</span>(temp))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="type">List</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">  <span class="comment"># request target URL (link? preceded by something)</span></span><br><span class="line"></span><br><span class="line">  url=<span class="string">&#x27;https://data.stats.gov.cn/easyquery.htm&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># request headers, User-Agent: used to prove you are a browser, just meet a certain format, not necessarily the same as your own browser</span></span><br><span class="line"></span><br><span class="line">  headers=&#123;<span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0(Windows;U;Windows NT6.1;en-US;rv:1.9.1.6) Geko/20091201 Firefox/3.5.6&#x27;</span>&#125;<span class="comment"># browser agent</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Construct parameter key-value pairs, with specific values obtained from the page structure parameters</span></span><br><span class="line"></span><br><span class="line">  key=&#123;&#125;</span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;m&#x27;</span>]=<span class="string">&#x27;QueryData&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;dbcode&#x27;</span>]=<span class="string">&#x27;fsjd&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;rowcode&#x27;</span>]=<span class="string">&#x27;zb&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;colcode&#x27;</span>]=<span class="string">&#x27;sj&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;wds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;: &quot;reg&quot;, &quot;valuecode&quot;: &quot;310000&quot;&#125;]&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;k1&#x27;</span>]=<span class="built_in">str</span>(getTime()) </span><br><span class="line"></span><br><span class="line">  <span class="comment"># &quot;wdcode&quot;: &quot;reg&quot; region field</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Shanghai 310000 </span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;dfwds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;: &quot;zb&quot;, &quot;valuecode&quot;: &quot;A0300&quot;&#125;,&#123;&quot;wdcode&quot;: &quot;sj&quot;, &quot;valuecode&quot;: &quot;LAST6&quot;&#125;]&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># &quot;wdcode&quot;: &quot;zb&quot; select which entry on the left, &quot;wdcode&quot;: &quot;sj&quot; option box select &quot;LAST 6 QUARTERS&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Disable security request warnings</span></span><br><span class="line"></span><br><span class="line">  requests.packages.urllib3.disable_warnings()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Send the request, using the post method, here using the previous custom header and parameters</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># ! verify=False, the NSO switched to https protocol in the second half of 20 years, if not add the code can not pass SSL verification</span></span><br><span class="line"></span><br><span class="line">  r = requests.post(url, headers=headers, params=key,verify=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Use the json library loads function to parse the r.text string into a dict dictionary format and store it in js</span></span><br><span class="line"></span><br><span class="line">  js = json.loads(r.text)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># get the required data of a one-dimensional array, using np.array().reshape() to organize into two-dimensional arrays</span></span><br><span class="line"></span><br><span class="line">  length=<span class="built_in">len</span>(js[<span class="string">&#x27;returndata&#x27;</span>][<span class="string">&#x27;datanodes&#x27;</span>])</span><br><span class="line"></span><br><span class="line">  res=getList(length)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Total data divided into 6 rows of format</span></span><br><span class="line"></span><br><span class="line">  array=np.array(res).reshape(<span class="built_in">len</span>(res)//<span class="number">6</span>,<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># np.array() is converted to pd.DataFrame format, the subsequent can use to_excel() to write directly to excel tables</span></span><br><span class="line"></span><br><span class="line">  df_shanghai=pd.DataFrame(array)</span><br><span class="line"></span><br><span class="line">  df_shanghai.columns=[<span class="string">&#x27;2020 Q3&#x27;</span>,<span class="string">&#x27;2020 Q2&#x27;</span>,<span class="string">&#x27;2020 Q1&#x27;</span>,<span class="string">&#x27;2019 Q4&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;2019 third quarter&#x27;</span>,<span class="string">&#x27;2019 second quarter&#x27;</span>]</span><br><span class="line"></span><br><span class="line">  df_shanghai.index=[<span class="string">&#x27;Cumulative value of per capita disposable income of residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita disposable income of urban residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita disposable income of rural residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita consumption expenditure of residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita consumption expenditure of urban residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita consumption expenditure of rural residents (yuan)&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="built_in">print</span>(df_shanghai)</span><br></pre></td></tr></table></figure><p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/9.jpg"></p><h2 id="4-Partial-code-description"><a href="#4-Partial-code-description" class="headerlink" title="4. Partial code description"></a>4. Partial code description</h2><h3 id="data-extraction"><a href="#data-extraction" class="headerlink" title="data extraction"></a>data extraction</h3><p>Getting the data in the table requires first analyzing the extracted js file, which prints the following.</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/10.jpg"></p><p>Strip the five layers of the list layer by layer to get the required srdata</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/11.jpg"></p><h3 id="Request-website"><a href="#Request-website" class="headerlink" title="Request website"></a>Request website</h3><p>Request target URL (‘’?’’ preceded by something)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">url=<span class="string">&#x27;https://data.stats.gov.cn/easyquery.htm&#x27;</span></span><br></pre></td></tr></table></figure><p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/12.jpg"></p><p>Request header, User-Agent: used to prove that you are a browser, just meet a certain format, not necessarily the same as your own browser</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">headers=&#123;<span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0(Windows;U;Windows NT6.1;en-US;rv:1.9.1.6) Geko/20091201 Firefox/3.5.6&#x27;</span>&#125;<span class="comment">#browser agent</span></span><br></pre></td></tr></table></figure><p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/13.jpg"></p><p>Construct the parameter key-value pairs, the following parameters will be concatenated with &amp; and placed in the ‘’?’’ of the link followed by</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">key=&#123;&#125;</span><br><span class="line">key[<span class="string">&#x27;m&#x27;</span>]=<span class="string">&#x27;QueryData&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;dbcode&#x27;</span>]=<span class="string">&#x27;fsjd&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;rowcode&#x27;</span>]=<span class="string">&#x27;zb&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;colcode&#x27;</span>]=<span class="string">&#x27;sj&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;wds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;: &quot;reg&quot;, &quot;valuecode&quot;: &quot;310000&quot;&#125;]&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;k1&#x27;</span>]=<span class="built_in">str</span>(getTime())  </span><br><span class="line">key[<span class="string">&#x27;dfwds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;: &quot;zb&quot;, &quot;valuecode&quot;: &quot;A0300&quot;&#125;,&#123;&quot;wdcode&quot;: &quot;sj&quot;, &quot;valuecode&quot;: &quot;LAST6&quot;&#125;]&#x27;</span></span><br></pre></td></tr></table></figure><p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/14.jpg"></p><p>Some of the parameters can be seen in the position shown below, some of them are not shown by default, if you need to show the same page, you need to select the corresponding option in the option box</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/15.jpg"></p><h2 id="5-Save-data-to-excel-sheet"><a href="#5-Save-data-to-excel-sheet" class="headerlink" title="5. Save data to excel sheet"></a>5. Save data to excel sheet</h2><p>The data crawled by the crawler is now stored in panda.dataframe format, and can be saved directly in an excel table using the to_excel() function</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># write object for this Excel workbook, use this method to save multiple worksheets</span></span><br><span class="line">    write = pd.ExcelWriter(<span class="string">&#x27;F:/Ivory_Tower/norm/provincial quarterly data_urban and rural residents income and expenditure.xls&#x27;</span>) <span class="comment"># The path can be set by yourself, there is no such file will create one on its own, if it exists, write will overwrite the original content</span></span><br><span class="line">    df_shanghai.to_excel(write,sheet_name=<span class="string">&#x27;Shanghai&#x27;</span>)</span><br><span class="line">    <span class="comment"># If you climb multiple provinces, you can write to multiple worksheets and must add save() to save the data</span></span><br><span class="line">    write.save()</span><br></pre></td></tr></table></figure><p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/16.jpg"></p><h2 id="6-Table-optimization-optional"><a href="#6-Table-optimization-optional" class="headerlink" title="6. Table optimization (optional)"></a>6. Table optimization (optional)</h2><p>You can optimize the table format with the help of python code, as shown above the results are not satisfactory, at least the need to automatically adjust the column width.</p><p>Here I use xlwings library, you need to first download the corresponding library in the command line</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install xlwings</span><br><span class="line">pip install pywin32</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Use the xlwings library to edit and organize Excel tables with python</span></span><br><span class="line"><span class="keyword">import</span> xlwings <span class="keyword">as</span> xw</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app=xw.App(visible=<span class="literal">False</span>,add_book=<span class="literal">False</span>) <span class="comment"># process is not visible, no new worksheet is added</span></span><br><span class="line">    wb=app.books.<span class="built_in">open</span>(<span class="string">r&#x27;F:/Ivory_Tower/norm/province_quarterly_income_and_expense_of_urban_rural_residents.xls&#x27;</span>)</span><br><span class="line">    <span class="comment"># wb is the new workbook (workbook)</span></span><br><span class="line">    <span class="comment"># For each of the 8 worksheets, do the following</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>): </span><br><span class="line">        rng=wb.sheets[i].<span class="built_in">range</span>(<span class="string">&#x27;A1:H20&#x27;</span>) <span class="comment"># select these cells</span></span><br><span class="line">        rng.api.HorizontalAlignment = -<span class="number">4108</span> <span class="comment"># center the text horizontally</span></span><br><span class="line">        rng.autofit() <span class="comment"># automatically adjust the row height and column width</span></span><br><span class="line">    wb.save()</span><br><span class="line">    wb.close()</span><br><span class="line">    app.quit()</span><br></pre></td></tr></table></figure><p>Run the code, you can get the following effect (subsequently crawled some other provinces, modify the corresponding parameters at the key can be)</p><p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/17.jpg"></p><h2 id="7-References"><a href="#7-References" class="headerlink" title="7. References"></a>7. References</h2><p>The history of super detailed python crawl the National Bureau of Statistics data: <a href="https://blog.csdn.net/qq_41988893/article/details/103017854">https://blog.csdn.net/qq_41988893/article/details/103017854</a></p><p>If you report a variety of other inexplicable errors, you can comment or private letter to ask ~</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Develop-Web-Crawling-in-A-National-Statistic-Institute&quot;&gt;&lt;a href=&quot;#Develop-Web-Crawling-in-A-National-Statistic-Institute&quot; class=&quot;hea</summary>
      
    
    
    
    <category term="project" scheme="https://serika-onoe.github.io/en/categories/project/"/>
    
    
    <category term="python" scheme="https://serika-onoe.github.io/en/tags/python/"/>
    
    <category term="crawler" scheme="https://serika-onoe.github.io/en/tags/crawler/"/>
    
  </entry>
  
  <entry>
    <title>In-game Card Draw Mechanism Summary</title>
    <link href="https://serika-onoe.github.io/en/2020/09/06/2022-12-09-In-game-Card-Draw-Mechanism-Summary/"/>
    <id>https://serika-onoe.github.io/en/2020/09/06/2022-12-09-In-game-Card-Draw-Mechanism-Summary/</id>
    <published>2020-09-06T03:00:00.000Z</published>
    <updated>2022-12-12T14:42:09.150Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Write-in-front"><a href="#Write-in-front" class="headerlink" title="Write in front"></a>Write in front</h2><p>Card games are very good at carrying the core element of acg - “character”, card draws have a great positive effect on inventory currency consumption and new currency, and players who participated in card draws also account for a high percentage of rechargeable users. Card draw is indeed a very important payment point at the moment</p><p>But I know that “Xuan does not change the wrong, krypton can change the life”, and because it is a light player and do not want to charge money to become stronger, so the card game is not played, Yin Yang Shi, Tomorrow’s Ark, sword and expedition are slightly contact, and each game has its own card draw probability.</p><p>The SSR is about 1%, and the probability of the sword and expedition is about 4.8%, but for the sake of user experience, the most important thing is not to let the time players open up the gap of RMB players, not to violate the principle of big R crush small R, so the so-called random is basically pseudo-random.</p><p>The pure dry goods, in order not to affect the reading will not put the picture, the following introduction of some common card draw mechanism.</p><h3 id="①-Guarantee-mechanism"><a href="#①-Guarantee-mechanism" class="headerlink" title="① Guarantee mechanism"></a>① Guarantee mechanism</h3><p>This is the simplest and most common mechanism, such as the “King of Glory”, the number of purchases reached 361 times, the probability of glory crystal output is 100%. The two guaranteed mechanisms of “Sword and Expedition”, 30 draws must be purple card, in the same card pool cumulative draw 30 times to get a purple card hero whether it is a single draw or continuous draw, as long as the number reaches that must be purple card.</p><p>There is also a guaranteed mechanism is 10 consecutive draws must be a rare or elite level hero, and 30 draws is not the same place is only applicable to ten consecutive draws and not applicable to ten single draws.</p><p>The guarantee mechanism ensures the ultimate player experience</p><h3 id="②-Metaphysical-lottery-method"><a href="#②-Metaphysical-lottery-method" class="headerlink" title="② Metaphysical lottery method"></a>② Metaphysical lottery method</h3><p>In some card-drawing games it is used for certain purposes, probably because the game developers sometimes refer to other data when writing the card-drawing procedure, and then add certain algorithms to decide which card to draw, which is where the player metaphysics comes from.</p><p>If the referenced data is the current system time, then there is a possibility that “the card draw rate is high at a certain time in the morning, or the rate is high in the first 10 minutes of every hour”.</p><p>Although the result is decided in the server at the moment you draw the card, it has nothing to do with what pattern is drawn or which method is used, but the game makers are still happy to leave a player-led process, so that players believe that it is the card drawing process that affects the result of card drawing, and the process is full of rituals.</p><h3 id="③Probability-increment-I-don’t-know-if-the-industry-is-called-water-level"><a href="#③Probability-increment-I-don’t-know-if-the-industry-is-called-water-level" class="headerlink" title="③Probability increment (I don’t know if the industry is called water level)"></a>③Probability increment (I don’t know if the industry is called water level)</h3><p>Incremental probability method, refers to the card draw, the more times the card is drawn, the higher the burst rate of card draw method. If you have drawn before you have accumulated this value, then the probability is returned to zero.</p><p>It can keep the player’s game experience in a more balanced position.</p><h3 id="④-Prize-pool-division"><a href="#④-Prize-pool-division" class="headerlink" title="④ Prize pool division"></a>④ Prize pool division</h3><p>This method of card drawing is more complicated and is more common in games that frequently release new cards.</p><p>When a player draws, it is determined which prize pool the player enters (R,SR,SSR) and then which card the player draws in that pool. If a new card is officially added, a single pool will be created and an old card will be implicitly removed, so players will not be too concerned about the rate of old cards and will be happy to draw more new cards.</p><h3 id="⑤-Scripted-card-draw"><a href="#⑤-Scripted-card-draw" class="headerlink" title="⑤ Scripted card draw"></a>⑤ Scripted card draw</h3><p>All of the decks in Air Dangling Solitaire are already written, and each time you start a game, you pick one from the deck script.</p><p>The game “Landlord” is officially written to have multiple pairs, planes and bombs, and randomly dealt cards are likely to appear as loose cards.</p><h3 id="⑥Kryptonite-distinguishes-card-draw"><a href="#⑥Kryptonite-distinguishes-card-draw" class="headerlink" title="⑥Kryptonite distinguishes card draw"></a>⑥Kryptonite distinguishes card draw</h3><p>The original game is to recharge how much to send a lottery, and generally get very precious game props. Now a data bar will be added implicitly to calculate the amount of player recharge and divide the level to adjust the probability to improve the game experience for kryptonite players.</p><p>If a certain currency can be obtained both from in-game liver and the option to recharge, then the official can secretly set a status bar to distinguish between the activity liver and the recharge, and each time a lottery is drawn, it will identify which type of diamond is used for this lottery. If you use both types of diamonds at the same time, the default may be the one you got by recharging, and then the probability will be greater than the one you got by using the liver.</p><h3 id="⑦-Other-ways-to-play-with-card-draw-promotions"><a href="#⑦-Other-ways-to-play-with-card-draw-promotions" class="headerlink" title="⑦ Other ways to play with card draw promotions"></a>⑦ Other ways to play with card draw promotions</h3><p>A common way to show this is to enter the game and just give the player a sum of money enough for the first draw, guiding the player to do the draw and then get precious props.</p><p>Or when drawing, the system suddenly reminds you: you get a chance to buy rare props with an added time limit.</p><p>There is also a way to adjust the burst rate of different items according to the prop needs of new players. For example, if the collection set is missing that one part, it is likely to pop out when the lottery is drawn.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Write-in-front&quot;&gt;&lt;a href=&quot;#Write-in-front&quot; class=&quot;headerlink&quot; title=&quot;Write in front&quot;&gt;&lt;/a&gt;Write in front&lt;/h2&gt;&lt;p&gt;Card games are very go</summary>
      
    
    
    
    <category term="collection" scheme="https://serika-onoe.github.io/en/categories/collection/"/>
    
    
    <category term="acg" scheme="https://serika-onoe.github.io/en/tags/acg/"/>
    
    <category term="card draw" scheme="https://serika-onoe.github.io/en/tags/card-draw/"/>
    
    <category term="game" scheme="https://serika-onoe.github.io/en/tags/game/"/>
    
  </entry>
  
  <entry>
    <title>My first blog</title>
    <link href="https://serika-onoe.github.io/en/2020/02/11/2022-12-10-My-first-blog/"/>
    <id>https://serika-onoe.github.io/en/2020/02/11/2022-12-10-My-first-blog/</id>
    <published>2020-02-11T04:14:00.000Z</published>
    <updated>2022-12-12T14:43:01.233Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Why-I-make-this-blog"><a href="#Why-I-make-this-blog" class="headerlink" title="Why I make this blog"></a>Why I make this blog</h1><p>Blogging is an idea that has been brewing for a long time, and I believe that most people have been procrastinating for a long time to make this decision hh. However, besides habitual laziness, there is also the consideration that they are not confident of their technical level, after all, the big cows are very few, and most people are just hovering around the average line.</p><p>But the brain does not make decisions purely rational, but mainly based on emotion. After setting up a target and setting down a direction, the rational mind will actively rationalize the behavior.</p><p>I have summarized the following motivations as to why I started blogging on a whim.</p><ul><li><p>I have developed the habit of consulting a lot of information before I start writing, both inside and outside the classroom. I have a lot of respect and gratitude for those who have the spirit of open source, the seniors. Many times, a concise and clear conclusion, a line of highly generalized code, often rely on their own exploration to half the effort, and may even be in the knowledge of the blind (Unknown Unknown) and make unnecessary suffering, was left by the seniors in the blog article inadvertently a break, such moments simply not too much.</p></li><li><p>Evolved from a pure white to now a in many areas have some experience in the beginning of the …. For the white guy, I also hope to make up for the pit that I fell into at that time, at least to make a warning in front that there is no need for newcomers to take detours in the environment building stage, and to focus on the debugging stage of the program to solve the needs and achieve higher self-improvement efficiency.</p></li><li><p>As the saying goes: “Good memory is better than bad penmanship.” Before reading a book on how to take notes efficiently, but the paper notes are also often impossible to flip through. Nowadays, I often use my cell phone to browse many fragmented knowledge points, which are not effectively organized. The existence of blogs also has a kind of democratic supervision in it than private notes, to avoid personal cognitive bias and limitations.</p></li><li><p>I often imagine how to explain the knowledge to a novice when I study, and blogging is equivalent to instantiating and visualizing this process.</p></li></ul><h1 id="What-to-record"><a href="#What-to-record" class="headerlink" title="What to record"></a>What to record</h1><p>During my bachelor years, I learned a lot of things at the principle level in class, and I have a wide range of interests outside of class. In order to avoid the problem of making a slapdash approach, I summarize the knowledge and techniques I learned in the following areas and take the time to record them.</p><ul><li>Programming languages: C, Python, JAVA, etc.</li><li>Software installation classes: Android Studio, WordPress, etc.</li><li>Audio editing: pr, ps, au, etc.</li></ul><p>Blog update frequency try to keep in a week or two, here first for a memorial, later if you need to add changes.</p><p>There is a poem: “green hills together with the clouds and rain, the moon has been two hometowns.”</p><p>I hope the content in my blog may help you.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Why-I-make-this-blog&quot;&gt;&lt;a href=&quot;#Why-I-make-this-blog&quot; class=&quot;headerlink&quot; title=&quot;Why I make this blog&quot;&gt;&lt;/a&gt;Why I make this blog&lt;/h1&gt;&lt;</summary>
      
    
    
    
    <category term="summary" scheme="https://serika-onoe.github.io/en/categories/summary/"/>
    
    
    <category term="first" scheme="https://serika-onoe.github.io/en/tags/first/"/>
    
    <category term="introduction" scheme="https://serika-onoe.github.io/en/tags/introduction/"/>
    
  </entry>
  
</feed>
