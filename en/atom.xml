<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Kung&#39;s Blog</title>
  
  <subtitle>Welcome to my blog!</subtitle>
  <link href="https://serika-onoe.github.io/atom.xml" rel="self"/>
  
  <link href="https://serika-onoe.github.io/"/>
  <updated>2022-12-30T14:02:48.011Z</updated>
  <id>https://serika-onoe.github.io/</id>
  
  <author>
    <name>Richard KUNG</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CS231n Assignment 1 (Updating)</title>
    <link href="https://serika-onoe.github.io/2022/12/20/CS231n-Assignment-1/"/>
    <id>https://serika-onoe.github.io/2022/12/20/CS231n-Assignment-1/</id>
    <published>2022-12-20T14:49:13.000Z</published>
    <updated>2022-12-30T14:02:48.011Z</updated>
    
    <content type="html"><![CDATA[<h1 id="cs231n-assignment-1">CS231n Assignment 1</h1><p>作业1分为五个部分：KNN、SVM、Softmax classifier、2层神经网络、HigherLevel Representations: Image Features.</p><p>建议作业完成顺序：</p><ol type="1"><li>k近邻分类：knn.ipynb &amp; k_nearest_neighbor.py</li><li>svm线性分类：svm.ipynb &amp; linear_svm.py &amp;linear_classifier.py</li><li>softmax线性分类：softmax.ipynb &amp; softmax.py</li><li>两层神经网络：two_layer_net.ipynb &amp; neural_net.py</li></ol><h1 id="k-nearest-neighbor-knn">k-Nearest Neighbor (kNN)</h1><p>在knn.ipynb中，调用了k_nearest_neighbor.py文件。</p><p>k近邻分类算法步骤如下介绍：</p><ol type="1"><li>记住所有训练图像</li><li>计算测试图像与所有训练图像的距离（常用L2距离）</li><li>选择与测试图像距离最小的k张训练图像</li><li>计算这k张图像所对应的类别出现的次数，选择出现次数最多的类别记为预测类别</li></ol><h2 id="k_nearest_neighbor.py">k_nearest_neighbor.py</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">KNearestNeighbor</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; a kNN classifier with L2 distance &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">#定义一个k近邻分类器的类</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h3 id="训练">训练</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, X, y</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Train the classifier. For k-nearest neighbors this is just</span></span><br><span class="line"><span class="string">    memorizing the training data.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - X: A numpy array of shape (num_train, D) containing the training data</span></span><br><span class="line"><span class="string">      consisting of num_train samples each of dimension D.</span></span><br><span class="line"><span class="string">    - y: A numpy array of shape (N,) containing the training labels, where</span></span><br><span class="line"><span class="string">         y[i] is the label for X[i].</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">#self.X_train 是训练数据，维度是 (N,D)，训练集有N个样本，每个样本特征是D维</span></span><br><span class="line">    <span class="comment">#self.y_train 是标签，维度是（N,）,即N个训练样本对应的标签</span></span><br><span class="line">    self.X_train = X</span><br><span class="line">    self.y_train = y</span><br></pre></td></tr></table></figure><h3id="预测计算测试图像和所有训练图像的l2距离">预测：计算测试图像和所有训练图像的L2距离</h3><p>预测时首先需要计算测试样本与所有训练样本的距离,然后根据距离判断样本的类别。</p><p>计算距离需要我们实现三种方法，分别为需要双重循环，单循环，不需要循环。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X, k=<span class="number">1</span>, num_loops=<span class="number">0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Predict labels for test data using this classifier.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - X: A numpy array of shape (num_test, D) containing test data consisting</span></span><br><span class="line"><span class="string">         of num_test samples each of dimension D.</span></span><br><span class="line"><span class="string">    - k: The number of nearest neighbors that vote for the predicted labels.</span></span><br><span class="line"><span class="string">    - num_loops: Determines which implementation to use to compute distances</span></span><br><span class="line"><span class="string">      between training points and testing points.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    - y: A numpy array of shape (num_test,) containing predicted labels for the</span></span><br><span class="line"><span class="string">      test data, where y[i] is the predicted label for the test point X[i].</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> num_loops == <span class="number">0</span>:</span><br><span class="line">        dists = self.compute_distances_no_loops(X)</span><br><span class="line">    <span class="keyword">elif</span> num_loops == <span class="number">1</span>:</span><br><span class="line">        dists = self.compute_distances_one_loop(X)</span><br><span class="line">    <span class="keyword">elif</span> num_loops == <span class="number">2</span>:</span><br><span class="line">        dists = self.compute_distances_two_loops(X)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;Invalid value %d for num_loops&quot;</span> % num_loops)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> self.predict_labels(dists, k=k)</span><br></pre></td></tr></table></figure><hr /><h4 id="双重循环实现">双重循环实现</h4><p>第i个测试样本与第j个训练样本的距离<spanclass="math inline">\(dist[i,j]\)</span>等于用第i个测试图像的特征向量减去第j个训练图像的特征向量的值</p><p><spanclass="math inline">\(dist[i,j]=\sqrt{\sum_{d}(x_{test[i,d]}-x_{train[j,d]})^2}\)</span></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/dij.png" /></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_distances_two_loops</span>(<span class="params">self, X</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute the distance between each test point in X and each training point</span></span><br><span class="line"><span class="string">    in self.X_train using a nested loop over both the training data and the</span></span><br><span class="line"><span class="string">    test data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - X: A numpy array of shape (num_test, D) containing test data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]</span></span><br><span class="line"><span class="string">      is the Euclidean distance between the ith test point and the jth training</span></span><br><span class="line"><span class="string">      point.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    num_test = X.shape[<span class="number">0</span>]</span><br><span class="line">    num_train = self.X_train.shape[<span class="number">0</span>]</span><br><span class="line">    dists = np.zeros((num_test, num_train))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_test):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(num_train):</span><br><span class="line">            <span class="comment">#####################################################################</span></span><br><span class="line">            <span class="comment"># <span class="doctag">TODO:</span>                                                             #</span></span><br><span class="line">            <span class="comment"># Compute the l2 distance between the ith test point and the jth    #</span></span><br><span class="line">            <span class="comment"># training point, and store the result in dists[i, j]. You should   #</span></span><br><span class="line">            <span class="comment"># not use a loop over dimension, nor use np.linalg.norm().          #</span></span><br><span class="line">            <span class="comment">#####################################################################</span></span><br><span class="line">            <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">            dists[i][j]=np.sqrt(np.<span class="built_in">sum</span>(np.square(X[i,:]-self.X_train[j,:])))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">    <span class="keyword">return</span> dists</span><br></pre></td></tr></table></figure><hr /><h4 id="单循环实现">单循环实现</h4><p>利用numpy的broadcast机制，可以直接计算第i张测试图像与所有训练样本的距离</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/dij_single.png" /></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_distances_one_loop</span>(<span class="params">self, X</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute the distance between each test point in X and each training point</span></span><br><span class="line"><span class="string">    in self.X_train using a single loop over the test data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Input / Output: Same as compute_distances_two_loops</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    num_test = X.shape[<span class="number">0</span>]</span><br><span class="line">    num_train = self.X_train.shape[<span class="number">0</span>]</span><br><span class="line">    dists = np.zeros((num_test, num_train))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_test):</span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span>                                                               #</span></span><br><span class="line">        <span class="comment"># Compute the l2 distance between the ith test point and all training #</span></span><br><span class="line">        <span class="comment"># points, and store the result in dists[i, :].                        #</span></span><br><span class="line">        <span class="comment"># Do not use np.linalg.norm().                                        #</span></span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">        <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">        dists[i,:]=np.sqrt(np.<span class="built_in">sum</span>(np.square(X[i,:]-self.X_train),axis=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">    <span class="keyword">return</span> dists</span><br></pre></td></tr></table></figure><hr /><h4 id="无循环实现">无循环实现</h4><p>两个矩阵不能直接相减，不用循环计算距离，考虑距离公式，同时需保证最后得到的dists.shape满足(num_test,num_train)=(500,5000)</p><p><span class="math inline">\((a-b)^2=a^2+b^2-2ab\)</span></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/dij_no.png" /></p><p>注意点：</p><ol type="1"><li>np.square，返回原列表每个元素的平方值，shape不变。</li><li>np.sum(,axis=1)按列相加（横向），我之前在这个地方没想通。以np.sum(np.square(self.X_train),axis = 1)为例：</li></ol><ul><li>np.shape(self.X_train)=(5000,3072)</li><li>np.shape(np.square(self.X_train))=(5000,3072)</li><li>np.shape(np.sum(np.square(self.X_train)))=(5000,)这表示的是一个含有5000个元素的一维数组，并不是(5000,1)具有5000行的二维list。因此可以被boardcasting,(1,5000)-&gt;(500,5000)</li></ul><ol start="3" type="1"><li>transpose针对二维及以上list有效。以np.transpose([np.sum(np.square(X),axis = 1)]))为例，结合第2点可知:</li></ol><ul><li>得到的np.sum(np.square(X), axis =1)]))是一个一维数组，shape为(500,)</li><li>因此加上[]变成(1,500)</li><li>之后转置得到(500,1),因此可以被boardcasting,(500,1)-&gt;(500,5000)</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_distances_no_loops</span>(<span class="params">self, X</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute the distance between each test point in X and each training point</span></span><br><span class="line"><span class="string">    in self.X_train using no explicit loops.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Input / Output: Same as compute_distances_two_loops</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    num_test = X.shape[<span class="number">0</span>]</span><br><span class="line">    num_train = self.X_train.shape[<span class="number">0</span>]</span><br><span class="line">    dists = np.zeros((num_test, num_train))</span><br><span class="line">    <span class="comment">#########################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span>                                                                 #</span></span><br><span class="line">    <span class="comment"># Compute the l2 distance between all test points and all training      #</span></span><br><span class="line">    <span class="comment"># points without using any explicit loops, and store the result in      #</span></span><br><span class="line">    <span class="comment"># dists.                                                                #</span></span><br><span class="line">    <span class="comment">#                                                                       #</span></span><br><span class="line">    <span class="comment"># You should implement this function using only basic array operations; #</span></span><br><span class="line">    <span class="comment"># in particular you should not use functions from scipy,                #</span></span><br><span class="line">    <span class="comment"># nor use np.linalg.norm().                                             #</span></span><br><span class="line">    <span class="comment">#                                                                       #</span></span><br><span class="line">    <span class="comment"># HINT: Try to formulate the l2 distance using matrix multiplication    #</span></span><br><span class="line">    <span class="comment">#       and two broadcast sums.                                         #</span></span><br><span class="line">    <span class="comment">#########################################################################</span></span><br><span class="line">    <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">    dists = np.sqrt(-<span class="number">2</span>*np.dot(X, self.X_train.T) + np.<span class="built_in">sum</span>(np.square(self.X_train), axis = <span class="number">1</span>) + np.transpose([np.<span class="built_in">sum</span>(np.square(X), axis = <span class="number">1</span>)]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">    <span class="keyword">return</span> dists</span><br></pre></td></tr></table></figure><h3id="预测根据k个最邻近距离中的多数确定标签">预测：根据K个最邻近距离中的多数确定标签</h3><ul><li>np.argsort() 返回一个数组排好序后各元素对应的原来的位置序号</li></ul><p>Examples:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#One dimensional array:</span></span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">np.argsort(x)</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#Two-dimensional array:</span></span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">0</span>, <span class="number">3</span>], [<span class="number">2</span>, <span class="number">2</span>]])</span><br><span class="line">x</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">2</span>]])</span><br><span class="line">ind = np.argsort(x, axis=<span class="number">0</span>)  <span class="comment"># sorts along first axis (down)</span></span><br><span class="line">ind</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">0</span>]])</span><br><span class="line">np.take_along_axis(x, ind, axis=<span class="number">0</span>)  <span class="comment"># same as np.sort(x, axis=0)</span></span><br><span class="line">array([[<span class="number">0</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">3</span>]])</span><br></pre></td></tr></table></figure><ul><li>np.bincount() 计算非负整数数组中每个值的出现次数。</li></ul><p>Examples:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#[0,1,2,3,4]</span></span><br><span class="line">np.bincount(np.arange(<span class="number">5</span>))</span><br><span class="line">array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">np.bincount(np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">7</span>]))</span><br><span class="line">array([<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br></pre></td></tr></table></figure><hr /><p>需要实现两个功能</p><ol type="1"><li><p>选择与测试图像最相似（距离最小）的k张训练图像np.argsort(dists[i])函数是将dist中的i行元素从小到大排列，并得到对应的index。然后再取前k个索引（也就是得到距离最近的k张图像的索引）</p></li><li><p>计算这k张图像所对应的类别出现的次数，选择出现次数最多的类别</p></li></ol><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict_labels</span>(<span class="params">self, dists, k=<span class="number">1</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Given a matrix of distances between test points and training points,</span></span><br><span class="line"><span class="string">    predict a label for each test point.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]</span></span><br><span class="line"><span class="string">      gives the distance betwen the ith test point and the jth training point.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    - y: A numpy array of shape (num_test,) containing predicted labels for the</span></span><br><span class="line"><span class="string">      test data, where y[i] is the predicted label for the test point X[i].</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    num_test = dists.shape[<span class="number">0</span>]</span><br><span class="line">    y_pred = np.zeros(num_test)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_test):</span><br><span class="line">        <span class="comment"># A list of length k storing the labels of the k nearest neighbors to</span></span><br><span class="line">        <span class="comment"># the ith test point.</span></span><br><span class="line">        closest_y = []</span><br><span class="line">        <span class="comment">#########################################################################</span></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span>                                                                 #</span></span><br><span class="line">        <span class="comment"># Use the distance matrix to find the k nearest neighbors of the ith    #</span></span><br><span class="line">        <span class="comment"># testing point, and use self.y_train to find the labels of these       #</span></span><br><span class="line">        <span class="comment"># neighbors. Store these labels in closest_y.                           #</span></span><br><span class="line">        <span class="comment"># Hint: Look up the function numpy.argsort.                             #</span></span><br><span class="line">        <span class="comment">#########################################################################</span></span><br><span class="line">        <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">        closest_y = self.y_train[np.argsort(dists[i])[:k]]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">        <span class="comment">#########################################################################</span></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span>                                                                 #</span></span><br><span class="line">        <span class="comment"># Now that you have found the labels of the k nearest neighbors, you    #</span></span><br><span class="line">        <span class="comment"># need to find the most common label in the list closest_y of labels.   #</span></span><br><span class="line">        <span class="comment"># Store this label in y_pred[i]. Break ties by choosing the smaller     #</span></span><br><span class="line">        <span class="comment"># label.                                                                #</span></span><br><span class="line">        <span class="comment">#########################################################################</span></span><br><span class="line">        <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">        y_pred[i] = np.argmax(np.bincount(closest_y))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="knn.ipynb">knn.ipynb</h2><p>讨论knn中k的取值问题</p><ul><li>np.array_split() 将一个数组拆分为多个子数组，可以大小不等。</li></ul><p>Examples:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.arange(<span class="number">8.0</span>)</span><br><span class="line">np.array_split(x, <span class="number">3</span>)</span><br><span class="line">[array([<span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>]), array([<span class="number">3.</span>,  <span class="number">4.</span>,  <span class="number">5.</span>]), array([<span class="number">6.</span>,  <span class="number">7.</span>])]</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">9</span>)</span><br><span class="line">np.array_split(x, <span class="number">4</span>)</span><br><span class="line">[array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]), array([<span class="number">3</span>, <span class="number">4</span>]), array([<span class="number">5</span>, <span class="number">6</span>]), array([<span class="number">7</span>, <span class="number">8</span>])]</span><br></pre></td></tr></table></figure><ul><li>dictionary.setdefault(keyname, value)返回具有指定键的项目的值。</li></ul><p>Examples:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">car = &#123;</span><br><span class="line">  <span class="string">&quot;brand&quot;</span>: <span class="string">&quot;Ford&quot;</span>,</span><br><span class="line">  <span class="string">&quot;model&quot;</span>: <span class="string">&quot;Mustang&quot;</span>,</span><br><span class="line">  <span class="string">&quot;year&quot;</span>: <span class="number">1964</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">x = car.setdefault(<span class="string">&quot;color&quot;</span>, <span class="string">&quot;White&quot;</span>)</span><br></pre></td></tr></table></figure><ul><li>hstack() 按列顺序(横向)把数组给堆叠起来</li></ul><p>Examples:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">b=[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line"><span class="built_in">print</span>(np.hstack((a,b)))</span><br><span class="line"><span class="comment">#[1 2 3 4 5 6 ]</span></span><br><span class="line"></span><br><span class="line">a=[[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>]]</span><br><span class="line">b=[[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>]]</span><br><span class="line">c=[[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>]]</span><br><span class="line">d=[[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>]]</span><br><span class="line"><span class="built_in">print</span>(np.hstack((a,b,c,d)))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[[1 1 1 1]</span></span><br><span class="line"><span class="string"> [2 2 2 2]</span></span><br><span class="line"><span class="string"> [3 3 3 3]]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><hr /><p>knn需要计算这k张图像所对应的类别出现的次数，选择出现次数最多的类别，那么问题来了，k应该取几效果会比较好呢？</p><p>这需要做两个任务：</p><ol type="1"><li>划分训练集</li><li>交叉验证</li></ol><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num_folds = <span class="number">5</span></span><br><span class="line">k_choices = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">8</span>, <span class="number">10</span>, <span class="number">12</span>, <span class="number">15</span>, <span class="number">20</span>, <span class="number">50</span>, <span class="number">100</span>]</span><br><span class="line"></span><br><span class="line">X_train_folds = []</span><br><span class="line">y_train_folds = []</span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span>                                                                        #</span></span><br><span class="line"><span class="comment"># Split up the training data into folds. After splitting, X_train_folds and    #</span></span><br><span class="line"><span class="comment"># y_train_folds should each be lists of length num_folds, where                #</span></span><br><span class="line"><span class="comment"># y_train_folds[i] is the label vector for the points in X_train_folds[i].     #</span></span><br><span class="line"><span class="comment"># Hint: Look up the numpy array_split function.                                #</span></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">X_train_folds = np.array_split(X_train,num_folds)</span><br><span class="line">y_train_folds = np.array_split(y_train,num_folds)</span><br><span class="line"></span><br><span class="line"><span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># A dictionary holding the accuracies for different values of k that we find</span></span><br><span class="line"><span class="comment"># when running cross-validation. After running cross-validation,</span></span><br><span class="line"><span class="comment"># k_to_accuracies[k] should be a list of length num_folds giving the different</span></span><br><span class="line"><span class="comment"># accuracy values that we found when using that value of k.</span></span><br><span class="line">k_to_accuracies = &#123;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span>                                                                        #</span></span><br><span class="line"><span class="comment"># Perform k-fold cross validation to find the best value of k. For each        #</span></span><br><span class="line"><span class="comment"># possible value of k, run the k-nearest-neighbor algorithm num_folds times,   #</span></span><br><span class="line"><span class="comment"># where in each case you use all but one of the folds as training data and the #</span></span><br><span class="line"><span class="comment"># last fold as a validation set. Store the accuracies for all fold and all     #</span></span><br><span class="line"><span class="comment"># values of k in the k_to_accuracies dictionary.                               #</span></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> k_choices:</span><br><span class="line">    k_to_accuracies.setdefault(k, [])</span><br><span class="line">    <span class="comment">#print(k_to_accuracies)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_folds):</span><br><span class="line">    classifier = KNearestNeighbor()</span><br><span class="line">    X_val_train = np.vstack(X_train_folds[<span class="number">0</span>:i] + X_train_folds[i+<span class="number">1</span>:])</span><br><span class="line">    y_val_train = np.hstack(y_train_folds[<span class="number">0</span>:i] + y_train_folds[i+<span class="number">1</span>:])</span><br><span class="line">    <span class="comment">#print(X_val_train, y_val_train)</span></span><br><span class="line">    classifier.train(X_val_train, y_val_train)</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> k_choices:</span><br><span class="line">        y_val_pred = classifier.predict(X_train_folds[i], k)</span><br><span class="line">        num_correct = np.<span class="built_in">sum</span>(y_val_pred == y_train_folds[i])</span><br><span class="line">        accuracy = <span class="built_in">float</span>(num_correct) / <span class="built_in">len</span>(y_val_pred)</span><br><span class="line">        k_to_accuracies[k] += [accuracy]</span><br><span class="line">        <span class="comment">#print(k,k_to_accuracies[k])</span></span><br><span class="line">    <span class="comment">#print(k_to_accuracies)</span></span><br><span class="line"><span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Print out the computed accuracies</span></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">sorted</span>(k_to_accuracies):</span><br><span class="line">    <span class="keyword">for</span> accuracy <span class="keyword">in</span> k_to_accuracies[k]:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;k = %d, accuracy = %f&#x27;</span> % (k, accuracy))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#OUTPUT</span></span><br><span class="line">    k = <span class="number">1</span>, accuracy = <span class="number">0.263000</span></span><br><span class="line">    k = <span class="number">1</span>, accuracy = <span class="number">0.257000</span> </span><br><span class="line">    k = <span class="number">1</span>, accuracy = <span class="number">0.264000</span></span><br><span class="line">    k = <span class="number">1</span>, accuracy = <span class="number">0.278000</span></span><br><span class="line">    k = <span class="number">1</span>, accuracy = <span class="number">0.266000</span></span><br><span class="line">    k = <span class="number">3</span>, accuracy = <span class="number">0.239000</span></span><br><span class="line">    k = <span class="number">3</span>, accuracy = <span class="number">0.249000</span></span><br><span class="line">    k = <span class="number">3</span>, accuracy = <span class="number">0.240000</span></span><br><span class="line">    k = <span class="number">3</span>, accuracy = <span class="number">0.266000</span></span><br><span class="line">    k = <span class="number">3</span>, accuracy = <span class="number">0.254000</span></span><br><span class="line">    k = <span class="number">5</span>, accuracy = <span class="number">0.248000</span></span><br><span class="line">    k = <span class="number">5</span>, accuracy = <span class="number">0.266000</span></span><br><span class="line">    k = <span class="number">5</span>, accuracy = <span class="number">0.280000</span></span><br><span class="line">    k = <span class="number">5</span>, accuracy = <span class="number">0.292000</span></span><br><span class="line">    k = <span class="number">5</span>, accuracy = <span class="number">0.280000</span></span><br><span class="line">    k = <span class="number">8</span>, accuracy = <span class="number">0.262000</span></span><br><span class="line">    k = <span class="number">8</span>, accuracy = <span class="number">0.282000</span></span><br><span class="line">    k = <span class="number">8</span>, accuracy = <span class="number">0.273000</span></span><br><span class="line">    k = <span class="number">8</span>, accuracy = <span class="number">0.290000</span></span><br><span class="line">    k = <span class="number">8</span>, accuracy = <span class="number">0.273000</span></span><br><span class="line">    k = <span class="number">10</span>, accuracy = <span class="number">0.265000</span></span><br><span class="line">    k = <span class="number">10</span>, accuracy = <span class="number">0.296000</span></span><br><span class="line">    k = <span class="number">10</span>, accuracy = <span class="number">0.276000</span></span><br><span class="line">    k = <span class="number">10</span>, accuracy = <span class="number">0.284000</span></span><br><span class="line">    k = <span class="number">10</span>, accuracy = <span class="number">0.280000</span></span><br><span class="line">    k = <span class="number">12</span>, accuracy = <span class="number">0.260000</span></span><br><span class="line">    k = <span class="number">12</span>, accuracy = <span class="number">0.295000</span></span><br><span class="line">    k = <span class="number">12</span>, accuracy = <span class="number">0.279000</span></span><br><span class="line">    k = <span class="number">12</span>, accuracy = <span class="number">0.283000</span></span><br><span class="line">    k = <span class="number">12</span>, accuracy = <span class="number">0.280000</span></span><br><span class="line">    k = <span class="number">15</span>, accuracy = <span class="number">0.252000</span></span><br><span class="line">    k = <span class="number">15</span>, accuracy = <span class="number">0.289000</span></span><br><span class="line">    k = <span class="number">15</span>, accuracy = <span class="number">0.278000</span></span><br><span class="line">    k = <span class="number">15</span>, accuracy = <span class="number">0.282000</span></span><br><span class="line">    k = <span class="number">15</span>, accuracy = <span class="number">0.274000</span></span><br><span class="line">    k = <span class="number">20</span>, accuracy = <span class="number">0.270000</span></span><br><span class="line">    k = <span class="number">20</span>, accuracy = <span class="number">0.279000</span></span><br><span class="line">    k = <span class="number">20</span>, accuracy = <span class="number">0.279000</span></span><br><span class="line">    k = <span class="number">20</span>, accuracy = <span class="number">0.282000</span></span><br><span class="line">    k = <span class="number">20</span>, accuracy = <span class="number">0.285000</span></span><br><span class="line">    k = <span class="number">50</span>, accuracy = <span class="number">0.271000</span></span><br><span class="line">    k = <span class="number">50</span>, accuracy = <span class="number">0.288000</span></span><br><span class="line">    k = <span class="number">50</span>, accuracy = <span class="number">0.278000</span></span><br><span class="line">    k = <span class="number">50</span>, accuracy = <span class="number">0.269000</span></span><br><span class="line">    k = <span class="number">50</span>, accuracy = <span class="number">0.266000</span></span><br><span class="line">    k = <span class="number">100</span>, accuracy = <span class="number">0.256000</span></span><br><span class="line">    k = <span class="number">100</span>, accuracy = <span class="number">0.270000</span></span><br><span class="line">    k = <span class="number">100</span>, accuracy = <span class="number">0.263000</span></span><br><span class="line">    k = <span class="number">100</span>, accuracy = <span class="number">0.256000</span></span><br><span class="line">    k = <span class="number">100</span>, accuracy = <span class="number">0.263000</span></span><br></pre></td></tr></table></figure><p>通过这行代码可以选出最好的k值</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">best_k = k_choices[accuracies_mean.argmax()]</span><br></pre></td></tr></table></figure><hr /><h3 id="inline-question-1"><strong>Inline Question 1</strong></h3><p>Notice the structured patterns in the distance matrix, where somerows or columns are visibly brighter. (Note that with the default colorscheme black indicates low distances while white indicates highdistances.)</p><ul><li>What in the data is the cause behind the distinctly brightrows?</li><li>What causes the columns?</li></ul><p><span class="math inline">\(\color{blue}{\textit YourAnswer:}\)</span> <em>fill this in.</em></p><ol type="1"><li><p>The test image is far different from all the trainimage.</p></li><li><p>The train image is unsimilar to all the test image.</p></li></ol><hr /><h3 id="inline-question-2"><strong>Inline Question 2</strong></h3><p>We can also use other distance metrics such as L1 distance. For pixelvalues <span class="math inline">\(p_{ij}^{k}\)</span> at location <spanclass="math inline">\((i,j)\)</span> of some image <spanclass="math inline">\(I_k\)</span>,</p><p>the mean <span class="math inline">\(\mu\)</span> across all pixelsover all images is <spanclass="math display">\[\mu=\frac{1}{nhw}\sum_{k=1}^n\sum_{i=1}^{h}\sum_{j=1}^{w}p_{ij}^{(k)}\]</span>And the pixel-wise mean <span class="math inline">\(\mu_{ij}\)</span>across all images is <spanclass="math display">\[\mu_{ij}=\frac{1}{n}\sum_{k=1}^np_{ij}^{(k)}.\]</span>The general standard deviation <spanclass="math inline">\(\sigma\)</span> and pixel-wise standard deviation<span class="math inline">\(\sigma_{ij}\)</span> is definedsimilarly.</p><p>Which of the following preprocessing steps will not change theperformance of a Nearest Neighbor classifier that uses L1 distance?Select all that apply.</p><ol type="1"><li><p>Subtracting the mean <span class="math inline">\(\mu\)</span>(<spanclass="math inline">\(\tilde{p}_{ij}^{(k)}=p_{ij}^{(k)}-\mu\)</span>.)</p></li><li><p>Subtracting the per pixel mean <spanclass="math inline">\(\mu_{ij}\)</span> (<spanclass="math inline">\(\tilde{p}_{ij}^{(k)}=p_{ij}^{(k)}-\mu_{ij}\)</span>.)</p></li><li><p>Subtracting the mean <span class="math inline">\(\mu\)</span> anddividing by the standard deviation <spanclass="math inline">\(\sigma\)</span>.</p></li><li><p>Subtracting the pixel-wise mean <spanclass="math inline">\(\mu_{ij}\)</span> and dividing by the pixel-wisestandard deviation <spanclass="math inline">\(\sigma_{ij}\)</span>.</p></li><li><p>Rotating the coordinate axes of the data.</p></li></ol><p><span class="math inline">\(\color{blue}{\textit YourAnswer:}\)</span></p><p>1, 3 will not change the L1 Distance.</p><p><span class="math inline">\(\color{blue}{\textit YourExplanation:}\)</span></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/inline1.jpg" /></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/inline2.jpg" /></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/inline3.jpg" /></p><hr /><h3 id="inline-question-3"><strong>Inline Question 3</strong></h3><p>Which of the following statements about <spanclass="math inline">\(k\)</span>-Nearest Neighbor (<spanclass="math inline">\(k\)</span>-NN) are true in a classificationsetting, and for all <span class="math inline">\(k\)</span>? Select allthat apply. 1. The decision boundary of the k-NN classifier is linear.2. The training error of a 1-NN will always be lower than or equal tothat of 5-NN. 3. The test error of a 1-NN will always be lower than thatof a 5-NN. 4. The time needed to classify a test example with the k-NNclassifier grows with the size of the training set. 5. None of theabove.</p><p><span class="math inline">\(\color{blue}{\textit YourAnswer:}\)</span></p><p>2, 4.</p><p><span class="math inline">\(\color{blue}{\textit YourExplanation:}\)</span></p><ol type="1"><li><p>False. It depends on the given categories of data, if you give acategory with a circle boundary to its neighborhood, it isnon-linear.</p></li><li><p>True. In fact the training error of a 1-NN is always 0, and5-NN's lower bound is 0. It is because the nearest neighbor of test datais always going to be itself in 1-NN.</p></li><li><p>False. The value of k is thus data-dependent, that is why we needto perform cross validation to determine the best k for your intendedapplication and dataset.</p></li><li><p>True. At test, KNN needs to make a full pass through the entiredata set and sort points by distance. The time needed thus grows withthe size of the data.</p></li></ol><hr /><h2 id="knn部分参考链接">KNN部分参考链接:</h2><ol type="1"><li><p>cs231n官网: <ahref="https://cs231n.github.io/">https://cs231n.github.io/</a></p></li><li><p>cs231n作业，assignment1-knn详解（注重算法与代码的结合）: <ahref="https://blog.csdn.net/qq_24906797/article/details/89245722">https://blog.csdn.net/qq_24906797/article/details/89245722</a></p></li><li><p>cs231n assignment1 knn: <ahref="https://blog.csdn.net/SpicyCoder/article/details/94992552">https://blog.csdn.net/SpicyCoder/article/details/94992552</a></p></li><li><p>【本课程配套的代码作业讲解见置顶评论】斯坦福CS231N计算机视觉作业讲解：<ahref="https://www.bilibili.com/video/BV1t4411U78z/?spm_id_from=333.337.search-card.all.click&amp;vd_source=f0de9c6453942ba082fa767eb7aa958a">https://www.bilibili.com/video/BV1t4411U78z/?spm_id_from=333.337.search-card.all.click&amp;vd_source=f0de9c6453942ba082fa767eb7aa958a</a></p></li><li><p>CS231N作业详解零基础版： <ahref="https://www.bilibili.com/video/BV19z411b7u9/?p=6&amp;vd_source=f0de9c6453942ba082fa767eb7aa958a">https://www.bilibili.com/video/BV19z411b7u9/?p=6&amp;vd_source=f0de9c6453942ba082fa767eb7aa958a</a></p></li></ol><h1 id="support-vector-machine-svm">Support Vector Machine (SVM)</h1><p>在svm.ipynb中，调用了linear_svm.py和linear_classifier.py两个文件。</p><p>为方便理解，先介绍SVM的引入基于的几个概念：</p><ol type="1"><li><p>我们要实现一种更强大的方法来解决图像分类问题，该方法可以自然地延伸到神经网络和卷积神经网络上。这种方法主要有两部分组成：</p><ul><li><p>一个是评分函数（scorefunction），它是原始图像数据到类别分值的映射。</p></li><li><p>另一个是损失函数（lossfunction），它是用来量化预测分类标签的得分与真实标签之间一致性的。</p></li></ul><p>该方法可转化为一个最优化问题，在最优化过程中，将通过更新评分函数的参数来最小化损失函数值。从图像像素值到所属类别的评分函数（scorefunction）</p></li><li><p>该我们现在定义评分函数为<span class="math inline">\(f:R^D \toR^K\)</span>，该函数是原始图像像素到分类分值的映射。在<strong>线性分类器</strong>中，一个线性映射：<spanclass="math inline">\(f(x_i,W,b)=Wx_i+b\)</span>。在函数中，数据<spanclass="math inline">\((x_i,y_i)\)</span>是给定的，不能修改。但是我们可以调整权重矩阵<spanclass="math inline">\(W\)</span>这个参数，使得评分函数的结果与训练数据集中图像的真实类别一致，即评分函数在正确的分类的位置应当得到最高的评分（score）。</p></li><li><p>我们将使用损失函数（****Loss Function）（有时也叫代价函数****CostFunction或目标函数****Objective）来衡量我们对结果的不满意程度。直观地讲，当评分函数输出结果与真实结果之间差异越大，损失函数输出越大，反之越小。多类支持向量机（SVM）损失函数是其中一种。SVM的损失函数想要SVM在正确分类上的得分始终比不正确分类上的得分高出一个边界值Delta$ $。</p></li></ol><h2 id="svm简介">SVM简介</h2><h3 id="公式说明">公式说明</h3><p>SVM算法由两个部分组成：数据损失（dataloss），即所有样例的的平均损失L_i，以及正则化损失（regularizationloss）。完整公式如下：</p><p><imgsrc="https://camo.githubusercontent.com/19467d143a4397b56c0aaf83d66de6ba9a4615c801e5ed3f2e1272b80748e789/687474703a2f2f7a686968752e636f6d2f6571756174696f6e3f7465783d4c253344253543646973706c61797374796c652b253543756e64657262726163652537422b25354366726163253742312537442537424e25374425354373756d5f692b4c5f692537445f253742646174612b2535432b2b6c6f7373253744253242253543756e64657262726163652537422535436c616d6264612b52253238572532392537445f253742726567756c6172697a6174696f6e2b2535432b6c6f7373253744" /></p><p>将其展开完整公式是：</p><p><span class="math inline">\(L=\frac{1}{N}\sum_i\sum_{j \not=y_i}[\max(0,f(x_i;W)j-f(x_i;W){y_i}+\Delta)]+\lambda \sum_k \sum_lW^2_{k,l}\)</span></p><p>其中参数意义如下： * X(N,D),N是训练集的数据量。 *W(D,C),C代表图片分类的数量。 * y(N,) * i 是迭代第N个训练集数据 * j是第C个图片分类 * <span class="math inline">\(\lambda\)</span>正则化惩罚，添加到了损失函数里面，并用超参数<spanclass="math inline">\(\lambda\)</span>来计算其权重。该超参数无法简单确定，需要通过交叉验证来获取。引入正则化惩罚还带来很多良好的性质，其中最好的性质就是对大数值权重进行惩罚，可以提升其泛化能力，因为这就意味着没有哪个维度能够独自对于整体分值有过大的影响。</p><h3 id="注意点">注意点</h3><p>超参数在绝大多数情况下设为<spanclass="math inline">\(\Delta\)</span>=1.0都是安全的。超参数<spanclass="math inline">\(\Delta\)</span>和<spanclass="math inline">\(\lambda\)</span>看起来是两个不同的超参数，但实际上他们一起控制同一个权衡：即损失函数中的数据损失和正则化损失之间的权衡。</p><h2 id="linear_svm.py">linear_svm.py</h2><p>损失函数公式： <span class="math inline">\(L=\frac{1}{N}\sum_i\sum_{j\not= y_i}[\max(0,f(x_i;W)j-f(x_i;W){y_i}+\Delta)]+\lambda \sum_k \sum_lW^2_{k,l}\)</span></p><p>我们想通过一个方法来得到损失函数L的最小值，这里考虑使用计算W的梯度来不停的对L进行优化，这里想的就是初始化一个W，然后计算W的梯度，接着不停的迭代W，直到收敛或者达到迭代次数。那问题就变成如何求L对于W的梯度了。</p><h3 id="循环求解">循环求解</h3><p>后面的正则项，就是<span class="math inline">\(\lambda \sum_k \sum_lW^2_{k,l}\)</span>，求导即为 <span class="math display">\[\frac{dL}{dw}(正则项)=2*\lambda*W\]</span></p><p>主要是求前面数据损失函数的梯度。那么，我们先把L给拆分一下，这样可以去掉一个求和符号<span class="math display">\[L_i=\sum_{j \not=y_i}\max(0,x_iw_j-x_iw_{y_i}+\Delta)\]</span></p><p>（1）考虑<span class="math inline">\(j \not= y_i\)</span></p><p><span class="math display">\[\begin{aligned}\frac{dL_i}{dw_j}=1(x_iw_j-x_iw_{y_i}+\Delta&gt;0) *    \begin{array}    {|c|}    x_{i1} \\    x_{i2}\\    \vdots&amp;\\    x_{iD}    \end{array}\end{aligned}\]</span> 所以得到 <span class="math display">\[\frac{dL_i}{dw_j}=1(x_iw_j-x_iw_{y_i}+\Delta&gt;0) *{x_i}\]</span></p><p>（2）考虑<span class="math inline">\(j = y_i\)</span>，则满足</p><ul><li><spanclass="math display">\[\frac{d(x_iw_j)}{dw_{y_i}}=0\]</span></li><li><spanclass="math display">\[\frac{d(-x_iw_{y_i})}{dw_{y_i}}=-x_i\]</span></li></ul><p>因此代入以下公式 <span class="math display">\[\begin{aligned}\frac{dL_i}{dw_{y_i}}=-\sum_{j \not= y_i}1(x_iw_j-x_iw_{y_i}+\Delta&gt;0) *    \begin{array}    {|c|}    x_{i1} \\    x_{i2}\\    \vdots&amp;\\    x_{iD}    \end{array}\end{aligned}\]</span></p><p>最终可以得到</p><p><span class="math display">\[\frac{dL_i}{dw_{y_i}}=-\sum_{j \not= y_i}1(x_iw_j-x_iw_{y_i}+\Delta&gt;0) * x_i\]</span></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">svm_loss_naive</span>(<span class="params">W, X, y, reg</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Structured SVM loss function, naive implementation (with loops).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs have dimension D, there are C classes, and we operate on minibatches</span></span><br><span class="line"><span class="string">    of N examples.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - W: A numpy array of shape (D, C) containing weights.</span></span><br><span class="line"><span class="string">    - X: A numpy array of shape (N, D) containing a minibatch of data.</span></span><br><span class="line"><span class="string">    - y: A numpy array of shape (N,) containing training labels; y[i] = c means</span></span><br><span class="line"><span class="string">      that X[i] has label c, where 0 &lt;= c &lt; C.</span></span><br><span class="line"><span class="string">    - reg: (float) regularization strength</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - loss as single float</span></span><br><span class="line"><span class="string">    - gradient with respect to weights W; an array of same shape as W</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    dW = np.zeros(W.shape)  <span class="comment"># initialize the gradient as zero</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute the loss and the gradient</span></span><br><span class="line">    num_classes = W.shape[<span class="number">1</span>]</span><br><span class="line">    num_train = X.shape[<span class="number">0</span>]</span><br><span class="line">    loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_train):</span><br><span class="line">        scores = X[i].dot(W)</span><br><span class="line">        correct_class_score = scores[y[i]]</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(num_classes):</span><br><span class="line">            <span class="keyword">if</span> j == y[i]:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            margin = scores[j] - correct_class_score + <span class="number">1</span>  <span class="comment"># note delta = 1</span></span><br><span class="line">            <span class="keyword">if</span> margin &gt; <span class="number">0</span>:</span><br><span class="line">                loss += margin</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Right now the loss is a sum over all training examples, but we want it</span></span><br><span class="line">    <span class="comment"># to be an average instead so we divide by num_train.</span></span><br><span class="line">    loss /= num_train</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Add regularization to the loss.</span></span><br><span class="line">    loss += reg * np.<span class="built_in">sum</span>(W * W)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span>                                                                     #</span></span><br><span class="line">    <span class="comment"># Compute the gradient of the loss function and store it dW.                #</span></span><br><span class="line">    <span class="comment"># Rather that first computing the loss and then computing the derivative,   #</span></span><br><span class="line">    <span class="comment"># it may be simpler to compute the derivative at the same time that the     #</span></span><br><span class="line">    <span class="comment"># loss is being computed. As a result you may need to modify some of the    #</span></span><br><span class="line">    <span class="comment"># code above to compute the gradient.                                       #</span></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_train):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(num_classes):</span><br><span class="line">            <span class="keyword">if</span> j == y[i]:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            margin = scores[j] - correct_class_score + <span class="number">1</span>  <span class="comment">#note delta = 1 </span></span><br><span class="line">            <span class="keyword">if</span> margin &gt; <span class="number">0</span>:</span><br><span class="line">                dW[:,j]+=X[i,:]</span><br><span class="line">                dW[:,y[i]]+=-X[i,:]</span><br><span class="line">    </span><br><span class="line">    dW /= num_train</span><br><span class="line">    dW += <span class="number">2</span>*reg*dW</span><br><span class="line">    <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss, dW</span><br></pre></td></tr></table></figure><h3 id="向量化实现">向量化实现</h3><p>第一个部分，损失函数。公式和前面基本一致，数据损失函数部分</p><p>分类正确即对应 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scores[<span class="built_in">range</span>(N),y]=<span class="number">0</span> </span><br></pre></td></tr></table></figure></p><p>分类错误即对应</p><p><span class="math display">\[L_i=\sum_{j \not=y_i}\max(0,x_iw_j-x_iw_{y_i}+\Delta)\]</span></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scores = np.dot(X,W) - scores[<span class="built_in">range</span>(N),[y]].T + <span class="number">1</span></span><br><span class="line">np.maximum(<span class="number">0</span>,scores)</span><br></pre></td></tr></table></figure><p>因为X(N,D),N是训练集的数据量。W(D,C),C代表图片分类的数量。所以一开始保证维数一致:<spanclass="math display">\[scores = X * W\]</span></p><ul><li><p>np.dot(X,W) shape: (N,C)</p></li><li><p>scores shape: (N,C)</p><ul><li>scores[range(N),[y]].T shape: (N,C) -&gt; (1,N) -&gt; (N,1)</li><li>表示选取每个图片的正确分类，给它们评分函数的相应位置置0，说明损失为0，而其他位置则需要按照SVM的公式计算损失并且和0比较大小。</li></ul></li></ul><p>后面的正则项损失函数部分，</p><p><span class="math display">\[\frac{dL}{dw}(正则项)=2*\lambda*W\]</span></p><p>二维数组的np.sum, shape是( , ) 也就是一个数值。</p><p>第二个部分，梯度求解。用到了链式法则： <span class="math display">\[\frac{dL}{dw}=\frac{dL}{dS}*\frac{dS}{dw}\]</span></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/SVMdw.png" /></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">svm_loss_vectorized</span>(<span class="params">W, X, y, reg</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Structured SVM loss function, vectorized implementation.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs and outputs are the same as svm_loss_naive.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    loss = <span class="number">0.0</span></span><br><span class="line">    dW = np.zeros(W.shape)  <span class="comment"># initialize the gradient as zero</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span>                                                                     #</span></span><br><span class="line">    <span class="comment"># Implement a vectorized version of the structured SVM loss, storing the    #</span></span><br><span class="line">    <span class="comment"># result in loss.                                                           #</span></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">    N=<span class="built_in">len</span>(y)</span><br><span class="line">    scores = np.dot(X,W)</span><br><span class="line">    scores -= scores[<span class="built_in">range</span>(N),[y]].T</span><br><span class="line">    scores += <span class="number">1</span></span><br><span class="line">    scores[<span class="built_in">range</span>(N),y]=<span class="number">0</span></span><br><span class="line">    margin = np.maximum(<span class="number">0</span>,scores)</span><br><span class="line">    loss = np.<span class="built_in">sum</span>(margin) / N + reg * np.<span class="built_in">sum</span>(np.square(W)) </span><br><span class="line"></span><br><span class="line">    <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span>                                                                     #</span></span><br><span class="line">    <span class="comment"># Implement a vectorized version of the gradient for the structured SVM     #</span></span><br><span class="line">    <span class="comment"># loss, storing the result in dW.                                           #</span></span><br><span class="line">    <span class="comment">#                                                                           #</span></span><br><span class="line">    <span class="comment"># Hint: Instead of computing the gradient from scratch, it may be easier    #</span></span><br><span class="line">    <span class="comment"># to reuse some of the intermediate values that you used to compute the     #</span></span><br><span class="line">    <span class="comment"># loss.                                                                     #</span></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">    ds = np.zeros_like(margin)</span><br><span class="line">    ds[margin&gt;<span class="number">0</span>]=<span class="number">1</span></span><br><span class="line">    ds[<span class="built_in">range</span>(N),y]-=np.<span class="built_in">sum</span>(ds,axis=<span class="number">1</span>)</span><br><span class="line">    ds /= N</span><br><span class="line">    dW = X.T.dot(ds)</span><br><span class="line">    dW += <span class="number">2</span> * reg * W</span><br><span class="line"></span><br><span class="line">    <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss, dW</span><br></pre></td></tr></table></figure><h2 id="linear_classifier.py">linear_classifier.py</h2><h3 id="训练-1">训练</h3><ul><li>np.random.choice() 从给定的一维数组生成随机样本。</li></ul><p>Examples:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#从大小为 3 的 np.arange(5) 生成均匀随机样本：</span></span><br><span class="line">np.random.choice(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">array([<span class="number">0</span>, <span class="number">3</span>, <span class="number">4</span>]) <span class="comment"># random</span></span><br><span class="line"><span class="comment">#This is equivalent to np.random.randint(0,5,3)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#从大小为 3 的 np.arange(5) 生成一个非均匀随机样本：</span></span><br><span class="line">np.random.choice(<span class="number">5</span>, <span class="number">3</span>, p=[<span class="number">0.1</span>, <span class="number">0</span>, <span class="number">0.3</span>, <span class="number">0.6</span>, <span class="number">0</span>])</span><br><span class="line">array([<span class="number">3</span>, <span class="number">3</span>, <span class="number">0</span>]) <span class="comment"># random</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#从大小为 3 的 np.arange(5) 生成一个统一的随机样本，无需替换，说明没有重复取值：</span></span><br><span class="line">np.random.choice(<span class="number">5</span>, <span class="number">3</span>, replace=<span class="literal">False</span>)</span><br><span class="line">array([<span class="number">3</span>,<span class="number">1</span>,<span class="number">0</span>]) <span class="comment"># random</span></span><br><span class="line"><span class="comment">#This is equivalent to np.random.permutation(np.arange(5))[:3]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#从大小为 3 的 np.arange(5) 生成非均匀随机样本，无需替换：</span></span><br><span class="line">np.random.choice(<span class="number">5</span>, <span class="number">3</span>, replace=<span class="literal">False</span>, p=[<span class="number">0.1</span>, <span class="number">0</span>, <span class="number">0.3</span>, <span class="number">0.6</span>, <span class="number">0</span>])</span><br><span class="line">array([<span class="number">2</span>, <span class="number">3</span>, <span class="number">0</span>]) <span class="comment"># random</span></span><br></pre></td></tr></table></figure><p>实现train函数，作用是从每一个 iteration 中选出 batch_size个训练样本投入到 SVM 中，然后再计算一次 Loss函数进行梯度下降，避免计算太频繁导致时间消耗过大。有两部分需要补全，第一个是随机选择数据，第二个是梯度下降，实现都比较简单</p><p>梯度下降公式： <imgsrc="https://math.jianshu.com/math?formula=%5Ctheta%20%3D%5Ctheta%20-%5Ceta%20%5Ccdot%20%5Ctriangledown%20_%7B%5Ctheta%20%7DJ%5Cleft%20(%20%5Ctheta%20%5Cright%20)" /></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LinearClassifier</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.W = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        X,</span></span><br><span class="line"><span class="params">        y,</span></span><br><span class="line"><span class="params">        learning_rate=<span class="number">1e-3</span>,</span></span><br><span class="line"><span class="params">        reg=<span class="number">1e-5</span>,</span></span><br><span class="line"><span class="params">        num_iters=<span class="number">100</span>,</span></span><br><span class="line"><span class="params">        batch_size=<span class="number">200</span>,</span></span><br><span class="line"><span class="params">        verbose=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Train this linear classifier using stochastic gradient descent.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Inputs:</span></span><br><span class="line"><span class="string">        - X: A numpy array of shape (N, D) containing training data; there are N</span></span><br><span class="line"><span class="string">          training samples each of dimension D.</span></span><br><span class="line"><span class="string">        - y: A numpy array of shape (N,) containing training labels; y[i] = c</span></span><br><span class="line"><span class="string">          means that X[i] has label 0 &lt;= c &lt; C for C classes.</span></span><br><span class="line"><span class="string">        - learning_rate: (float) learning rate for optimization.</span></span><br><span class="line"><span class="string">        - reg: (float) regularization strength.</span></span><br><span class="line"><span class="string">        - num_iters: (integer) number of steps to take when optimizing</span></span><br><span class="line"><span class="string">        - batch_size: (integer) number of training examples to use at each step.</span></span><br><span class="line"><span class="string">        - verbose: (boolean) If true, print progress during optimization.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Outputs:</span></span><br><span class="line"><span class="string">        A list containing the value of the loss function at each training iteration.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        num_train, dim = X.shape</span><br><span class="line">        num_classes = (</span><br><span class="line">            np.<span class="built_in">max</span>(y) + <span class="number">1</span></span><br><span class="line">        )  <span class="comment"># assume y takes values 0...K-1 where K is number of classes</span></span><br><span class="line">        <span class="keyword">if</span> self.W <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># lazily initialize W</span></span><br><span class="line">            self.W = <span class="number">0.001</span> * np.random.randn(dim, num_classes)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Run stochastic gradient descent to optimize W</span></span><br><span class="line">        loss_history = []</span><br><span class="line">        <span class="keyword">for</span> it <span class="keyword">in</span> <span class="built_in">range</span>(num_iters):</span><br><span class="line">            X_batch = <span class="literal">None</span></span><br><span class="line">            y_batch = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">#########################################################################</span></span><br><span class="line">            <span class="comment"># <span class="doctag">TODO:</span>                                                                 #</span></span><br><span class="line">            <span class="comment"># Sample batch_size elements from the training data and their           #</span></span><br><span class="line">            <span class="comment"># corresponding labels to use in this round of gradient descent.        #</span></span><br><span class="line">            <span class="comment"># Store the data in X_batch and their corresponding labels in           #</span></span><br><span class="line">            <span class="comment"># y_batch; after sampling X_batch should have shape (batch_size, dim)   #</span></span><br><span class="line">            <span class="comment"># and y_batch should have shape (batch_size,)                           #</span></span><br><span class="line">            <span class="comment">#                                                                       #</span></span><br><span class="line">            <span class="comment"># Hint: Use np.random.choice to generate indices. Sampling with         #</span></span><br><span class="line">            <span class="comment"># replacement is faster than sampling without replacement.              #</span></span><br><span class="line">            <span class="comment">#########################################################################</span></span><br><span class="line">            <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">            bindex = np.random.choice(num_train,batch_size)</span><br><span class="line">            X_batch = X[bindex]</span><br><span class="line">            y_batch = y[bindex]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># evaluate loss and gradient</span></span><br><span class="line">            loss, grad = self.loss(X_batch, y_batch, reg)</span><br><span class="line">            loss_history.append(loss)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># perform parameter update</span></span><br><span class="line">            <span class="comment">#########################################################################</span></span><br><span class="line">            <span class="comment"># <span class="doctag">TODO:</span>                                                                 #</span></span><br><span class="line">            <span class="comment"># Update the weights using the gradient and the learning rate.          #</span></span><br><span class="line">            <span class="comment">#########################################################################</span></span><br><span class="line">            <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">            self.W = self.W - learning_rate * grad</span><br><span class="line"></span><br><span class="line">            <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> verbose <span class="keyword">and</span> it % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;iteration %d / %d: loss %f&quot;</span> % (it, num_iters, loss))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> loss_history</span><br></pre></td></tr></table></figure><h3 id="预测">预测</h3><p>调参环节，从不同的 learning rate 与 regularization strengths中选出使验证集正确率最高的组合。对每一种组合都训一遍SVM，然后计算一次正确率。不过在 learning rate较大的两个情况训练时，发生了计算溢出的情况。题面中说这是正常现象，正确率接近39%​就算成功。</p><ul><li>np.mean(y_train == y_train_pred)解释：<ul><li>mean是求平均值的意思</li><li>y_train ==y_train_pred意思就是判断训练的值和预测的值是否相同，相等返回1</li><li>将相等的全部加起来/总训练数，就是训练集的准确率了，mean这里就是统计相等的做除法算出准确率的作用</li><li>所以 np.mean(y_train == y_train_pred)就是算训练集准确率的意思</li></ul></li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Use the validation set to tune hyperparameters (regularization strength and</span></span><br><span class="line"><span class="comment"># learning rate). You should experiment with different ranges for the learning</span></span><br><span class="line"><span class="comment"># rates and regularization strengths; if you are careful you should be able to</span></span><br><span class="line"><span class="comment"># get a classification accuracy of about 0.39 (&gt; 0.385) on the validation set.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Note: you may see runtime/overflow warnings during hyper-parameter search. </span></span><br><span class="line"><span class="comment"># This may be caused by extreme values, and is not a bug.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># results is dictionary mapping tuples of the form</span></span><br><span class="line"><span class="comment"># (learning_rate, regularization_strength) to tuples of the form</span></span><br><span class="line"><span class="comment"># (training_accuracy, validation_accuracy). The accuracy is simply the fraction</span></span><br><span class="line"><span class="comment"># of data points that are correctly classified.</span></span><br><span class="line">results = &#123;&#125;</span><br><span class="line">best_val = -<span class="number">1</span>   <span class="comment"># The highest validation accuracy that we have seen so far.</span></span><br><span class="line">best_svm = <span class="literal">None</span> <span class="comment"># The LinearSVM object that achieved the highest validation rate.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span>                                                                        #</span></span><br><span class="line"><span class="comment"># Write code that chooses the best hyperparameters by tuning on the validation #</span></span><br><span class="line"><span class="comment"># set. For each combination of hyperparameters, train a linear SVM on the      #</span></span><br><span class="line"><span class="comment"># training set, compute its accuracy on the training and validation sets, and  #</span></span><br><span class="line"><span class="comment"># store these numbers in the results dictionary. In addition, store the best   #</span></span><br><span class="line"><span class="comment"># validation accuracy in best_val and the LinearSVM object that achieves this  #</span></span><br><span class="line"><span class="comment"># accuracy in best_svm.                                                        #</span></span><br><span class="line"><span class="comment">#                                                                              #</span></span><br><span class="line"><span class="comment"># Hint: You should use a small value for num_iters as you develop your         #</span></span><br><span class="line"><span class="comment"># validation code so that the SVMs don&#x27;t take much time to train; once you are #</span></span><br><span class="line"><span class="comment"># confident that your validation code works, you should rerun the validation   #</span></span><br><span class="line"><span class="comment"># code with a larger value for num_iters.                                      #</span></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Provided as a reference. You may or may not want to change these hyperparameters</span></span><br><span class="line">learning_rates = [<span class="number">1e-7</span>, <span class="number">5e-5</span>]</span><br><span class="line">regularization_strengths = [<span class="number">2.5e4</span>, <span class="number">5e4</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"><span class="keyword">for</span> rs <span class="keyword">in</span> regularization_strengths:</span><br><span class="line">  <span class="keyword">for</span> lr <span class="keyword">in</span> learning_rates:</span><br><span class="line">    svm = LinearSVM()</span><br><span class="line">    loss_hist = svm.train(X_train,y_train,lr,rs,num_iters=<span class="number">1500</span>)</span><br><span class="line">    y_train_pred = svm.predict(X_train)</span><br><span class="line">    train_accuracy = np.mean(y_train == y_train_pred)</span><br><span class="line">    y_val_pred = svm.predict(X_val)</span><br><span class="line">    val_accuracy = np.mean(y_val == y_val_pred)</span><br><span class="line">    <span class="keyword">if</span> val_accuracy &gt; best_val:</span><br><span class="line">      best_val = val_accuracy</span><br><span class="line">      best_svm = svm</span><br><span class="line">    results[(lr,rs)] = train_accuracy,val_accuracy</span><br><span class="line"><span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># Print out results.</span></span><br><span class="line"><span class="keyword">for</span> lr, reg <span class="keyword">in</span> <span class="built_in">sorted</span>(results):</span><br><span class="line">    train_accuracy, val_accuracy = results[(lr, reg)]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;lr %e reg %e train accuracy: %f val accuracy: %f&#x27;</span> % (</span><br><span class="line">                lr, reg, train_accuracy, val_accuracy))</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best validation accuracy achieved during cross-validation: %f&#x27;</span> % best_val)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#output result</span></span><br><span class="line">    lr <span class="number">1.000000e-07</span> reg <span class="number">2.500000e+04</span> train accuracy: <span class="number">0.371204</span> val accuracy: <span class="number">0.387000</span></span><br><span class="line">    lr <span class="number">1.000000e-07</span> reg <span class="number">5.000000e+04</span> train accuracy: <span class="number">0.351857</span> val accuracy: <span class="number">0.356000</span></span><br><span class="line">    lr <span class="number">5.000000e-05</span> reg <span class="number">2.500000e+04</span> train accuracy: <span class="number">0.054959</span> val accuracy: <span class="number">0.068000</span></span><br><span class="line">    lr <span class="number">5.000000e-05</span> reg <span class="number">5.000000e+04</span> train accuracy: <span class="number">0.100265</span> val accuracy: <span class="number">0.087000</span></span><br><span class="line">    best validation accuracy achieved during cross-validation: <span class="number">0.387000</span></span><br></pre></td></tr></table></figure><h3 id="inline-question-1-1"><strong>Inline Question 1</strong></h3><p>It is possible that once in a while a dimension in the gradcheck willnot match exactly. What could such a discrepancy be caused by? Is it areason for concern? What is a simple example in one dimension where agradient check could fail? How would change the margin affect of thefrequency of this happening? <em>Hint: the SVM loss function is notstrictly speaking differentiable</em></p><p><span class="math inline">\(\color{blue}{\textit YourAnswer:}\)</span></p><p>It is possible that the numerical gradient does not match the actualgradient, because the max function is non-linear, continuous at 0 butnot derivable, so the numerical gradient is inaccurate at thissituation.</p><h3 id="inline-question-2-1"><strong>Inline question 2</strong></h3><p>Describe what your visualized SVM weights look like, and offer abrief explanation for why they look the way they do.</p><p><span class="math inline">\(\color{blue}{\textit YourAnswer:}\)</span></p><p>Each class of weighted visual image shows roughly the shape of theobjects in that class as well as the background colour. When an imagehas a shape or background colour similar to that class, there is a highprobability that it will be classified as such.</p><h2 id="svm部分参考链接">SVM部分参考链接:</h2><ol type="1"><li><p>cs231n官网: <ahref="https://cs231n.github.io/">https://cs231n.github.io/</a></p></li><li><p>深度学习课程 CS231n Assignment1 SVM部分: <ahref="http://marvolo.top/archives/17202">http://marvolo.top/archives/17202</a></p></li><li><p>CS231-Multi-calss SVM的求导: <ahref="https://www.cnblogs.com/chenyusheng0803/p/10018306.html">https://www.cnblogs.com/chenyusheng0803/p/10018306.html</a></p></li><li><p>机器学习算法：梯度下降法——原理篇 <ahref="https://www.jianshu.com/p/424b7b70df7b">https://www.jianshu.com/p/424b7b70df7b</a></p></li><li><p>CS231N作业详解零基础版： <ahref="https://www.bilibili.com/video/BV19z411b7u9/?p=9&amp;vd_source=f0de9c6453942ba082fa767eb7aa958a">https://www.bilibili.com/video/BV19z411b7u9/?p=9&amp;vd_source=f0de9c6453942ba082fa767eb7aa958a</a></p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;cs231n-assignment-1&quot;&gt;CS231n Assignment 1&lt;/h1&gt;
&lt;p&gt;作业1分为五个部分：KNN、SVM、Softmax classifier、2层神经网络、Higher
Level Representations: Image F</summary>
      
    
    
    
    <category term="笔记" scheme="https://serika-onoe.github.io/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="介绍" scheme="https://serika-onoe.github.io/tags/%E4%BB%8B%E7%BB%8D/"/>
    
    <category term="深度学习" scheme="https://serika-onoe.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="cs231n" scheme="https://serika-onoe.github.io/tags/cs231n/"/>
    
    <category term="作业" scheme="https://serika-onoe.github.io/tags/%E4%BD%9C%E4%B8%9A/"/>
    
  </entry>
  
  <entry>
    <title>CS231n Assignment 1</title>
    <link href="https://serika-onoe.github.io/2022/12/20/knn/"/>
    <id>https://serika-onoe.github.io/2022/12/20/knn/</id>
    <published>2022-12-20T14:49:13.000Z</published>
    <updated>2022-12-21T09:48:02.075Z</updated>
    
    <content type="html"><![CDATA[<p>Assignment One is divided into 5 parts: KNN, SVM, Softmax, 2-layerneural network, and Higher Level Representations: Image Features.</p><h1 id="k-nearest-neighbor-knn-exercise">k-Nearest Neighbor (kNN)exercise</h1><p>In this exercise we will implement these steps and understand thebasic Image Classification pipeline, cross-validation, and gainproficiency in writing efficient, vectorized code.</p><h2 id="k_nearest_neighbor.py">k_nearest_neighbor.py</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KNearestNeighbor</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; a kNN classifier with L2 distance &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, X, y</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Train the classifier. For k-nearest neighbors this is just</span></span><br><span class="line"><span class="string">        memorizing the training data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Inputs:</span></span><br><span class="line"><span class="string">        - X: A numpy array of shape (num_train, D) containing the training data</span></span><br><span class="line"><span class="string">          consisting of num_train samples each of dimension D.</span></span><br><span class="line"><span class="string">        - y: A numpy array of shape (N,) containing the training labels, where</span></span><br><span class="line"><span class="string">             y[i] is the label for X[i].</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.X_train = X</span><br><span class="line">        self.y_train = y</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X, k=<span class="number">1</span>, num_loops=<span class="number">0</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Predict labels for test data using this classifier.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Inputs:</span></span><br><span class="line"><span class="string">        - X: A numpy array of shape (num_test, D) containing test data consisting</span></span><br><span class="line"><span class="string">             of num_test samples each of dimension D.</span></span><br><span class="line"><span class="string">        - k: The number of nearest neighbors that vote for the predicted labels.</span></span><br><span class="line"><span class="string">        - num_loops: Determines which implementation to use to compute distances</span></span><br><span class="line"><span class="string">          between training points and testing points.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">        - y: A numpy array of shape (num_test,) containing predicted labels for the</span></span><br><span class="line"><span class="string">          test data, where y[i] is the predicted label for the test point X[i].</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> num_loops == <span class="number">0</span>:</span><br><span class="line">            dists = self.compute_distances_no_loops(X)</span><br><span class="line">        <span class="keyword">elif</span> num_loops == <span class="number">1</span>:</span><br><span class="line">            dists = self.compute_distances_one_loop(X)</span><br><span class="line">        <span class="keyword">elif</span> num_loops == <span class="number">2</span>:</span><br><span class="line">            dists = self.compute_distances_two_loops(X)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;Invalid value %d for num_loops&quot;</span> % num_loops)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.predict_labels(dists, k=k)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compute_distances_two_loops</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Compute the distance between each test point in X and each training point</span></span><br><span class="line"><span class="string">        in self.X_train using a nested loop over both the training data and the</span></span><br><span class="line"><span class="string">        test data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Inputs:</span></span><br><span class="line"><span class="string">        - X: A numpy array of shape (num_test, D) containing test data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">        - dists: A numpy array of shape (num_test, num_train) where dists[i, j]</span></span><br><span class="line"><span class="string">          is the Euclidean distance between the ith test point and the jth training</span></span><br><span class="line"><span class="string">          point.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        num_test = X.shape[<span class="number">0</span>]</span><br><span class="line">        num_train = self.X_train.shape[<span class="number">0</span>]</span><br><span class="line">        dists = np.zeros((num_test, num_train))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_test):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(num_train):</span><br><span class="line">                <span class="comment">#####################################################################</span></span><br><span class="line">                <span class="comment"># <span class="doctag">TODO:</span>                                                             #</span></span><br><span class="line">                <span class="comment"># Compute the l2 distance between the ith test point and the jth    #</span></span><br><span class="line">                <span class="comment"># training point, and store the result in dists[i, j]. You should   #</span></span><br><span class="line">                <span class="comment"># not use a loop over dimension, nor use np.linalg.norm().          #</span></span><br><span class="line">                <span class="comment">#####################################################################</span></span><br><span class="line">                <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">        <span class="keyword">return</span> dists</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compute_distances_one_loop</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Compute the distance between each test point in X and each training point</span></span><br><span class="line"><span class="string">        in self.X_train using a single loop over the test data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Input / Output: Same as compute_distances_two_loops</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        num_test = X.shape[<span class="number">0</span>]</span><br><span class="line">        num_train = self.X_train.shape[<span class="number">0</span>]</span><br><span class="line">        dists = np.zeros((num_test, num_train))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_test):</span><br><span class="line">            <span class="comment">#######################################################################</span></span><br><span class="line">            <span class="comment"># <span class="doctag">TODO:</span>                                                               #</span></span><br><span class="line">            <span class="comment"># Compute the l2 distance between the ith test point and all training #</span></span><br><span class="line">            <span class="comment"># points, and store the result in dists[i, :].                        #</span></span><br><span class="line">            <span class="comment"># Do not use np.linalg.norm().                                        #</span></span><br><span class="line">            <span class="comment">#######################################################################</span></span><br><span class="line">            <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">        <span class="keyword">return</span> dists</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compute_distances_no_loops</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Compute the distance between each test point in X and each training point</span></span><br><span class="line"><span class="string">        in self.X_train using no explicit loops.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Input / Output: Same as compute_distances_two_loops</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        num_test = X.shape[<span class="number">0</span>]</span><br><span class="line">        num_train = self.X_train.shape[<span class="number">0</span>]</span><br><span class="line">        dists = np.zeros((num_test, num_train))</span><br><span class="line">        <span class="comment">#########################################################################</span></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span>                                                                 #</span></span><br><span class="line">        <span class="comment"># Compute the l2 distance between all test points and all training      #</span></span><br><span class="line">        <span class="comment"># points without using any explicit loops, and store the result in      #</span></span><br><span class="line">        <span class="comment"># dists.                                                                #</span></span><br><span class="line">        <span class="comment">#                                                                       #</span></span><br><span class="line">        <span class="comment"># You should implement this function using only basic array operations; #</span></span><br><span class="line">        <span class="comment"># in particular you should not use functions from scipy,                #</span></span><br><span class="line">        <span class="comment"># nor use np.linalg.norm().                                             #</span></span><br><span class="line">        <span class="comment">#                                                                       #</span></span><br><span class="line">        <span class="comment"># HINT: Try to formulate the l2 distance using matrix multiplication    #</span></span><br><span class="line">        <span class="comment">#       and two broadcast sums.                                         #</span></span><br><span class="line">        <span class="comment">#########################################################################</span></span><br><span class="line">        <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">        <span class="keyword">return</span> dists</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict_labels</span>(<span class="params">self, dists, k=<span class="number">1</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Given a matrix of distances between test points and training points,</span></span><br><span class="line"><span class="string">        predict a label for each test point.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Inputs:</span></span><br><span class="line"><span class="string">        - dists: A numpy array of shape (num_test, num_train) where dists[i, j]</span></span><br><span class="line"><span class="string">          gives the distance betwen the ith test point and the jth training point.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">        - y: A numpy array of shape (num_test,) containing predicted labels for the</span></span><br><span class="line"><span class="string">          test data, where y[i] is the predicted label for the test point X[i].</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        num_test = dists.shape[<span class="number">0</span>]</span><br><span class="line">        y_pred = np.zeros(num_test)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_test):</span><br><span class="line">            <span class="comment"># A list of length k storing the labels of the k nearest neighbors to</span></span><br><span class="line">            <span class="comment"># the ith test point.</span></span><br><span class="line">            closest_y = []</span><br><span class="line">            <span class="comment">#########################################################################</span></span><br><span class="line">            <span class="comment"># <span class="doctag">TODO:</span>                                                                 #</span></span><br><span class="line">            <span class="comment"># Use the distance matrix to find the k nearest neighbors of the ith    #</span></span><br><span class="line">            <span class="comment"># testing point, and use self.y_train to find the labels of these       #</span></span><br><span class="line">            <span class="comment"># neighbors. Store these labels in closest_y.                           #</span></span><br><span class="line">            <span class="comment"># Hint: Look up the function numpy.argsort.                             #</span></span><br><span class="line">            <span class="comment">#########################################################################</span></span><br><span class="line">            <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">            <span class="comment">#########################################################################</span></span><br><span class="line">            <span class="comment"># <span class="doctag">TODO:</span>                                                                 #</span></span><br><span class="line">            <span class="comment"># Now that you have found the labels of the k nearest neighbors, you    #</span></span><br><span class="line">            <span class="comment"># need to find the most common label in the list closest_y of labels.   #</span></span><br><span class="line">            <span class="comment"># Store this label in y_pred[i]. Break ties by choosing the smaller     #</span></span><br><span class="line">            <span class="comment"># label.                                                                #</span></span><br><span class="line">            <span class="comment">#########################################################################</span></span><br><span class="line">            <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="run-some-setup-code-for-this-notebook.">Run some setup code forthis notebook.</h1><p>import random import numpy as np from cs231n.data_utils importload_CIFAR10 import matplotlib.pyplot as plt</p><h1id="this-is-a-bit-of-magic-to-make-matplotlib-figures-appear-inline-in-the-notebook">Thisis a bit of magic to make matplotlib figures appear inline in thenotebook</h1><h1 id="rather-than-in-a-new-window.">rather than in a new window.</h1><p>%matplotlib inline plt.rcParams['figure.figsize'] = (10.0, 8.0) # setdefault size of plots plt.rcParams['image.interpolation'] = 'nearest'plt.rcParams['image.cmap'] = 'gray'</p><h1id="some-more-magic-so-that-the-notebook-will-reload-external-python-modules">Somemore magic so that the notebook will reload external pythonmodules;</h1><h1id="see-httpstackoverflow.comquestions1907993autoreload-of-modules-in-ipython">seehttp://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython</h1><p>%load_ext autoreload %autoreload 2 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"># Load the raw CIFAR-10 data.</span><br><span class="line">cifar10_dir = &#x27;cs231n/datasets/cifar-10-batches-py&#x27;</span><br><span class="line"></span><br><span class="line"># Cleaning up variables to prevent loading data multiple times (which may cause memory issue)</span><br><span class="line">try:</span><br><span class="line">   del X_train, y_train</span><br><span class="line">   del X_test, y_test</span><br><span class="line">   print(&#x27;Clear previously loaded data.&#x27;)</span><br><span class="line">except:</span><br><span class="line">   pass</span><br><span class="line"></span><br><span class="line">X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)</span><br><span class="line"></span><br><span class="line"># As a sanity check, we print out the size of the training and test data.</span><br><span class="line">print(&#x27;Training data shape: &#x27;, X_train.shape)</span><br><span class="line">print(&#x27;Training labels shape: &#x27;, y_train.shape)</span><br><span class="line">print(&#x27;Test data shape: &#x27;, X_test.shape)</span><br><span class="line">print(&#x27;Test labels shape: &#x27;, y_test.shape)</span><br></pre></td></tr></table></figure></p><pre><code>Training data shape:  (50000, 32, 32, 3)Training labels shape:  (50000,)Test data shape:  (10000, 32, 32, 3)Test labels shape:  (10000,)</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Visualize some examples from the dataset.</span></span><br><span class="line"><span class="comment"># We show a few examples of training images from each class.</span></span><br><span class="line">classes = [<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>]</span><br><span class="line">num_classes = <span class="built_in">len</span>(classes)</span><br><span class="line">samples_per_class = <span class="number">7</span></span><br><span class="line"><span class="keyword">for</span> y, cls <span class="keyword">in</span> <span class="built_in">enumerate</span>(classes):</span><br><span class="line">    idxs = np.flatnonzero(y_train == y)</span><br><span class="line">    idxs = np.random.choice(idxs, samples_per_class, replace=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">for</span> i, idx <span class="keyword">in</span> <span class="built_in">enumerate</span>(idxs):</span><br><span class="line">        plt_idx = i * num_classes + y + <span class="number">1</span></span><br><span class="line">        plt.subplot(samples_per_class, num_classes, plt_idx)</span><br><span class="line">        plt.imshow(X_train[idx].astype(<span class="string">&#x27;uint8&#x27;</span>))</span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">            plt.title(cls)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><img src="knn_files/knn_4_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Subsample the data for more efficient code execution in this exercise</span></span><br><span class="line">num_training = <span class="number">5000</span></span><br><span class="line">mask = <span class="built_in">list</span>(<span class="built_in">range</span>(num_training))</span><br><span class="line">X_train = X_train[mask]</span><br><span class="line">y_train = y_train[mask]</span><br><span class="line"></span><br><span class="line">num_test = <span class="number">500</span></span><br><span class="line">mask = <span class="built_in">list</span>(<span class="built_in">range</span>(num_test))</span><br><span class="line">X_test = X_test[mask]</span><br><span class="line">y_test = y_test[mask]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(X_train.shape, X_test.shape)</span><br><span class="line"><span class="comment"># Reshape the image data into rows</span></span><br><span class="line">X_train = np.reshape(X_train, (X_train.shape[<span class="number">0</span>], -<span class="number">1</span>))</span><br><span class="line">X_test = np.reshape(X_test, (X_test.shape[<span class="number">0</span>], -<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(X_train.shape, X_test.shape)</span><br></pre></td></tr></table></figure><pre><code>(5000, 32, 32, 3) (500, 32, 32, 3)(5000, 3072) (500, 3072)</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> cs231n.classifiers <span class="keyword">import</span> KNearestNeighbor</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a kNN classifier instance. </span></span><br><span class="line"><span class="comment"># Remember that training a kNN classifier is a noop: </span></span><br><span class="line"><span class="comment"># the Classifier simply remembers the data and does no further processing </span></span><br><span class="line">classifier = KNearestNeighbor()</span><br><span class="line">classifier.train(X_train, y_train)</span><br></pre></td></tr></table></figure><p>We would now like to classify the test data with the kNN classifier.Recall that we can break down this process into two steps:</p><ol type="1"><li>First we must compute the distances between all test examples andall train examples.</li><li>Given these distances, for each test example we find the k nearestexamples and have them vote for the label</li></ol><p>Lets begin with computing the distance matrix between all trainingand test examples. For example, if there are <strong>Ntr</strong>training examples and <strong>Nte</strong> test examples, this stageshould result in a <strong>Nte x Ntr</strong> matrix where each element(i,j) is the distance between the i-th test and j-th train example.</p><p><strong>Note: For the three distance computations that we require youto implement in this notebook, you may not use the np.linalg.norm()function that numpy provides.</strong></p><p>First, open <code>cs231n/classifiers/k_nearest_neighbor.py</code> andimplement the function <code>compute_distances_two_loops</code> thatuses a (very inefficient) double loop over all pairs of (test, train)examples and computes the distance matrix one element at a time.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Open cs231n/classifiers/k_nearest_neighbor.py and implement</span></span><br><span class="line"><span class="comment"># compute_distances_two_loops.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Test your implementation:</span></span><br><span class="line">dists = classifier.compute_distances_two_loops(X_test)</span><br><span class="line"><span class="built_in">print</span>(dists.shape)</span><br></pre></td></tr></table></figure><pre><code>(500, 5000)</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># We can visualize the distance matrix: each row is a single test example and</span></span><br><span class="line"><span class="comment"># its distances to training examples</span></span><br><span class="line">plt.imshow(dists, interpolation=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><img src="knn_files/knn_9_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption></figure><p><strong>Inline Question 1</strong></p><p>Notice the structured patterns in the distance matrix, where somerows or columns are visibly brighter. (Note that with the default colorscheme black indicates low distances while white indicates highdistances.)</p><ul><li>What in the data is the cause behind the distinctly brightrows?</li><li>What causes the columns?</li></ul><p><span class="math inline">\(\color{blue}{\textit YourAnswer:}\)</span> <em>fill this in.</em></p><ol type="1"><li><p>The test image is far different from all the trainimage.</p></li><li><p>The train image is unsimilar to all the test image.</p></li></ol><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Now implement the function predict_labels and run the code below:</span></span><br><span class="line"><span class="comment"># We use k = 1 (which is Nearest Neighbor).</span></span><br><span class="line">y_test_pred = classifier.predict_labels(dists, k=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute and print the fraction of correctly predicted examples</span></span><br><span class="line">num_correct = np.<span class="built_in">sum</span>(y_test_pred == y_test)</span><br><span class="line">accuracy = <span class="built_in">float</span>(num_correct) / num_test</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Got %d / %d correct =&gt; accuracy: %f&#x27;</span> % (num_correct, num_test, accuracy))</span><br></pre></td></tr></table></figure><pre><code>Got 137 / 500 correct =&gt; accuracy: 0.274000</code></pre><p>You should expect to see approximately <code>27%</code> accuracy. Nowlets try out a larger <code>k</code>, say <code>k = 5</code>:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y_test_pred = classifier.predict_labels(dists, k=<span class="number">5</span>)</span><br><span class="line">num_correct = np.<span class="built_in">sum</span>(y_test_pred == y_test)</span><br><span class="line">accuracy = <span class="built_in">float</span>(num_correct) / num_test</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Got %d / %d correct =&gt; accuracy: %f&#x27;</span> % (num_correct, num_test, accuracy))</span><br></pre></td></tr></table></figure><pre><code>Got 139 / 500 correct =&gt; accuracy: 0.278000</code></pre><p>You should expect to see a slightly better performance than with<code>k = 1</code>.</p><p><strong>Inline Question 2</strong></p><p>We can also use other distance metrics such as L1 distance. For pixelvalues <span class="math inline">\(p_{ij}^{(k)}\)</span> at location<span class="math inline">\((i,j)\)</span> of some image <spanclass="math inline">\(I_k\)</span>,</p><p>the mean <span class="math inline">\(\mu\)</span> across all pixelsover all images is <spanclass="math display">\[\mu=\frac{1}{nhw}\sum_{k=1}^n\sum_{i=1}^{h}\sum_{j=1}^{w}p_{ij}^{(k)}\]</span>And the pixel-wise mean <span class="math inline">\(\mu_{ij}\)</span>across all images is <spanclass="math display">\[\mu_{ij}=\frac{1}{n}\sum_{k=1}^np_{ij}^{(k)}.\]</span>The general standard deviation <spanclass="math inline">\(\sigma\)</span> and pixel-wise standard deviation<span class="math inline">\(\sigma_{ij}\)</span> is definedsimilarly.</p><p>Which of the following preprocessing steps will not change theperformance of a Nearest Neighbor classifier that uses L1 distance?Select all that apply. 1. Subtracting the mean <spanclass="math inline">\(\mu\)</span> (<spanclass="math inline">\(\tilde{p}_{ij}^{(k)}=p_{ij}^{(k)}-\mu\)</span>.)2. Subtracting the per pixel mean <spanclass="math inline">\(\mu_{ij}\)</span> (<spanclass="math inline">\(\tilde{p}_{ij}^{(k)}=p_{ij}^{(k)}-\mu_{ij}\)</span>.)3. Subtracting the mean <span class="math inline">\(\mu\)</span> anddividing by the standard deviation <spanclass="math inline">\(\sigma\)</span>. 4. Subtracting the pixel-wisemean <span class="math inline">\(\mu_{ij}\)</span> and dividing by thepixel-wise standard deviation <spanclass="math inline">\(\sigma_{ij}\)</span>. 5. Rotating the coordinateaxes of the data.</p><p><span class="math inline">\(\color{blue}{\textit YourAnswer:}\)</span></p><p>1, 2, 3, 4 will not change the L1 Distance.</p><p><span class="math inline">\(\color{blue}{\textit YourExplanation:}\)</span></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Now lets speed up distance matrix computation by using partial vectorization</span></span><br><span class="line"><span class="comment"># with one loop. Implement the function compute_distances_one_loop and run the</span></span><br><span class="line"><span class="comment"># code below:</span></span><br><span class="line">dists_one = classifier.compute_distances_one_loop(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># To ensure that our vectorized implementation is correct, we make sure that it</span></span><br><span class="line"><span class="comment"># agrees with the naive implementation. There are many ways to decide whether</span></span><br><span class="line"><span class="comment"># two matrices are similar; one of the simplest is the Frobenius norm. In case</span></span><br><span class="line"><span class="comment"># you haven&#x27;t seen it before, the Frobenius norm of two matrices is the square</span></span><br><span class="line"><span class="comment"># root of the squared sum of differences of all elements; in other words, reshape</span></span><br><span class="line"><span class="comment"># the matrices into vectors and compute the Euclidean distance between them.</span></span><br><span class="line">difference = np.linalg.norm(dists - dists_one, <span class="built_in">ord</span>=<span class="string">&#x27;fro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;One loop difference was: %f&#x27;</span> % (difference, ))</span><br><span class="line"><span class="keyword">if</span> difference &lt; <span class="number">0.001</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Good! The distance matrices are the same&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Uh-oh! The distance matrices are different&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>One loop difference was: 0.000000Good! The distance matrices are the same</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Now implement the fully vectorized version inside compute_distances_no_loops</span></span><br><span class="line"><span class="comment"># and run the code</span></span><br><span class="line">dists_two = classifier.compute_distances_no_loops(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># check that the distance matrix agrees with the one we computed before:</span></span><br><span class="line">difference = np.linalg.norm(dists - dists_two, <span class="built_in">ord</span>=<span class="string">&#x27;fro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;No loop difference was: %f&#x27;</span> % (difference, ))</span><br><span class="line"><span class="keyword">if</span> difference &lt; <span class="number">0.001</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Good! The distance matrices are the same&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Uh-oh! The distance matrices are different&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>No loop difference was: 0.000000Good! The distance matrices are the same</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Let&#x27;s compare how fast the implementations are</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">time_function</span>(<span class="params">f, *args</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Call a function f with args and return the time (in seconds) that it took to execute.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">import</span> time</span><br><span class="line">    tic = time.time()</span><br><span class="line">    f(*args)</span><br><span class="line">    toc = time.time()</span><br><span class="line">    <span class="keyword">return</span> toc - tic</span><br><span class="line"></span><br><span class="line">two_loop_time = time_function(classifier.compute_distances_two_loops, X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Two loop version took %f seconds&#x27;</span> % two_loop_time)</span><br><span class="line"></span><br><span class="line">one_loop_time = time_function(classifier.compute_distances_one_loop, X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;One loop version took %f seconds&#x27;</span> % one_loop_time)</span><br><span class="line"></span><br><span class="line">no_loop_time = time_function(classifier.compute_distances_no_loops, X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;No loop version took %f seconds&#x27;</span> % no_loop_time)</span><br><span class="line"></span><br><span class="line"><span class="comment"># You should see significantly faster performance with the fully vectorized implementation!</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># <span class="doctag">NOTE:</span> depending on what machine you&#x27;re using, </span></span><br><span class="line"><span class="comment"># you might not see a speedup when you go from two loops to one loop, </span></span><br><span class="line"><span class="comment"># and might even see a slow-down.</span></span><br></pre></td></tr></table></figure><pre><code>Two loop version took 40.888526 secondsOne loop version took 43.892950 secondsNo loop version took 0.555355 seconds</code></pre><h3 id="cross-validation">Cross-validation</h3><p>We have implemented the k-Nearest Neighbor classifier but we set thevalue k = 5 arbitrarily. We will now determine the best value of thishyperparameter with cross-validation.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num_folds = <span class="number">5</span></span><br><span class="line">k_choices = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">8</span>, <span class="number">10</span>, <span class="number">12</span>, <span class="number">15</span>, <span class="number">20</span>, <span class="number">50</span>, <span class="number">100</span>]</span><br><span class="line"></span><br><span class="line">X_train_folds = []</span><br><span class="line">y_train_folds = []</span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span>                                                                        #</span></span><br><span class="line"><span class="comment"># Split up the training data into folds. After splitting, X_train_folds and    #</span></span><br><span class="line"><span class="comment"># y_train_folds should each be lists of length num_folds, where                #</span></span><br><span class="line"><span class="comment"># y_train_folds[i] is the label vector for the points in X_train_folds[i].     #</span></span><br><span class="line"><span class="comment"># Hint: Look up the numpy array_split function.                                #</span></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">X_train_folds = np.array_split(X_train,num_folds)</span><br><span class="line">y_train_folds = np.array_split(y_train,num_folds)</span><br><span class="line"></span><br><span class="line"><span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># A dictionary holding the accuracies for different values of k that we find</span></span><br><span class="line"><span class="comment"># when running cross-validation. After running cross-validation,</span></span><br><span class="line"><span class="comment"># k_to_accuracies[k] should be a list of length num_folds giving the different</span></span><br><span class="line"><span class="comment"># accuracy values that we found when using that value of k.</span></span><br><span class="line">k_to_accuracies = &#123;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span>                                                                        #</span></span><br><span class="line"><span class="comment"># Perform k-fold cross validation to find the best value of k. For each        #</span></span><br><span class="line"><span class="comment"># possible value of k, run the k-nearest-neighbor algorithm num_folds times,   #</span></span><br><span class="line"><span class="comment"># where in each case you use all but one of the folds as training data and the #</span></span><br><span class="line"><span class="comment"># last fold as a validation set. Store the accuracies for all fold and all     #</span></span><br><span class="line"><span class="comment"># values of k in the k_to_accuracies dictionary.                               #</span></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> k_choices:</span><br><span class="line">    k_to_accuracies.setdefault(k, [])</span><br><span class="line">    <span class="comment">#print(k_to_accuracies)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_folds):</span><br><span class="line">    classifier = KNearestNeighbor()</span><br><span class="line">    X_val_train = np.vstack(X_train_folds[<span class="number">0</span>:i] + X_train_folds[i+<span class="number">1</span>:])</span><br><span class="line">    y_val_train = np.hstack(y_train_folds[<span class="number">0</span>:i] + y_train_folds[i+<span class="number">1</span>:])</span><br><span class="line">    <span class="comment">#print(X_val_train, y_val_train)</span></span><br><span class="line">    classifier.train(X_val_train, y_val_train)</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> k_choices:</span><br><span class="line">        y_val_pred = classifier.predict(X_train_folds[i], k)</span><br><span class="line">        num_correct = np.<span class="built_in">sum</span>(y_val_pred == y_train_folds[i])</span><br><span class="line">        accuracy = <span class="built_in">float</span>(num_correct) / <span class="built_in">len</span>(y_val_pred)</span><br><span class="line">        k_to_accuracies[k] += [accuracy]</span><br><span class="line">        <span class="comment">#print(k,k_to_accuracies[k])</span></span><br><span class="line">    <span class="comment">#print(k_to_accuracies)</span></span><br><span class="line"><span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Print out the computed accuracies</span></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">sorted</span>(k_to_accuracies):</span><br><span class="line">    <span class="keyword">for</span> accuracy <span class="keyword">in</span> k_to_accuracies[k]:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;k = %d, accuracy = %f&#x27;</span> % (k, accuracy))</span><br></pre></td></tr></table></figure><pre><code>k = 1, accuracy = 0.263000k = 1, accuracy = 0.257000k = 1, accuracy = 0.264000k = 1, accuracy = 0.278000k = 1, accuracy = 0.266000k = 3, accuracy = 0.239000k = 3, accuracy = 0.249000k = 3, accuracy = 0.240000k = 3, accuracy = 0.266000k = 3, accuracy = 0.254000k = 5, accuracy = 0.248000k = 5, accuracy = 0.266000k = 5, accuracy = 0.280000k = 5, accuracy = 0.292000k = 5, accuracy = 0.280000k = 8, accuracy = 0.262000k = 8, accuracy = 0.282000k = 8, accuracy = 0.273000k = 8, accuracy = 0.290000k = 8, accuracy = 0.273000k = 10, accuracy = 0.265000k = 10, accuracy = 0.296000k = 10, accuracy = 0.276000k = 10, accuracy = 0.284000k = 10, accuracy = 0.280000k = 12, accuracy = 0.260000k = 12, accuracy = 0.295000k = 12, accuracy = 0.279000k = 12, accuracy = 0.283000k = 12, accuracy = 0.280000k = 15, accuracy = 0.252000k = 15, accuracy = 0.289000k = 15, accuracy = 0.278000k = 15, accuracy = 0.282000k = 15, accuracy = 0.274000k = 20, accuracy = 0.270000k = 20, accuracy = 0.279000k = 20, accuracy = 0.279000k = 20, accuracy = 0.282000k = 20, accuracy = 0.285000k = 50, accuracy = 0.271000k = 50, accuracy = 0.288000k = 50, accuracy = 0.278000k = 50, accuracy = 0.269000k = 50, accuracy = 0.266000k = 100, accuracy = 0.256000k = 100, accuracy = 0.270000k = 100, accuracy = 0.263000k = 100, accuracy = 0.256000k = 100, accuracy = 0.263000</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># plot the raw observations</span></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> k_choices:</span><br><span class="line">    accuracies = k_to_accuracies[k]</span><br><span class="line">    plt.scatter([k] * <span class="built_in">len</span>(accuracies), accuracies)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot the trend line with error bars that correspond to standard deviation</span></span><br><span class="line">accuracies_mean = np.array([np.mean(v) <span class="keyword">for</span> k,v <span class="keyword">in</span> <span class="built_in">sorted</span>(k_to_accuracies.items())])</span><br><span class="line">accuracies_std = np.array([np.std(v) <span class="keyword">for</span> k,v <span class="keyword">in</span> <span class="built_in">sorted</span>(k_to_accuracies.items())])</span><br><span class="line">plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)</span><br><span class="line">plt.title(<span class="string">&#x27;Cross-validation on k&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Cross-validation accuracy&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><img src="knn_files/knn_21_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Based on the cross-validation results above, choose the best value for k,   </span></span><br><span class="line"><span class="comment"># retrain the classifier using all the training data, and test it on the test</span></span><br><span class="line"><span class="comment"># data. You should be able to get above 28% accuracy on the test data.</span></span><br><span class="line"><span class="built_in">print</span>(accuracies_mean.argmax())<span class="comment">#add</span></span><br><span class="line">best_k = k_choices[accuracies_mean.argmax()]</span><br><span class="line"></span><br><span class="line">classifier = KNearestNeighbor()</span><br><span class="line">classifier.train(X_train, y_train)</span><br><span class="line">y_test_pred = classifier.predict(X_test, k=best_k)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute and display the accuracy</span></span><br><span class="line">num_correct = np.<span class="built_in">sum</span>(y_test_pred == y_test)</span><br><span class="line">accuracy = <span class="built_in">float</span>(num_correct) / num_test</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Got %d / %d correct =&gt; accuracy: %f&#x27;</span> % (num_correct, num_test, accuracy))</span><br></pre></td></tr></table></figure><pre><code>4Got 141 / 500 correct =&gt; accuracy: 0.282000</code></pre><p><strong>Inline Question 3</strong></p><p>Which of the following statements about <spanclass="math inline">\(k\)</span>-Nearest Neighbor (<spanclass="math inline">\(k\)</span>-NN) are true in a classificationsetting, and for all <span class="math inline">\(k\)</span>? Select allthat apply. 1. The decision boundary of the k-NN classifier is linear.2. The training error of a 1-NN will always be lower than or equal tothat of 5-NN. 3. The test error of a 1-NN will always be lower than thatof a 5-NN. 4. The time needed to classify a test example with the k-NNclassifier grows with the size of the training set. 5. None of theabove.</p><p><span class="math inline">\(\color{blue}{\textit YourAnswer:}\)</span></p><p>2, 4.</p><p><span class="math inline">\(\color{blue}{\textit YourExplanation:}\)</span></p><ol type="1"><li><p>False. It depends on the given categories of data, if you give acategory with a circle boundary to its neighborhood, it isnon-linear.</p></li><li><p>True. In fact the training error of a 1-NN is always 0, and5-NN's lower bound is 0. It is because the nearest neighbor of test datais always going to be itself in 1-NN.</p></li><li><p>False. The value of k is thus data-dependent, that is why we needto perform cross validation to determine the best k for your intendedapplication and dataset.</p></li><li><p>True. At test, KNN needs to make a full pass through the entiredata set and sort points by distance. The time needed thus grows withthe size of the data.</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Assignment One is divided into 5 parts: KNN, SVM, Softmax, 2-layer
neural network, and Higher Level Representations: Image Features.&lt;/p&gt;</summary>
      
    
    
    
    <category term="note" scheme="https://serika-onoe.github.io/categories/note/"/>
    
    
    <category term="cs231n" scheme="https://serika-onoe.github.io/tags/cs231n/"/>
    
    <category term="introduction" scheme="https://serika-onoe.github.io/tags/introduction/"/>
    
    <category term="deep learning" scheme="https://serika-onoe.github.io/tags/deep-learning/"/>
    
    <category term="assignment" scheme="https://serika-onoe.github.io/tags/assignment/"/>
    
  </entry>
  
  <entry>
    <title>Transformer模型初探</title>
    <link href="https://serika-onoe.github.io/2022/12/14/Transformer%E6%A8%A1%E5%9E%8B%E5%88%9D%E6%8E%A2/"/>
    <id>https://serika-onoe.github.io/2022/12/14/Transformer%E6%A8%A1%E5%9E%8B%E5%88%9D%E6%8E%A2/</id>
    <published>2022-12-14T01:42:13.000Z</published>
    <updated>2022-12-20T14:48:56.160Z</updated>
    
    <content type="html"><![CDATA[<h1 id="transformer模型初探">Transformer模型初探</h1><h2 id="位置编码">位置编码</h2><ol type="1"><li>embedding</li><li>位置编码 面试题：RNN的梯度消失有什么不同 ## 多头注意力机制</li></ol><h2 id="残差和laternorm">残差和laterNorm</h2><h2 id="前馈神经网络">前馈神经网络</h2><h2 id="trm面试题讲解">TRM面试题讲解</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;transformer模型初探&quot;&gt;Transformer模型初探&lt;/h1&gt;
&lt;h2 id=&quot;位置编码&quot;&gt;位置编码&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;embedding&lt;/li&gt;
&lt;li&gt;位置编码 面试题：RNN的梯度消失有什么不同 ## 多头注</summary>
      
    
    
    
    <category term="笔记" scheme="https://serika-onoe.github.io/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="科研" scheme="https://serika-onoe.github.io/tags/%E7%A7%91%E7%A0%94/"/>
    
    <category term="项目" scheme="https://serika-onoe.github.io/tags/%E9%A1%B9%E7%9B%AE/"/>
    
  </entry>
  
  <entry>
    <title>强化学习初探</title>
    <link href="https://serika-onoe.github.io/2022/12/12/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%9D%E6%8E%A2/"/>
    <id>https://serika-onoe.github.io/2022/12/12/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%9D%E6%8E%A2/</id>
    <published>2022-12-12T15:17:01.000Z</published>
    <updated>2022-12-13T02:17:47.012Z</updated>
    
    <content type="html"><![CDATA[<h1 id="强化学习">强化学习</h1><p>强化学习是一类对目标导向的学习与决策问题进行理解和自动化处理的算法。它强调智能体通过与环境的直接互动来学习，无需像监督学习一样密集的样本级标签标注，通过奖励来学习合理的策略。</p><p>强化学习包含2个可以进行交互的对象：智能体和环境，它们的定义与介绍如下：</p><p>智能体：可以感知环境的状态，并根据反馈的奖励学习选择一个合适的动作，我们希望它能最大化长期总收益。环境：环境会接收智能体执行的一系列动作，对这一系列动作进行评价并转换为一种可量化的信号反馈给智能体。环境对智能体来说是一套相对固定的规则。</p><h2 id="目的">目的</h2><p>强化学习的目的是让计算机自行学习，以获得最好的未来结果。它通过不断的尝试和评估来实现这一目标，从而使计算机能够根据结果自动调整自身来获得最佳结果。</p><h2 id="典型算法">典型算法</h2><p>强化学习中使用的典型算法有：Q学习、蒙特卡洛树搜索、模仿学习、深度强化学习等。</p><h2 id="优点">优点</h2><p>强化学习的优点有：</p><ul><li>可以解决复杂的决策问题，比如游戏、控制和规划。</li><li>可以快速解决不断变化的环境问题和复杂的决策问题。</li><li>可以在非常少的知识和计算量情况下学习。</li></ul><h2 id="缺点">缺点</h2><p>强化学习的缺点有：</p><ul><li>需要大量的试验数据，因此在小数据集上表现不佳。</li><li>可能会出现“收敛停滞”现象，即它可能会在局部最优解上停止收敛。</li><li>它可能会陷入错误的局部最优解。</li></ul><h2 id="应用">应用</h2><p>强化学习在实际应用中有很多，比如：自动驾驶、智能家居、游戏、虚拟助手、自动投资、博弈机器人等。</p><h2 id="参考网站">参考网站</h2><ol type="1"><li>Reinforcement Learning and ArtificialIntelligence：https://www.reinforcementlearning.ai/</li><li>Deep ReinforcementLearning：https://deepreinforcementlearning.ai/</li><li>Andrew Ng Reinforcement Learning：https://www.andrewng.org/</li><li>Open AI Gym：https://gym.openai.com/</li><li>Google DeepMind：https://deepmind.com/research/open-source/</li><li>Berkeley AI Research：https://bair.berkeley.edu/</li><li>Udacity ReinforcementLearning：https://www.udacity.com/course/reinforcement-learning--ud600</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;强化学习&quot;&gt;强化学习&lt;/h1&gt;
&lt;p&gt;强化学习是一类对目标导向的学习与决策问题进行理解和自动化处理的算法。它强调智能体通过与环境的直接互动来学习，无需像监督学习一样密集的样本级标签标注，通过奖励来学习合理的策略。&lt;/p&gt;
&lt;p&gt;强化学习包含2个可以进行交互的对</summary>
      
    
    
    
    <category term="介绍" scheme="https://serika-onoe.github.io/categories/%E4%BB%8B%E7%BB%8D/"/>
    
    
    <category term="强化学习" scheme="https://serika-onoe.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="人工智能" scheme="https://serika-onoe.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="算法" scheme="https://serika-onoe.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>My Projects</title>
    <link href="https://serika-onoe.github.io/2022/12/09/My%20projects/"/>
    <id>https://serika-onoe.github.io/2022/12/09/My%20projects/</id>
    <published>2022-12-09T03:10:23.000Z</published>
    <updated>2022-12-12T14:45:37.714Z</updated>
    
    <content type="html"><![CDATA[<h1 id="software-programming-projects">Software ProgrammingProjects</h1><h2id="cluster-unmanned-aerial-vehicle-electromagnetic-calculations-and-applications">ClusterUnmanned Aerial Vehicle Electromagnetic Calculations andApplications</h2><p>2021.1 - 2021.8</p><hr /><h3 id="description.">Description.</h3><p>We solve the problem of acquiring target electromagneticcharacteristic data of UAV cluster by the following steps, and proposean innovative idea to solve the target detection of UAV clusterproblem.</p><p>First, a typical single fixed-wing UAV represented by the "Gremlin"UAV is used as an example for electromagnetic calculation based on themulti-stage fast multipole method (MLFMM). Then, radar scattering crosssection (RCS) simulation data and two-dimensional inverse syntheticaperture radar (ISAR) imaging are used to verify the accuracy of theresults of the above simulations. Finally, we simulated and validatedthe RCS simulation data for the UAV cluster.</p><p>The programming languages and software tools used are as follow:</p><ol type="1"><li>Solidworks - to build 3D models of both types of UAVs</li><li>Feko electromagnetic simulation software -- MLFMM-basedelectromagnetic simulation calculations for UAVs</li><li>MATLAB -- simulation data cleaning and processing, ISAR imagingalgorithm implementation</li></ol><h3 id="achievements.">Achievements.</h3><p>The process and conclusions of the project have been presented at theCIE Radar Conference 2021.</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/uav_prove.jpg" /></p><p>We summarize and analyze the EM scattering calculations for the UAVtarget "Gremlin" in single and clustered cases, which are based on theapplication requirements and technical difficulties. Fully polarizedstatic EM scattering was calculated for the "Gremlin" in typicalfrequency bands and the results were used to perform clustered targetimaging, where the wingtip characteristics of the "Gremlin" can beclearly seen.</p><h4 id="fixed-wing-representative-1---u.s.-army-predator-uav">Fixed WingRepresentative 1 - U.S. Army Predator UAV</h4><p><imgsrc="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Finews.gtimg.com%2Fnewsapp_match%2F0%2F2985298796%2F0.jpg&amp;refer=http%3A%2F%2Finews.gtimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1617869104&amp;t=54d2c95a6f95de01679291e9b76837dd" /></p><center>Fixed Wing Representative 1 - U.S. Army Predator drone in action</center><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/uav1.jpg" /></p><center>Fixed Wing Representative 1--Model view of U.S. Army Predator drone</center><h4 id="fixed-wing-representative-2---us-army-pixie-drone">Fixed-wingrepresentative 2 - US Army Pixie drone</h4><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/uav2.jpg" /></p><center>Fixed Wing Representative 2 - U.S. Army Pixie Drone Physical Image</center><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/uav3.jpg" /></p><center>Fixed-wing representative 2 - a model of the U.S. Army Pixie drone</center><h4 id="rotor-wing-representative---dji-f450-drone">Rotor wingrepresentative - DJI F450 drone</h4><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/uav4.jpg" /></p><center>Rotary wing representative - DJI F450 drone physical picture</center><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/uav5.jpg" /></p><center>Rotor representation - model image of DJI F450 drone</center><h2id="semantic-understanding-of-point-clouds-under-weakly-supervised-conditions">Semanticunderstanding of point clouds under weakly supervised conditions</h2><p>2020.10 - 2021.1</p><hr /><h3 id="description.-1">Description.</h3><p>To solve the problem of expensive data annotation in semanticsegmentation of 3D point clouds, an attempt is made to use a weaklysupervised learning approach for research. A review of the paper ispresented, and the "PointNet++" code is reproduced.</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/pointcloud%20mind.png" /></p><p>The programming languages and software tools used are.</p><ol type="1"><li>Python - code reproduction via Jupyter Notebook</li></ol><h3 id="achievements.-1">Achievements.</h3><p>Based on the PaddlePaddle framework of the Baidu AI platform, theclassification of disordered point clouds generated from ten sets offurniture images reproduced the 91.9% accuracy rate of the "PointNet++"paper.</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/point%20cloud2.jpg" /></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/point%20cloud3.jpg" /></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/point%20cloud4.jpg" /></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/point%20cloud5.jpg" /></p><h2 id="python-crawl-for-country-statistics">Python crawl for countrystatistics</h2><p>2021.1</p><hr /><h3 id="description.-2">Description.</h3><p>Independently, crawl the basic information of urban and ruralresidents' income and expenditure for eight provinces and six quartersfrom the "National Bureau of Statistics".</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/crawl%20mind.jpg" /></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/crawl2.jpg" /></p><p>The programming languages and software tools used are.</p><ol type="1"><li>Python -- crawler functionality through the panda library and tableprocessing through the xlwings library</li></ol><h3 id="achievements.-2">Achievements.</h3><p>Crawl the table data of eight provinces and six quarters of theNational Bureau of Statistics into excel tables, while the code cansieve invalid data, automatically organize the excel tables, and realizethe data centering and adaptive column width through xlwingslibrary.</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/crawl3.jpg" /></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/crawl4.jpg" /></p><h2 id="app-creation-and-security-analysis">app creation and securityanalysis</h2><p>2019.10 - 2020.1</p><hr /><h3 id="description.-3">Description.</h3><p>App Implementation Requirements:The app has a user/password loginfunction and is available for user registration. The password forregistration is limited in length only (e.g. 8 digits in length), butthe strength is not required for now. The user name/password is saved onthe cell phone, and the password is encrypted when saved (choose yourown encryption algorithm).</p><p>The function is relatively simple, a floating window pops up, showingthat the app needs to obtain storage space, device information,geolocation permissions prompt, you can choose to authorize or deny. Byrunning the app on the phone, registering several accounts with strongand weak passwords, then analyzing the security and improving it.</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/app1.png" /></p><p>Code related to the client login function (Kotlin).</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/app2.png" /></p><p>Statements related to obtaining the permissions for storage space,device information, and geolocation permissions.</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/app3.png" /></p><p>Screenshot of Androbugs analysis.</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/app5.png" /></p><p>The analysis modifies the registration/login authentication method ofthe original app to use the authorization code pattern from the OAuth2specification: !</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/app6.png" /></p><p>Changed external storage to internal storage: !</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/app7.png" /></p><p>The programming languages and software tools used are.</p><ol type="1"><li>Kotlin -- implement app functions through Android Studio</li><li>Androbugs -- analyzing app security</li></ol><h3 id="accomplishments.">Accomplishments.</h3><p>The full runtime video is as follows.</p><p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTQwNjUwOA==' frameborder=0 allowfullscreen></iframe></p><h2id="experimenting-with-bypassing-authentication-systems">Experimentingwith bypassing authentication systems</h2><p>2019.9</p><hr /><h3 id="description.-4">Description.</h3><p>Many commercial WIFIs in shopping malls and restaurants use WEBPortal authentication, but some authentication systems are vulnerableand can bypass the gateway billing system using DNS TUNNEL. Thisvulnerability exists in commercial WIFI environments and can be verifiedto be able to use DNS TUNNEL to bypass the gateway billing system.</p><p>It is not really practical for DNS Tunnel to be used for"password-free Internet access". Even though our group had "cut out" theexpense of the cloud server (and moved the proxy server locally), thewhole experiment ended up costing $6 to purchase the domain name.</p><p>The programming languages and software tools used were</p><ol type="1"><li>Raspberry Pi -- build a local proxy server</li><li>Portal -- topology analysis and DNS simulation configuration</li></ol><h3 id="achievements.-3">Achievements.</h3><p>The whole experiment actually tells us: hackers will "see theneedle", DNS, a protocol dedicated to domain name queries, can also beused to transmit data. If you need to do network application layerprotocol design and maintenance work in the future, you must be doublycareful and be very cautious in network security. Also for individuals,if they connect to a public network, they must be vigilant to prevent"high-tech theft" because it is difficult to know where the hackers willtarget next.</p><iframe height="498" width="510" src="https://player.youku.com/embed/XNDg5NzI1OTY0OA==" frameborder="0" allowfullscreen></iframe><h2 id="ai-playing-tetris">AI playing Tetris</h2><p>2018.9</p><hr /><h3 id="description.-5">Description.</h3><p>Implementing a tetris game using pygame while setting up an AI (can'teven use machine learning algorithms)</p><p>The programming languages and software tools used are.</p><ol type="1"><li>Python - to implement Tetris logic and AI algorithms</li></ol><p>The basic idea of the AI algorithm is to traverse all possible futurescenarios consisting of the current operable tetris and the nextoperable tetris (according to different strategies, i.e., choosingdifferent positions and rotation angles) after they fall to thebottom</p><p>The merits of future scenes are judged based on.</p><pre><code>1) the number of rows that can be eliminated.2) the number of virtual holes inside the stacked Tetris blocks.3) the number of small squares in the stacked Tetris.(4) the highest point of the stacked tetris.5) the standard deviation of the heights (one height for each column) of the stacked Tetris.6) the first-order forward difference of the heights of the stacked Tetris blocks.7) the standard deviation of the first-order forward difference of the heights of the stacked Tetris blocks.8) the difference between the highest and lowest points of the stacked Tetris.</code></pre><p>Choose the optimal one from these future scenarios, whosecorresponding action strategy for the currently operable Tetris is thecurrent solution</p><h3 id="achievements.-4">Achievements.</h3><p>Video demonstration of dragging the source code while the game isrunning automatically to show that it is not a manual operation hh</p><p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTAwMTY4MA==' frameborder=0 allowfullscreen></iframe></p><h2 id="handwritten-number-recognition-gui">Handwritten numberrecognition GUI</h2><p>2020.11 - 2021.1</p><hr /><h3 id="description.-6">Description.</h3><p>Handwritten digit recognition GUI development without usingframeworks</p><p>The programming languages and software tools used are.</p><ol type="1"><li>Python - development of GUI interface (based on Qt5), involvingbasic bp algorithm implementation and optimization algorithms such asregularization (BN, L2 regularization, RMSProp), and implementation ofpyqt interface and three functions: extraction recognition in mnist,upload image recognition, and drawing board handwriting recognition</li></ol><h3 id="achievements.-5">Achievements.</h3><p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTAwMDg3Mg==' frameborder=0 allowfullscreen></iframe></p><h2 id="mario-diy-version">Mario DIY version</h2><p>2018.4 - 2018.6</p><hr /><h3 id="description.-7">Description.</h3><p>DIY a Mario with changed life settings and map scenes from theoriginal version.</p><p>Life cap can be increased by eating mushrooms and returning a portionof blood, while if the body is in villain form it turns into adult form.When hit, the form does not change and the HP is deductedaccordingly.</p><p>The programming language and software tools used are.</p><ol type="1"><li>Gamemaker - to develop the game interface, draw the game map andplay logic implementation</li></ol><p>Achievements.</p><p><strong>Pass demo and simple function demo</strong></p><p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTAwMjQxMg==' frameborder=0 allowfullscreen></iframe></p><p><strong>If HP is 0, then just die</strong></p><p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTAwNDE1Mg==' frameborder=0 allowfullscreen></iframe></p><h2 id="easy-version-of-magic-tower">Easy version of Magic Tower</h2><p>2017.11 - 2018.1</p><hr /><h3 id="description.-8">Description.</h3><p>Command line interface, operable simple version of Magic Tower</p><p>The programming languages and software tools used are.</p><ol type="1"><li>C++ -- drawing game maps and play logic implementation via commandline and strings</li></ol><h3 id="accomplishments.-1">Accomplishments.</h3><p><strong>Pass demo and simple functionality demo</strong></p><iframe height="498" width="510" src="https://player.youku.com/embed/XNDg5NzU4NDgzMg==" frameborder="0" allowfullscreen></iframe><h2 id="epidemic-map-applet">Epidemic map applet</h2><p>2020.6</p><hr /><h3 id="description.-9">Description.</h3><p>An epidemic map made during the epidemic, divided into two sections:domestic and foreign, each section is divided into two subsections:cumulative epidemic of the day and new epidemic of the day, citing thedata source of the open class bar, where the darker the color indicatesthe more infected people.</p><p>The programming languages and software tools used are.</p><ol type="1"><li>html -- citing the data source of Open Class Bar, trying tovisualize the figures</li></ol><h3 id="results.">Results.</h3><iframe height="498" width="510" src="https://player.youku.com/embed/XNDg5NzI4NDU0MA==" frameborder="0" allowfullscreen></iframe><h2 id="hardware-control-project">Hardware Control Project</h2><p>## Multiple switching methods for toy dogs</p><h2 id="gps-spoofing">GPS spoofing</h2><p>2019.9 - 2019.11</p><hr /><h3 id="description.-10">Description.</h3><p>In the Linux environment, the cell phone with GPS satellitepositioning is applied, and the HackRF One transmits a spoofing signalto achieve point-to-point spoofing or trajectory spoofing, which cansuccessfully spoof to the specified location within 1 or 2 minutes ofuninterrupted motion within the specified trajectory based on the givenacceleration and speed.</p><p>The programming language and software tools used are.</p><ol type="1"><li>Hardware: HackRF One - with TCXO clock module and antenna fortransmitting GPS signals</li><li>Software. | software | role | | ---- | ---- | | Google Earth |Selects the spoofed location and sketches the target trajectory | |SatGen | Target trajectory and store as motion path | | gps-sdr-sim |Samples data files to generate GPS data sources | | Gnuradio | Aflowchart-style program to run GPS spoofing | | hackrf-tools | Run GPSspoofing from the command line via the hackrf_transfer function |</li></ol><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/gps%20mind.png" /></p><h3 id="achievements.-6">Achievements.</h3><p>The actual phone is located at a certain point in the living area ofGuangzhou University City and is stationary, and the position is spoofedto run at variable speed on the playground track of Shanghai JiaotongUniversity, 1,000 km away, within 5m accuracy throughout.</p><p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTAwNDUyOA==' frameborder=0 allowfullscreen></iframe></p><p>2020.11 - 2021.1</p><hr /><h3 id="description.-11">Description.</h3><p>According to the toy electronic dog, through its circuit diagram ismodified accordingly, can get different switch corresponding way, inaddition to the following video has also been achieved magnetic control,small program control, Bluetooth control and other ways</p><p>The hardware modules used are.</p><ol type="1"><li>toy electronic dog -- with basic walking, barking function</li><li>circuit board -- to achieve different ways to switch and solder thecircuit</li><li>Bluetooth switch module -- with WeChat small program controlsystem</li></ol><h3 id="achievements.-7">Achievements.</h3><p><strong>keyed switch method</strong></p><iframe height="498" width="510" src="https://player.youku.com/embed/XNDg5NzI5MDU0MA==" frameborder="0" allowfullscreen></iframe><p><strong>Temperature control switch method</strong></p><iframe height="498" width="510" src="https://player.youku.com/embed/XNDg5NzI5MDcyMA==" frameborder="0" allowfullscreen></iframe><h2 id="arduino-based-music-player">Arduino-based music player</h2><p>2020.4 - 2020.6</p><hr /><h3 id="description.-12">Description.</h3><p>The basic functions of MP3 (track switching, multiple playback modes,volume adjustment) are implemented through cell phone (serial port) orcomputer input control.</p><p>The hardware modules used are.</p><ol type="1"><li>Arduino -- central processor</li><li>tf card -- storage of tracks</li><li>speaker -- play sound</li><li>LCD screen -- display playback mode, tracks</li></ol><h3 id="accomplishments.-2">Accomplishments.</h3><iframe height="498" width="510" src="https://player.youku.com/embed/XNDg0MTAzMDQwOA==" frameborder="0" allowfullscreen></iframe>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;software-programming-projects&quot;&gt;Software Programming
Projects&lt;/h1&gt;
&lt;h2
id=&quot;cluster-unmanned-aerial-vehicle-electromagnetic-calcula</summary>
      
    
    
    
    <category term="summary" scheme="https://serika-onoe.github.io/categories/summary/"/>
    
    
    <category term="research" scheme="https://serika-onoe.github.io/tags/research/"/>
    
    <category term="project" scheme="https://serika-onoe.github.io/tags/project/"/>
    
  </entry>
  
  <entry>
    <title>我的项目经历</title>
    <link href="https://serika-onoe.github.io/2022/12/09/%E6%88%91%E7%9A%84%E7%A7%91%E7%A0%94%E7%BB%8F%E5%8E%86/"/>
    <id>https://serika-onoe.github.io/2022/12/09/%E6%88%91%E7%9A%84%E7%A7%91%E7%A0%94%E7%BB%8F%E5%8E%86/</id>
    <published>2022-12-09T03:10:23.000Z</published>
    <updated>2022-12-13T02:06:24.224Z</updated>
    
    <content type="html"><![CDATA[<h1 id="我的项目经历">我的项目经历</h1><p>目录：</p><!-- vscode-markdown-toc --><p><strong>一、软件编程项目</strong> * 1. <ahref="#">无人机集群电磁仿真设计</a> * 2. <ahref="#-1">弱监督条件下的点云语义理解</a> * 3. <ahref="#Python">Python爬取国家统计数据</a> * 4. <ahref="#app">app制作与安全性分析</a> * 5. <ahref="#-1">绕过认证系统实验</a> * 6. <a href="#AI">AI玩俄罗斯方块</a> *7. <a href="#GUI">手写数字识别GUI</a> * 8. <ahref="#DIY">马里奥DIY版</a> * 9. <a href="#-1">简易版魔塔</a> * 10. <ahref="#-1">疫情地图小程序</a></p><p><strong>二、硬件控制项目</strong> * 1. <ahref="#-1">玩具狗的多种开关方式</a> * 2. <a href="#GPS">GPS欺骗</a> * 3.<a href="#Arduino">基于Arduino的音乐播放器</a><!-- vscode-markdown-toc-config    numbering=true    autoSave=true    /vscode-markdown-toc-config --> <!-- /vscode-markdown-toc --></p><h1 id="软件编程项目">软件编程项目</h1><h2 id="无人机集群电磁仿真设计">1.<a name=''></a>无人机集群电磁仿真设计</h2><p>2021.1 - 2021.8</p><hr /><h3 id="描述">1.1. <a name='-1'></a>描述：</h3><p>我们通过以下步骤解决无人机集群的目标电磁特征数据的获取问题，提出了解决无人机集群问题目标检测的创新思路。</p><p>首先，以 "Gremlin"无人机为代表的典型单架固定翼无人机为例，基于多级快速多极法（MLFMM）进行电磁计算。然后，利用雷达散射截面（RCS）仿真数据和二维反合成孔径雷达（ISAR）成像来验证上述仿真结果的结果准确性。最后，我们对无人机集群的RCS模拟数据进行了模拟和验证。</p><p>用到的编程语言和软件工具有：</p><p>（1）Solidworks -- 建立两类无人机的三维模型 （2）Feko电磁仿真软件 --基于MLFMM对无人机进行电磁仿真计算 （3）MATLAB --仿真数据清洗和处理，ISAR成像算法实现</p><h3 id="成绩">1.2. <a name='-1'></a>成绩：</h3><p>该项目过程和结论已在2021年的CIE雷达会议上提出。</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/uav_prove.jpg" /></p><p>我们总结和分析了无人机目标 "Gremlin"在单一和集群情况下的电磁散射计算，这些都是基于的应用要求和技术困难。全极化静态电磁散射计算了"Gremlin"在典型频段的全极化静态电磁散射特征数据，并将其结果用于进行集群目标成像，可以清楚地看到"Gremlin "的翼尖特征。</p><h4 id="固定翼代表1--美军捕食者无人机">1.2.1.<a name='1--'></a>固定翼代表1--美军“捕食者”无人机</h4><p><imgsrc="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Finews.gtimg.com%2Fnewsapp_match%2F0%2F2985298796%2F0.jpg&amp;refer=http%3A%2F%2Finews.gtimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1617869104&amp;t=54d2c95a6f95de01679291e9b76837dd" /></p><center>固定翼代表1--美军“捕食者”无人机实物图</center><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/uav1.jpg" /></p><center>固定翼代表1--美军“捕食者”无人机模型图</center><h4 id="固定翼代表2--美军小精灵无人机">1.2.2.<a name='2--'></a>固定翼代表2--美军“小精灵”无人机</h4><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/uav2.jpg" /></p><center>固定翼代表2--美军“小精灵”无人机实物图</center><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/uav3.jpg" /></p><center>固定翼代表2--美军“小精灵”无人机模型图</center><h4 id="旋翼代表--大疆f450无人机">1.2.3.<a name='--F450'></a>旋翼代表--大疆F450无人机</h4><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/uav4.jpg" /></p><center>旋翼代表--大疆F450无人机实物图</center><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/uav5.jpg" /></p><center>旋翼代表--大疆F450无人机模型图</center><h2 id="弱监督条件下的点云语义理解">2.<a name='-1'></a>弱监督条件下的点云语义理解</h2><p>2020.10 - 2021.1</p><hr /><h3 id="描述-1">2.1. <a name='-1'></a>描述：</h3><p>为解决三维点云语义分割中数据标注昂贵的问题，尝试使用弱监督学习的方法进行研究。进行了论文综述，同时复现了“PointNet++”代码。</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/pointcloud%20mind.png" /></p><p>用到的编程语言和软件工具有：</p><p>（1）Python -- 通过Jupyter Notebook复现代码</p><h3 id="成绩-1">2.2. <a name='-1'></a>成绩：</h3><p>基于百度AI平台的PaddlePaddle框架，对十组家具图片生成的无序点云进行分类处理，复现了“PointNet++”论文中91.9%的准确率。</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/point%20cloud2.jpg" /></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/point%20cloud3.jpg" /></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/point%20cloud4.jpg" /></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/point%20cloud5.jpg" /></p><h2 id="python爬取国家统计数据">3.<a name='Python'></a>Python爬取国家统计数据</h2><p>2021.1</p><hr /><h3 id="描述-2">3.1. <a name='-1'></a>描述：</h3><p>独立完成，爬取“国家统计局”八个省份、六个季度的城乡居民收支基本情况</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/crawl%20mind.jpg" /></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/crawl2.jpg" /></p><p>用到的编程语言和软件工具有：</p><p>（1）Python -- 通过panda库实现爬虫功能，通过xlwings库实现表格处理</p><h3 id="成绩-2">3.2. <a name='-1'></a>成绩：</h3><p>爬取国家统计局八个省份、六个季度的表格数据到excel表格中，同时代码可筛去无效数据，自动整理excel表格，通过xlwings库实现数据居中、自适应列宽等功能。</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/crawl3.jpg" /></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/crawl4.jpg" /></p><h2 id="app制作与安全性分析">4.<a name='app'></a>app制作与安全性分析</h2><p>2019.10 - 2020.1</p><hr /><h3 id="描述-3">4.1. <a name='-1'></a>描述：</h3><p>app实现要求:该app具有用户/口令登录功能，并可供使用者注册。注册时口令只作长度限制（如8位长度），但强度暂不作要求。用户名/口令保存在手机上，口令保存时作加密处理（自行选择加密算法）。</p><p>功能比较简单，弹出一浮窗，显示app需要获取存储空间、设备信息、地理位置权限的提示，可选择授权或拒绝。通过在手机上运行此app，注册若干个账号，口令设置时有强口令，也有弱口令，然后分析其安全性，加以改进。</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/app1.png" /></p><p>客户端登录功能的相关代码（Kotlin）：</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/app2.png" /></p><p>获取存储空间、设备信息、地理位置权限这些权限的相关语句：</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/app3.png" /></p><p>Androbugs分析截图：</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/app5.png" /></p><p>分析后修改了原有app的注册/登录认证方式，采用OAuth2规范中的授权码模式：</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/app6.png" /></p><p>将外部存储改为内部存储：</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/app7.png" /></p><p>用到的编程语言和软件工具有：</p><p>（1）Kotlin -- 通过Android Studio实现app功能 （2）Androbugs --分析app安全性</p><h3 id="成绩-3">4.2. <a name='-1'></a>成绩：</h3><p>完整的运行视频如下：</p><p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTQwNjUwOA==' frameborder=0 allowfullscreen></iframe></p><h2 id="绕过认证系统实验">5. <a name='-1'></a>绕过认证系统实验</h2><p>2019.9</p><hr /><h3 id="描述-4">5.1. <a name='-1'></a>描述：</h3><p>很多商场、饭店的商业WIFI采用了WEBPortal认证方式，但有些认证系统存在漏洞，可以利用 DNS TUNNEL绕过网关计费系统。存在这种漏洞的商业WIFI环境，并且可验证能够利用 DNSTUNNEL 穿越网关计费系统。</p><p>DNSTunnel真正用来“免密上网”，其实不太实际。尽管我们组已经“砍掉了”云服务器的开支（把代理服务器搬到本地来进行了），结果整个实验还是花掉了6块钱来购买域名。</p><p>用到的编程语言和软件工具有：</p><p>（1）树莓派 -- 搭建本地代理服务器 （2）Portal --拓扑结构分析和DNS仿真配置</p><h3 id="成绩-4">5.2. <a name='-1'></a>成绩：</h3><p>整个实验其实是告诉我们：黑客会“见缝插针”，DNS这样专门用于域名查询的协议，也可以被拿来传输数据。若将来需要做网络应用层的协议设计、维护工作，一定要加倍小心，在网络安全方面要非常谨慎。另外对于个人来说，如果连接到公共网络，一定要提高警惕，谨防“高科技偷窃”，因为我们难以知道黑客下一个目标是哪里。</p><iframe height="498" width="510" src="https://player.youku.com/embed/XNDg5NzI1OTY0OA==" frameborder="0" allowfullscreen></iframe><h2 id="ai玩俄罗斯方块">6. <a name='AI'></a>AI玩俄罗斯方块</h2><p>2018.9</p><hr /><h3 id="描述-5">6.1. <a name='-1'></a>描述：</h3><p>利用pygame实现俄罗斯方块游戏，同时设置了一个AI（甚至都可以不用机器学习算法）</p><p>用到的编程语言和软件工具有：</p><p>（1）Python -- 实现俄罗斯方块逻辑和AI算法</p><p>AI算法基本思想就是，遍历当前可操作的俄罗斯方块和下一个可操作的俄罗斯方块(根据不同的策略，即选择不同的位置和旋转角度)下落到底部后组成的所有可能的未来场景</p><p>未来场景的优劣判断依据：</p><pre><code>1）可消除的行数；2）堆积后的俄罗斯方块内的虚洞数量；3）堆积后的俄罗斯方块内的小方块数量；4）堆积后的俄罗斯方块的最高点；5）堆积后的俄罗斯方块的高度(每一列都有一个高度)标准差；6）堆积后的俄罗斯方块的高度一阶前向差分；7）堆积后的俄罗斯方块的高度一阶前向差分的标准差；8）堆积后的俄罗斯方块的最高点和最低点之差。</code></pre><p>从这些未来场景中选择一个最优的，其对应的当前可操作的俄罗斯方块的行动策略即为当前解</p><h3 id="成绩-5">6.2. <a name='-1'></a>成绩：</h3><p>视频演示一边拖动源码一边游戏在自动运行，以显示不是手动操作的hh</p><p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTAwMTY4MA==' frameborder=0 allowfullscreen></iframe></p><h2 id="手写数字识别gui">7. <a name='GUI'></a>手写数字识别GUI</h2><p>2020.11 - 2021.1</p><hr /><h3 id="描述-6">7.1. <a name='-1'></a>描述：</h3><p>不使用框架，实现手写数字识别GUI开发</p><p>用到的编程语言和软件工具有：</p><p>（1）Python --开发GUI界面（基于Qt5），涉及基本bp算法实现和正则化（BN，L2正则化，RMSProp）等优化算法，并实现pyqt界面及三个功能:mnist中抽取识别,上传图片识别,画板手写识别</p><h3 id="成绩-6">7.2. <a name='-1'></a>成绩：</h3><p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTAwMDg3Mg==' frameborder=0 allowfullscreen></iframe></p><h2 id="马里奥diy版">8. <a name='DIY'></a>马里奥DIY版</h2><p>2018.4 - 2018.6</p><hr /><h3 id="描述-7">8.1. <a name='-1'></a>描述：</h3><p>DIY了一个马里奥，在原版的基础上改变了生命设定和地图场景：</p><p>生命上限可以通过吃蘑菇增加，并回复一部分血量，同时若身体是小人形态则变成大人形态。受击时形态不变化，扣相应的HP。</p><p>用到的编程语言和软件工具有：</p><p>（1）Gamemaker -- 开发游戏界面，绘制游戏地图及玩法逻辑实现</p><p>成绩：</p><p><strong>通关演示及简单功能演示</strong></p><p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTAwMjQxMg==' frameborder=0 allowfullscreen></iframe></p><p><strong>若HP为0，则直接死亡</strong></p><p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTAwNDE1Mg==' frameborder=0 allowfullscreen></iframe></p><h2 id="简易版魔塔">9. <a name='-1'></a>简易版魔塔</h2><p>2017.11 - 2018.1</p><hr /><p>###描述：</p><p>命令行界面，可操作的简易版魔塔</p><p>用到的编程语言和软件工具有：</p><p>（1）C++ -- 通过命令行和字符串绘制游戏地图及玩法逻辑实现</p><h3 id="成绩-7">9.1. <a name='-1'></a>成绩：</h3><p><strong>通关演示及简单功能演示</strong></p><iframe height="498" width="510" src="https://player.youku.com/embed/XNDg5NzU4NDgzMg==" frameborder="0" allowfullscreen></iframe><h2 id="疫情地图小程序">10. <a name='-1'></a>疫情地图小程序</h2><p>2020.6</p><hr /><h3 id="描述-8">10.1. <a name='-1'></a>描述：</h3><p>疫情期间做的一个疫情地图，分为国内、国外两个板块，每个板块分为当日累计疫情、当日新增疫情两个子板块，引用了开课吧的数据源，颜色越深说明感染人数越多。</p><p>用到的编程语言和软件工具有：</p><p>（1）html -- 引用开课吧数据源，尝试进行数字可视化</p><h3 id="成绩-8">10.2. <a name='-1'></a>成绩：</h3><iframe height="498" width="510" src="https://player.youku.com/embed/XNDg5NzI4NDU0MA==" frameborder="0" allowfullscreen></iframe><h1 id="硬件控制项目">硬件控制项目</h1><h2 id="玩具狗的多种开关方式式">11.<a name='-1'></a>玩具狗的多种开关方式式</h2><h2 id="gps欺骗">12. <a name='GPS'></a>GPS欺骗</h2><p>2019.9 - 2019.11</p><hr /><h3 id="描述-9">12.1. <a name='-1'></a>描述：</h3><p>在Linux环境下，应用GPS卫星定位的手机,通过HackRFOne发射欺骗信号，实现点到点欺骗或轨迹欺骗，可在1、2分钟内成功欺骗到指定位置在指定轨迹内依据给定的加速度、速度进行不间断运动。</p><p>用到的编程语言和软件工具有：</p><p>（1）硬件：HackRF One -- 带 TCXO 时钟模块和天线，用于发射GPS信号 (2)软件： | 软件 | 作用 | | ---- | ---- | | Google Earth |选中欺骗地点，勾画目标轨迹 | | SatGen | 目标轨迹并存储为运动路径 | |gps-sdr-sim | 采样数据文件，生成GPS数据源 | | Gnuradio |流程图式运行GPS欺骗的程序 | | hackrf-tools |通过hackrf_transfer函数，在命令行运行GPS欺骗 |</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/gps%20mind.png" /></p><h3 id="成绩-9">12.2. <a name='-1'></a>成绩：</h3><p>实际手机位于广州大学城生活区某一定点静止不动，将定位欺骗至1千公里外的上海交大的操场跑道上变速跑步,全程精确度5m以内。</p><p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTAwNDUyOA==' frameborder=0 allowfullscreen></iframe></p><p>2020.11 - 2021.1</p><hr /><h3 id="描述-10">12.3. <a name='-1'></a>描述：</h3><p>根据玩具电子狗，通过其电路图进行相应修改，可得到不同开关相应方式，除了下面视频外也已经实现磁控、小程序控制、蓝牙控制等方式</p><p>用到的硬件模块有：</p><ol type="1"><li>玩具电子狗 -- 具备基本行走，吠叫功能</li><li>电路板 -- 实现不同方式开关并焊接电路 （3) 蓝牙开关模块 --具有微信小程序控制系统</li></ol><h3 id="成绩-10">12.4. <a name='-1'></a>成绩：</h3><p><strong>键控开关方式</strong></p><iframe height="498" width="510" src="https://player.youku.com/embed/XNDg5NzI5MDU0MA==" frameborder="0" allowfullscreen></iframe><p><strong>温控开关方式</strong></p><iframe height="498" width="510" src="https://player.youku.com/embed/XNDg5NzI5MDcyMA==" frameborder="0" allowfullscreen></iframe><h2 id="基于arduino的音乐播放器">13.<a name='Arduino'></a>基于Arduino的音乐播放器</h2><p>2020.4 - 2020.6</p><hr /><h3 id="描述-11">13.1. <a name='-1'></a>描述：</h3><p>通过手机(串口)或电脑输入控制，实现了MP3的基本功能（曲目切换，多种播放模式，音量调节）。</p><p>用到的硬件模块有：</p><ol type="1"><li>Arduino -- 中央处理器</li><li>tf卡 -- 存储曲目 （3) 扬声器 -- 播放声音</li><li>LCD屏幕 -- 显示播放模式、曲目</li></ol><h3 id="成绩-11">13.2. <a name='-1'></a>成绩：</h3><iframe height="498" width="510" src="https://player.youku.com/embed/XNDg0MTAzMDQwOA==" frameborder="0" allowfullscreen></iframe>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;我的项目经历&quot;&gt;我的项目经历&lt;/h1&gt;
&lt;p&gt;目录：&lt;/p&gt;
&lt;!-- vscode-markdown-toc --&gt;
&lt;p&gt;&lt;strong&gt;一、软件编程项目&lt;/strong&gt; * 1. &lt;a
href=&quot;#&quot;&gt;无人机集群电磁仿真设计&lt;/a&gt; * 2. &lt;</summary>
      
    
    
    
    <category term="总结" scheme="https://serika-onoe.github.io/categories/%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="科研" scheme="https://serika-onoe.github.io/tags/%E7%A7%91%E7%A0%94/"/>
    
    <category term="项目" scheme="https://serika-onoe.github.io/tags/%E9%A1%B9%E7%9B%AE/"/>
    
  </entry>
  
  <entry>
    <title>Develop Web Crawling in A National Statistic Institute</title>
    <link href="https://serika-onoe.github.io/2021/01/13/Develop%20Web%20Crawling%20in%20A%20National%20Statistic%20Institute/"/>
    <id>https://serika-onoe.github.io/2021/01/13/Develop%20Web%20Crawling%20in%20A%20National%20Statistic%20Institute/</id>
    <published>2021-01-12T16:12:47.000Z</published>
    <updated>2022-12-12T14:38:42.128Z</updated>
    
    <content type="html"><![CDATA[<h1 id="develop-web-crawling-in-a-national-statistic-institute">DevelopWeb Crawling in A National Statistic Institute</h1><p>** This experiment is to crawl the home page of "<ahref="https://data.stats.gov.cn/index.htm">National Bureau ofStatistics</a>" for the example of [Shanghai urban and rural residentsincome and expenditure basic information], other pages of the NationalBureau of Statistics crawl in a similar way **</p><h2 id="crawler-basic-process">1. Crawler basic process</h2><ol type="1"><li>initiate a request: launch a request to the target site through thehttp/https library, that is, send a request, the request can containadditional information such as headers, waiting for the server torespond</li><li>get the corresponding content: if the server can respond normally,it will get a response, the content of the response is the content ofthe page to be obtained, the type may be HTML, json string, binary data(such as pictures and videos) and other types</li><li>parsing content: the content may be HTML, you can use regularexpressions, web parsing library to parse, may be json, can be directlyconverted to json objects, may be binary data, you can do to save orfurther processing ** (The parsed content of this experiment isjson)**</li><li>save data: can be saved as text, can also be saved to the database,or a specific format file</li></ol><h2 id="open-the-web-page-and-analyze">2. Open the web page andanalyze</h2><p>The website of the National Bureau of Statistics is very strange, itis obviously https but it warns of insecurity, the first time theinterface is opened as follows (I use Google Chrome)</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/1.jpg" /></p><p>Click on "Advanced" - "Continue to" to enter the home page</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/2.jpg" /></p><p>Select "Quarterly Data" - "Quarterly Data by Province"</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/3.jpg" /></p><p>Select "People's Life" - "Urban and Rural Income and Expenditure"</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/4.jpg" /></p><p>Change the region to "Shanghai"</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/5.jpg" /></p><p>Press F12 to enter browser debugging mode</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/6.jpg" /></p><p>Refresh and re-fetch the page information, find easyquery.htm?m=QueryData&amp;dbc... file. You can check the "XHR" filter first to narrow thesearch</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/7.jpg" /></p><p>How can we make sure that this file contains the data we are lookingfor? By clicking on the "response" panel and dragging the slider to theright, you can see that the table data corresponds to each other (butthe data does not appear consecutively)</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/8.jpg" /></p><p>** Note: here data and strdata look the same, but the actual formatis not the same, data is int or double format, strdata is str format,this table has some empty data lines, string format is convenient to dojudgment, string to digital use eval () **</p><h2 id="full-code-and-parsing">3. Full code and parsing</h2><p>** Note: the missing libraries can be installed at the command lineusing the pip command, such as the lack of requests library, you canenter the command at the command line **</p><p>`<code>pip install requests</code></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib3 </span><br><span class="line"></span><br><span class="line"><span class="comment"># use urllib3.disable_warnings() with SSL authentication turned off (verify=False)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Disable secure request warnings for requests</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests <span class="comment"># Use Requests to send network requests</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time <span class="comment"># used to get timestamp (calculate current time for web validation)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json <span class="comment"># Process json files</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># Process arrays</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># np.array() to pd.DataFrame format, then use to_excel() to write to excel tables</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get millisecond timestamp for web validation</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getTime</span>():</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">int</span>(<span class="built_in">round</span>(time.time() * <span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># data preprocessing, get the srdata elements (data) wrapped in layers in a json list</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getList</span>(<span class="params">length</span>):</span><br><span class="line"></span><br><span class="line">  <span class="type">List</span>=[]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(length):</span><br><span class="line"></span><br><span class="line">temp = js[<span class="string">&#x27;returndata&#x27;</span>][<span class="string">&#x27;datanodes&#x27;</span>][i][<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;strdata&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># urban and rural residents income and expenditure list, the original site has a year-on-year growth data is empty, if you directly use eval() will report an error, you need to determine first</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(<span class="built_in">len</span>(temp)! =<span class="number">0</span>):</span><br><span class="line"></span><br><span class="line"><span class="comment"># eval() number to string</span></span><br><span class="line"></span><br><span class="line"><span class="type">List</span>.append(<span class="built_in">eval</span>(temp))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="type">List</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">  <span class="comment"># request target URL (link? preceded by something)</span></span><br><span class="line"></span><br><span class="line">  url=<span class="string">&#x27;https://data.stats.gov.cn/easyquery.htm&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># request headers, User-Agent: used to prove you are a browser, just meet a certain format, not necessarily the same as your own browser</span></span><br><span class="line"></span><br><span class="line">  headers=&#123;<span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0(Windows;U;Windows NT6.1;en-US;rv:1.9.1.6) Geko/20091201 Firefox/3.5.6&#x27;</span>&#125;<span class="comment"># browser agent</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Construct parameter key-value pairs, with specific values obtained from the page structure parameters</span></span><br><span class="line"></span><br><span class="line">  key=&#123;&#125;</span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;m&#x27;</span>]=<span class="string">&#x27;QueryData&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;dbcode&#x27;</span>]=<span class="string">&#x27;fsjd&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;rowcode&#x27;</span>]=<span class="string">&#x27;zb&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;colcode&#x27;</span>]=<span class="string">&#x27;sj&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;wds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;: &quot;reg&quot;, &quot;valuecode&quot;: &quot;310000&quot;&#125;]&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;k1&#x27;</span>]=<span class="built_in">str</span>(getTime()) </span><br><span class="line"></span><br><span class="line">  <span class="comment"># &quot;wdcode&quot;: &quot;reg&quot; region field</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Shanghai 310000 </span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;dfwds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;: &quot;zb&quot;, &quot;valuecode&quot;: &quot;A0300&quot;&#125;,&#123;&quot;wdcode&quot;: &quot;sj&quot;, &quot;valuecode&quot;: &quot;LAST6&quot;&#125;]&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># &quot;wdcode&quot;: &quot;zb&quot; select which entry on the left, &quot;wdcode&quot;: &quot;sj&quot; option box select &quot;LAST 6 QUARTERS&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Disable security request warnings</span></span><br><span class="line"></span><br><span class="line">  requests.packages.urllib3.disable_warnings()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Send the request, using the post method, here using the previous custom header and parameters</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># ! verify=False, the NSO switched to https protocol in the second half of 20 years, if not add the code can not pass SSL verification</span></span><br><span class="line"></span><br><span class="line">  r = requests.post(url, headers=headers, params=key,verify=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Use the json library loads function to parse the r.text string into a dict dictionary format and store it in js</span></span><br><span class="line"></span><br><span class="line">  js = json.loads(r.text)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># get the required data of a one-dimensional array, using np.array().reshape() to organize into two-dimensional arrays</span></span><br><span class="line"></span><br><span class="line">  length=<span class="built_in">len</span>(js[<span class="string">&#x27;returndata&#x27;</span>][<span class="string">&#x27;datanodes&#x27;</span>])</span><br><span class="line"></span><br><span class="line">  res=getList(length)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Total data divided into 6 rows of format</span></span><br><span class="line"></span><br><span class="line">  array=np.array(res).reshape(<span class="built_in">len</span>(res)//<span class="number">6</span>,<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># np.array() is converted to pd.DataFrame format, the subsequent can use to_excel() to write directly to excel tables</span></span><br><span class="line"></span><br><span class="line">  df_shanghai=pd.DataFrame(array)</span><br><span class="line"></span><br><span class="line">  df_shanghai.columns=[<span class="string">&#x27;2020 Q3&#x27;</span>,<span class="string">&#x27;2020 Q2&#x27;</span>,<span class="string">&#x27;2020 Q1&#x27;</span>,<span class="string">&#x27;2019 Q4&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;2019 third quarter&#x27;</span>,<span class="string">&#x27;2019 second quarter&#x27;</span>]</span><br><span class="line"></span><br><span class="line">  df_shanghai.index=[<span class="string">&#x27;Cumulative value of per capita disposable income of residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita disposable income of urban residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita disposable income of rural residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita consumption expenditure of residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita consumption expenditure of urban residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita consumption expenditure of rural residents (yuan)&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="built_in">print</span>(df_shanghai)</span><br></pre></td></tr></table></figure><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/9.jpg" /></p><h2 id="partial-code-description">4. Partial code description</h2><h3 id="data-extraction">data extraction</h3><p>Getting the data in the table requires first analyzing the extractedjs file, which prints the following.</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/10.jpg" /></p><p>Strip the five layers of the list layer by layer to get the requiredsrdata</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/11.jpg" /></p><h3 id="request-website">Request website</h3><p>Request target URL (''?'' preceded by something)</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url=<span class="string">&#x27;https://data.stats.gov.cn/easyquery.htm&#x27;</span></span><br></pre></td></tr></table></figure><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/12.jpg" /></p><p>Request header, User-Agent: used to prove that you are a browser,just meet a certain format, not necessarily the same as your ownbrowser</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">headers=&#123;<span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0(Windows;U;Windows NT6.1;en-US;rv:1.9.1.6) Geko/20091201 Firefox/3.5.6&#x27;</span>&#125;<span class="comment">#browser agent</span></span><br></pre></td></tr></table></figure><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/13.jpg" /></p><p>Construct the parameter key-value pairs, the following parameterswill be concatenated with &amp; and placed in the ''?'' of the linkfollowed by</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">key=&#123;&#125;</span><br><span class="line">key[<span class="string">&#x27;m&#x27;</span>]=<span class="string">&#x27;QueryData&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;dbcode&#x27;</span>]=<span class="string">&#x27;fsjd&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;rowcode&#x27;</span>]=<span class="string">&#x27;zb&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;colcode&#x27;</span>]=<span class="string">&#x27;sj&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;wds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;: &quot;reg&quot;, &quot;valuecode&quot;: &quot;310000&quot;&#125;]&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;k1&#x27;</span>]=<span class="built_in">str</span>(getTime())  </span><br><span class="line">key[<span class="string">&#x27;dfwds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;: &quot;zb&quot;, &quot;valuecode&quot;: &quot;A0300&quot;&#125;,&#123;&quot;wdcode&quot;: &quot;sj&quot;, &quot;valuecode&quot;: &quot;LAST6&quot;&#125;]&#x27;</span></span><br></pre></td></tr></table></figure><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/14.jpg" /></p><p>Some of the parameters can be seen in the position shown below, someof them are not shown by default, if you need to show the same page, youneed to select the corresponding option in the option box</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/15.jpg" /></p><h2 id="save-data-to-excel-sheet">5. Save data to excel sheet</h2><p>The data crawled by the crawler is now stored in panda.dataframeformat, and can be saved directly in an excel table using the to_excel()function</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># write object for this Excel workbook, use this method to save multiple worksheets</span></span><br><span class="line">    write = pd.ExcelWriter(<span class="string">&#x27;F:/Ivory_Tower/norm/provincial quarterly data_urban and rural residents income and expenditure.xls&#x27;</span>) <span class="comment"># The path can be set by yourself, there is no such file will create one on its own, if it exists, write will overwrite the original content</span></span><br><span class="line">    df_shanghai.to_excel(write,sheet_name=<span class="string">&#x27;Shanghai&#x27;</span>)</span><br><span class="line">    <span class="comment"># If you climb multiple provinces, you can write to multiple worksheets and must add save() to save the data</span></span><br><span class="line">    write.save()</span><br></pre></td></tr></table></figure><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/16.jpg" /></p><h2 id="table-optimization-optional">6. Table optimization(optional)</h2><p>You can optimize the table format with the help of python code, asshown above the results are not satisfactory, at least the need toautomatically adjust the column width.</p><p>Here I use xlwings library, you need to first download thecorresponding library in the command line</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install xlwings</span><br><span class="line">pip install pywin32</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Use the xlwings library to edit and organize Excel tables with python</span></span><br><span class="line"><span class="keyword">import</span> xlwings <span class="keyword">as</span> xw</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app=xw.App(visible=<span class="literal">False</span>,add_book=<span class="literal">False</span>) <span class="comment"># process is not visible, no new worksheet is added</span></span><br><span class="line">    wb=app.books.<span class="built_in">open</span>(<span class="string">r&#x27;F:/Ivory_Tower/norm/province_quarterly_income_and_expense_of_urban_rural_residents.xls&#x27;</span>)</span><br><span class="line">    <span class="comment"># wb is the new workbook (workbook)</span></span><br><span class="line">    <span class="comment"># For each of the 8 worksheets, do the following</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>): </span><br><span class="line">        rng=wb.sheets[i].<span class="built_in">range</span>(<span class="string">&#x27;A1:H20&#x27;</span>) <span class="comment"># select these cells</span></span><br><span class="line">        rng.api.HorizontalAlignment = -<span class="number">4108</span> <span class="comment"># center the text horizontally</span></span><br><span class="line">        rng.autofit() <span class="comment"># automatically adjust the row height and column width</span></span><br><span class="line">    wb.save()</span><br><span class="line">    wb.close()</span><br><span class="line">    app.quit()</span><br></pre></td></tr></table></figure><p>Run the code, you can get the following effect (subsequently crawledsome other provinces, modify the corresponding parameters at the key canbe)</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/17.jpg" /></p><h2 id="references">7. References</h2><p>The history of super detailed python crawl the National Bureau ofStatistics data:https://blog.csdn.net/qq_41988893/article/details/103017854</p><p>If you report a variety of other inexplicable errors, you can commentor private letter to ask ~</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;develop-web-crawling-in-a-national-statistic-institute&quot;&gt;Develop
Web Crawling in A National Statistic Institute&lt;/h1&gt;
&lt;p&gt;** This exp</summary>
      
    
    
    
    <category term="project" scheme="https://serika-onoe.github.io/categories/project/"/>
    
    
    <category term="python" scheme="https://serika-onoe.github.io/tags/python/"/>
    
    <category term="crawler" scheme="https://serika-onoe.github.io/tags/crawler/"/>
    
  </entry>
  
  <entry>
    <title>Python爬虫爬取国家统计局数据</title>
    <link href="https://serika-onoe.github.io/2021/01/13/Python%E7%88%AC%E8%99%AB%E7%88%AC%E5%8F%96%E5%9B%BD%E5%AE%B6%E7%BB%9F%E8%AE%A1%E5%B1%80%E6%95%B0%E6%8D%AE/"/>
    <id>https://serika-onoe.github.io/2021/01/13/Python%E7%88%AC%E8%99%AB%E7%88%AC%E5%8F%96%E5%9B%BD%E5%AE%B6%E7%BB%9F%E8%AE%A1%E5%B1%80%E6%95%B0%E6%8D%AE/</id>
    <published>2021-01-12T16:12:47.000Z</published>
    <updated>2022-12-12T14:35:22.494Z</updated>
    
    <content type="html"><![CDATA[<h1 id="python-爬虫爬取国家统计局数据">Python爬虫爬取国家统计局数据</h1><p><strong>本次实验以爬取“<ahref="https://data.stats.gov.cn/index.htm">国家统计局</a>”首页中的【上海市城乡居民收支基本情况】为例，国家统计局其他页面的爬取方法大同小异</strong></p><h2 id="爬虫基本流程">1.爬虫基本流程</h2><ol type="1"><li>发起请求：通过http/https库向目标站点发起请求，即发送一个request，请求可以包含额外的headers等信息，等待服务器响应</li><li>获取相应内容：如果服务器能正常响应，会得到一个response，response的内容便是所要获取的页面内容，类型可能有HTML，json字符串，二进制数据（如图片视频）等类型</li><li>解析内容：得到的内容可能是HTML，可以用正则表达式，网页解析库进行解析，可能是json，可以直接转为json对象，可能是二进制数据，可以做保存或者进一步的处理<strong>（本次实验得到的解析内容是json）</strong></li><li>保存数据：可以存为文本，也可以保存至数据库，或者特定格式的文件</li></ol><h2 id="打开网页并分析">2.打开网页并分析</h2><p>国家统计局的网站很奇怪，明明是https却会告警不安全，首次打开界面如下（本人使用的是谷歌浏览器）</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/1.jpg" /></p><p>点击“高级”-“继续前往”，方可进入首页</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/2.jpg" /></p><p>选择“季度数据”-“分省季度数据”</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/3.jpg" /></p><p>选择“人民生活”-“城乡收支情况”</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/4.jpg" /></p><p>地区修改为“上海市”</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/5.jpg" /></p><p>按下F12，进入浏览器调试模式</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/6.jpg" /></p><p>刷新重新获取网页信息，找到easyquery.htm?m=QueryData&amp;dbc...的文件。可以先选中"XHR"过滤条件，缩小查找范围</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/7.jpg" /></p><p>怎么确认这个文件就包含有我们要找的数据呢？点击“response”板块，向右拖动滑块可以看到表格数据可以一一对应（但数据并没有连续出现）</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/8.jpg" /></p><p><strong>注意：这里的data和strdata看上去一样，但实际格式不一样，data是int或double格式，strdata是str格式，这个表格有一些空数据行，字符串格式方便做判断，字符串转数字使用eval()即可</strong></p><h2 id="完整代码及解析">3.完整代码及解析</h2><p><strong>注：缺少的库可以在命令行使用pip命令安装，如缺少requests库，可以在命令行输入命令</strong></p><p><code>pip install requests</code></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib3 </span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用urllib3.disable_warnings()在关闭SSL认证（verify=False）情况下</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将requests请求禁用安全请求警告</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests    <span class="comment"># 使用Requests发送网络请求</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time      <span class="comment"># 用来获取时间戳(计算当前时间，用于网页验证)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json      <span class="comment"># 处理json文件</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  <span class="comment"># 处理数组</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd  <span class="comment"># np.array()转换成pd.DataFrame格式，再使用to_excel()写入excel表格</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取毫秒级时间戳，用于网页验证</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getTime</span>():</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">int</span>(<span class="built_in">round</span>(time.time() * <span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据预处理，获取json列表中层层包裹的strdata元素（数据）</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getList</span>(<span class="params">length</span>):</span><br><span class="line"></span><br><span class="line">  <span class="type">List</span>=[]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(length):</span><br><span class="line"></span><br><span class="line">​    temp = js[<span class="string">&#x27;returndata&#x27;</span>][<span class="string">&#x27;datanodes&#x27;</span>][i][<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;strdata&#x27;</span>]</span><br><span class="line"></span><br><span class="line">​    <span class="comment"># 城乡居民收支列表中，原网站有同比增长数据为空，若直接使用eval()会报错，需要先判断</span></span><br><span class="line"></span><br><span class="line">​    <span class="keyword">if</span>(<span class="built_in">len</span>(temp)!=<span class="number">0</span>):</span><br><span class="line"></span><br><span class="line">​      <span class="comment"># eval()数字转字符串</span></span><br><span class="line"></span><br><span class="line">​      <span class="type">List</span>.append(<span class="built_in">eval</span>(temp))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="type">List</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 请求目标网址(链接?前面的东西)</span></span><br><span class="line"></span><br><span class="line">  url=<span class="string">&#x27;https://data.stats.gov.cn/easyquery.htm&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 请求头，User-Agent: 用来证明你是浏览器，满足一定格式即可，不一定和自己的浏览器一样</span></span><br><span class="line"></span><br><span class="line">  headers=&#123;<span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0(Windows;U;Windows NT6.1;en-US;rv:1.9.1.6) Geko/20091201 Firefox/3.5.6&#x27;</span>&#125;<span class="comment">#浏览器代理</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 构造参数键值对，具体数值从网页结构参数中获取</span></span><br><span class="line"></span><br><span class="line">  key=&#123;&#125;</span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;m&#x27;</span>]=<span class="string">&#x27;QueryData&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;dbcode&#x27;</span>]=<span class="string">&#x27;fsjd&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;rowcode&#x27;</span>]=<span class="string">&#x27;zb&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;colcode&#x27;</span>]=<span class="string">&#x27;sj&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;wds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;:&quot;reg&quot;,&quot;valuecode&quot;:&quot;310000&quot;&#125;]&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;k1&#x27;</span>]=<span class="built_in">str</span>(getTime()) </span><br><span class="line"></span><br><span class="line">  <span class="comment"># &quot;wdcode&quot;:&quot;reg&quot; 地区栏</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 上海 310000 </span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;dfwds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;:&quot;zb&quot;,&quot;valuecode&quot;:&quot;A0300&quot;&#125;,&#123;&quot;wdcode&quot;:&quot;sj&quot;,&quot;valuecode&quot;:&quot;LAST6&quot;&#125;]&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># &quot;wdcode&quot;:&quot;zb&quot; 选取左侧哪个条目,&quot;wdcode&quot;:&quot;sj&quot;选项框中选取&quot;最近6季度&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 禁用安全请求警告</span></span><br><span class="line"></span><br><span class="line">  requests.packages.urllib3.disable_warnings()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 发出请求，使用post方法，这里使用前面自定义的头部和参数</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># ！！！verify=False，国家统计局20年下半年改用https协议,若不加该代码无法通过SSL验证</span></span><br><span class="line"></span><br><span class="line">  r = requests.post(url, headers=headers, params=key,verify=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 使用json库中loads函数，将r.text字符串解析成dict字典格式存储于js中</span></span><br><span class="line"></span><br><span class="line">  js = json.loads(r.text)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 得到所需数据的一维数组，利用np.array().reshape()整理为二维数组</span></span><br><span class="line"></span><br><span class="line">  length=<span class="built_in">len</span>(js[<span class="string">&#x27;returndata&#x27;</span>][<span class="string">&#x27;datanodes&#x27;</span>])</span><br><span class="line"></span><br><span class="line">  res=getList(length)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 总数据划分成6行的格式</span></span><br><span class="line"></span><br><span class="line">  array=np.array(res).reshape(<span class="built_in">len</span>(res)//<span class="number">6</span>,<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># np.array()转换成pd.DataFrame格式，后续可使用to_excel()直接写入excel表格</span></span><br><span class="line"></span><br><span class="line">  df_shanghai=pd.DataFrame(array)</span><br><span class="line"></span><br><span class="line">  df_shanghai.columns=[<span class="string">&#x27;2020年第三季度&#x27;</span>,<span class="string">&#x27;2020年第二季度&#x27;</span>,<span class="string">&#x27;2020年第一季度&#x27;</span>,<span class="string">&#x27;2019年第四季度&#x27;</span>,</span><br><span class="line"></span><br><span class="line">​        <span class="string">&#x27;2019年第三季度&#x27;</span>,<span class="string">&#x27;2019年第二季度&#x27;</span>]</span><br><span class="line"></span><br><span class="line">  df_shanghai.index=[<span class="string">&#x27;居民人均可支配收入累计值(元)&#x27;</span>,</span><br><span class="line"></span><br><span class="line">​       <span class="string">&#x27;城镇居民人均可支配收入累计值(元)&#x27;</span>,</span><br><span class="line"></span><br><span class="line">​       <span class="string">&#x27;农村居民人均可支配收入累计值(元)&#x27;</span>,</span><br><span class="line"></span><br><span class="line">​       <span class="string">&#x27;居民人均消费支出累计值(元)&#x27;</span>,</span><br><span class="line"></span><br><span class="line">​        <span class="string">&#x27;城镇居民人均消费支出累计值(元)&#x27;</span>,</span><br><span class="line"></span><br><span class="line">​       <span class="string">&#x27;农村居民人均消费支出累计值(元)&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="built_in">print</span>(df_shanghai)</span><br></pre></td></tr></table></figure><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/9.jpg" /></p><h2 id="部分代码说明">4.部分代码说明</h2><h3 id="数据提取">数据提取</h3><p>得到表格中的数据需要先分析提取到的js文件，打印内容如下：</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/10.jpg" /></p><p>将五层列表层层剥开，得到需要的strdata</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/11.jpg" /></p><h3 id="请求网站">请求网站</h3><p>请求目标网址(''?''前面的东西)</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url=<span class="string">&#x27;https://data.stats.gov.cn/easyquery.htm&#x27;</span></span><br></pre></td></tr></table></figure><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/12.jpg" /></p><p>请求头，User-Agent:用来证明你是浏览器，满足一定格式即可，不一定要和自己的浏览器一样</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">headers=&#123;<span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0(Windows;U;Windows NT6.1;en-US;rv:1.9.1.6) Geko/20091201 Firefox/3.5.6&#x27;</span>&#125;<span class="comment">#浏览器代理</span></span><br></pre></td></tr></table></figure><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/13.jpg" /></p><p>构造参数键值对，下列参数会以 &amp; 连接，放在链接的''?''后面</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">key=&#123;&#125;</span><br><span class="line">key[<span class="string">&#x27;m&#x27;</span>]=<span class="string">&#x27;QueryData&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;dbcode&#x27;</span>]=<span class="string">&#x27;fsjd&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;rowcode&#x27;</span>]=<span class="string">&#x27;zb&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;colcode&#x27;</span>]=<span class="string">&#x27;sj&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;wds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;:&quot;reg&quot;,&quot;valuecode&quot;:&quot;310000&quot;&#125;]&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;k1&#x27;</span>]=<span class="built_in">str</span>(getTime())  </span><br><span class="line">key[<span class="string">&#x27;dfwds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;:&quot;zb&quot;,&quot;valuecode&quot;:&quot;A0300&quot;&#125;,&#123;&quot;wdcode&quot;:&quot;sj&quot;,&quot;valuecode&quot;:&quot;LAST6&quot;&#125;]&#x27;</span></span><br></pre></td></tr></table></figure><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/14.jpg" /></p><p>部分参数可以从下图所示位置查看到，有些不显示的为默认，如果需要显示相同页面，需选取选项框中的相应选项</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/15.jpg" /></p><h2 id="数据保存到excel表格">5.数据保存到excel表格</h2><p>爬虫爬到的数据现以panda.dataframe格式存储，可以利用to_excel()函数，直接保存在excel表格中</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># write对象为该Excel工作簿，使用该方法保存多个工作表</span></span><br><span class="line">    write = pd.ExcelWriter(<span class="string">&#x27;F:/Ivory_Tower/norm/分省季度数据_城乡居民收支.xls&#x27;</span>) <span class="comment">#该路径自己设置即可，没有该文件的话会自行创建一个，存在的话写入会覆盖原内容</span></span><br><span class="line">    df_shanghai.to_excel(write,sheet_name=<span class="string">&#x27;上海&#x27;</span>)</span><br><span class="line">    <span class="comment">#如果爬多个省份的数据，可以写入多个工作表，且必须要加上save()保存</span></span><br><span class="line">    write.save()</span><br></pre></td></tr></table></figure><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/16.jpg" /></p><h2 id="表格优化可选">6.表格优化（可选）</h2><p>可以借助python代码，优化表格格式，如上图所示的结果不尽人意，至少还需要自动调整列宽。</p><p>这里本人采用xlwings库，需要先在命令行下载相应的库</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install xlwings</span><br><span class="line">pip install pywin32</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用xlwings库，利用python编辑整理Excel表格</span></span><br><span class="line"><span class="keyword">import</span> xlwings <span class="keyword">as</span> xw</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app=xw.App(visible=<span class="literal">False</span>,add_book=<span class="literal">False</span>) <span class="comment">#过程不可见，不添加新工作表</span></span><br><span class="line">    wb=app.books.<span class="built_in">open</span>(<span class="string">r&#x27;F:/Ivory_Tower/norm/分省季度数据_城乡居民收支.xls&#x27;</span>)</span><br><span class="line">    <span class="comment"># wb就是新建的工作簿(workbook)</span></span><br><span class="line">    <span class="comment"># 对8个工作表，分别进行操作</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>): </span><br><span class="line">        rng=wb.sheets[i].<span class="built_in">range</span>(<span class="string">&#x27;A1:H20&#x27;</span>)      <span class="comment"># 选中这些单元格</span></span><br><span class="line">        rng.api.HorizontalAlignment = -<span class="number">4108</span>   <span class="comment"># 文字水平方向居中</span></span><br><span class="line">        rng.autofit()                         <span class="comment"># 自动调整行高列宽</span></span><br><span class="line">    wb.save()</span><br><span class="line">    wb.close()</span><br><span class="line">    app.quit()</span><br></pre></td></tr></table></figure><p>运行代码，即可得到以下效果（后续多爬了其他一些省份，在key处修改相应参数即可）</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/17.jpg" /></p><h2 id="参考资料">7.参考资料</h2><p>史上超详细python爬取国家统计局数据：https://blog.csdn.net/qq_41988893/article/details/103017854</p><p>如果报其他各种各样莫名其妙的错，可以评论或私信询问哦~</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;python-爬虫爬取国家统计局数据&quot;&gt;Python
爬虫爬取国家统计局数据&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;本次实验以爬取“&lt;a
href=&quot;https://data.stats.gov.cn/index.htm&quot;&gt;国家统计局&lt;/a&gt;”首页中的【上海市城乡</summary>
      
    
    
    
    <category term="项目详情" scheme="https://serika-onoe.github.io/categories/%E9%A1%B9%E7%9B%AE%E8%AF%A6%E6%83%85/"/>
    
    
    <category term="Python" scheme="https://serika-onoe.github.io/tags/Python/"/>
    
    <category term="爬虫" scheme="https://serika-onoe.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>In-game Card Draw Mechanism Summary</title>
    <link href="https://serika-onoe.github.io/2020/09/06/In-game%20Card%20Draw%20Mechanism%20Summary/"/>
    <id>https://serika-onoe.github.io/2020/09/06/In-game%20Card%20Draw%20Mechanism%20Summary/</id>
    <published>2020-09-06T03:00:00.000Z</published>
    <updated>2022-12-12T14:42:09.150Z</updated>
    
    <content type="html"><![CDATA[<h2 id="write-in-front">Write in front</h2><p>Card games are very good at carrying the core element of acg -"character", card draws have a great positive effect on inventorycurrency consumption and new currency, and players who participated incard draws also account for a high percentage of rechargeable users.Card draw is indeed a very important payment point at the moment</p><p>But I know that "Xuan does not change the wrong, krypton can changethe life", and because it is a light player and do not want to chargemoney to become stronger, so the card game is not played, Yin Yang Shi,Tomorrow's Ark, sword and expedition are slightly contact, and each gamehas its own card draw probability.</p><p>The SSR is about 1%, and the probability of the sword and expeditionis about 4.8%, but for the sake of user experience, the most importantthing is not to let the time players open up the gap of RMB players, notto violate the principle of big R crush small R, so the so-called randomis basically pseudo-random.</p><p>The pure dry goods, in order not to affect the reading will not putthe picture, the following introduction of some common card drawmechanism.</p><h3 id="guarantee-mechanism">① Guarantee mechanism</h3><p>This is the simplest and most common mechanism, such as the "King ofGlory", the number of purchases reached 361 times, the probability ofglory crystal output is 100%. The two guaranteed mechanisms of "Swordand Expedition", 30 draws must be purple card, in the same card poolcumulative draw 30 times to get a purple card hero whether it is asingle draw or continuous draw, as long as the number reaches that mustbe purple card.</p><p>There is also a guaranteed mechanism is 10 consecutive draws must bea rare or elite level hero, and 30 draws is not the same place is onlyapplicable to ten consecutive draws and not applicable to ten singledraws.</p><p>The guarantee mechanism ensures the ultimate player experience</p><h3 id="metaphysical-lottery-method">② Metaphysical lottery method</h3><p>In some card-drawing games it is used for certain purposes, probablybecause the game developers sometimes refer to other data when writingthe card-drawing procedure, and then add certain algorithms to decidewhich card to draw, which is where the player metaphysics comesfrom.</p><p>If the referenced data is the current system time, then there is apossibility that "the card draw rate is high at a certain time in themorning, or the rate is high in the first 10 minutes of every hour".</p><p>Although the result is decided in the server at the moment you drawthe card, it has nothing to do with what pattern is drawn or whichmethod is used, but the game makers are still happy to leave aplayer-led process, so that players believe that it is the card drawingprocess that affects the result of card drawing, and the process is fullof rituals.</p><h3id="probability-increment-i-dont-know-if-the-industry-is-called-water-level">③Probabilityincrement (I don't know if the industry is called water level)</h3><p>Incremental probability method, refers to the card draw, the moretimes the card is drawn, the higher the burst rate of card draw method.If you have drawn before you have accumulated this value, then theprobability is returned to zero.</p><p>It can keep the player's game experience in a more balancedposition.</p><h3 id="prize-pool-division">④ Prize pool division</h3><p>This method of card drawing is more complicated and is more common ingames that frequently release new cards.</p><p>When a player draws, it is determined which prize pool the playerenters (R,SR,SSR) and then which card the player draws in that pool. Ifa new card is officially added, a single pool will be created and an oldcard will be implicitly removed, so players will not be too concernedabout the rate of old cards and will be happy to draw more newcards.</p><h3 id="scripted-card-draw">⑤ Scripted card draw</h3><p>All of the decks in Air Dangling Solitaire are already written, andeach time you start a game, you pick one from the deck script.</p><p>The game "Landlord" is officially written to have multiple pairs,planes and bombs, and randomly dealt cards are likely to appear as loosecards.</p><h3 id="kryptonite-distinguishes-card-draw">⑥Kryptonite distinguishescard draw</h3><p>The original game is to recharge how much to send a lottery, andgenerally get very precious game props. Now a data bar will be addedimplicitly to calculate the amount of player recharge and divide thelevel to adjust the probability to improve the game experience forkryptonite players.</p><p>If a certain currency can be obtained both from in-game liver and theoption to recharge, then the official can secretly set a status bar todistinguish between the activity liver and the recharge, and each time alottery is drawn, it will identify which type of diamond is used forthis lottery. If you use both types of diamonds at the same time, thedefault may be the one you got by recharging, and then the probabilitywill be greater than the one you got by using the liver.</p><h3 id="other-ways-to-play-with-card-draw-promotions">⑦ Other ways toplay with card draw promotions</h3><p>A common way to show this is to enter the game and just give theplayer a sum of money enough for the first draw, guiding the player todo the draw and then get precious props.</p><p>Or when drawing, the system suddenly reminds you: you get a chance tobuy rare props with an added time limit.</p><p>There is also a way to adjust the burst rate of different itemsaccording to the prop needs of new players. For example, if thecollection set is missing that one part, it is likely to pop out whenthe lottery is drawn.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;write-in-front&quot;&gt;Write in front&lt;/h2&gt;
&lt;p&gt;Card games are very good at carrying the core element of acg -
&quot;character&quot;, card draws have</summary>
      
    
    
    
    <category term="collection" scheme="https://serika-onoe.github.io/categories/collection/"/>
    
    
    <category term="acg" scheme="https://serika-onoe.github.io/tags/acg/"/>
    
    <category term="card draw" scheme="https://serika-onoe.github.io/tags/card-draw/"/>
    
    <category term="game" scheme="https://serika-onoe.github.io/tags/game/"/>
    
  </entry>
  
  <entry>
    <title>游戏内抽卡机制总结</title>
    <link href="https://serika-onoe.github.io/2020/09/06/%E6%B8%B8%E6%88%8F%E5%86%85%E6%8A%BD%E5%8D%A1%E6%9C%BA%E5%88%B6%E6%80%BB%E7%BB%93/"/>
    <id>https://serika-onoe.github.io/2020/09/06/%E6%B8%B8%E6%88%8F%E5%86%85%E6%8A%BD%E5%8D%A1%E6%9C%BA%E5%88%B6%E6%80%BB%E7%BB%93/</id>
    <published>2020-09-06T03:00:00.000Z</published>
    <updated>2022-12-11T03:55:10.746Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面">写在前面</h2><p>卡牌类游戏很好地搭载了二次元的核心元素——“角色”，抽卡活动对库存货币消耗和新增货币均有很大的正面作用，且参与了抽卡活动的玩家也占了充值用户相当高的比例。抽卡活动确实是当前非常重要的付费点</p><p>但本人深知“玄不改非，氪能改命”，而因为是轻度玩家并不想充钱变强，所以卡牌游戏玩的并不多，阴阳师、明日方舟、剑与远征等都略有接触，而每个游戏都有着属于自己的抽卡概率。</p><p>像阴阳师的SSR大体在1%左右，而剑与远征的概率在4.8%左右，但为了用户体验，最重要的是不能让时间玩家拉开RMB玩家的差距，不能违反大R碾压小R的原则，所以所谓随机基本都是伪随机。</p><p>纯干货，为了不影响阅读就不放图片了，下面介绍一些常见的抽卡机制。</p><h3 id="保底机制">①保底机制</h3><p>这是最简单，也最普遍的一种机制，如《王者荣耀》，购买次数到达361次时，荣耀水晶产出概率为100%。《剑与远征》两个保底机制，30抽必出紫卡，在同卡池内累计抽30次即可获得出一张紫卡英雄不论是单抽还是连抽，只要数量达到即必出紫卡。</p><p>还有一个保底机制就是10连抽必出一个稀有或者精英级别的英雄，和30抽不一样的地方在于只能是适用于十连抽而不能适用于十次单抽。</p><p>保底机制保证了玩家的最终体验</p><h3 id="玄学抽奖法">②玄学抽奖法</h3><p>在一些抽卡游戏里是用一定作用的，可能由于游戏开发者在写抽卡的程序时，有时候会引用其他数据，然后增加一定算法，来决定抽到哪一张卡，这就是玩家玄学的由来。</p><p>如果引用的数据是当前系统时间，那么有可能出现“凌晨某个时间点抽卡中奖率高，或者每小时的前十分钟中奖率高”</p><p>虽说结果都在你抽卡的那一刻，在服务器就决定好，这就与抽卡画出什么图案、使用哪种方法无关，但游戏厂商还是乐意留下一个玩家主导的过程，让玩家相信是抽卡过程影响抽卡结果，对抽卡这一过程充满仪式感。</p><h3id="概率递增不知道业内是不是叫水位">③概率递增（不知道业内是不是叫水位）</h3><p>概率递增法，是指抽卡时，抽卡次数越多，爆率越高的抽卡方法。如果在还没累积到这个数值前已经抽到，那么就将概率归零。</p><p>可以让玩家的游戏体验保持在一个比较均衡的位置。</p><h3 id="奖池划分">④奖池划分</h3><p>这种抽卡方法比较复杂，在一些频繁出新卡的游戏里比较多。</p><p>当玩家抽取时候，会先判定玩家进入哪个奖池（R,SR,SSR），然后再判定玩家在这个奖池里抽到哪一张卡。如果官方加入一张新卡，会单出一个奖池，暗中去掉一张旧卡，玩家不会太过关注旧卡的出卡率，也乐意多抽出新卡。</p><h3 id="剧本抽卡">⑤剧本抽卡</h3><p>《空当接龙》所有的牌组都已经写好，每次开始游戏，就从牌组剧本中挑选一个。</p><p>《斗地主》游戏官方会特意编写出多连对，多飞机，多炸弹的牌组，随机发牌很可能出现散牌。</p><h3 id="氪金区分抽卡">⑥氪金区分抽卡</h3><p>原来的游戏是充值多少送一次抽奖，且一般都能得到非常珍贵的游戏道具。现在会暗中增加一个数据栏，计算玩家充值的数量，划分等级调整概率，来提高氪金玩家的游戏体验。</p><p>如果某种货币既可以从游戏内肝到，也可以选择充值得到，那么官方可以暗中设定一个状态栏，将活动肝到的和充值得到的区别开，每次抽奖，都会识别这次抽奖所使用的钻石是哪种类型的钻石。如果使用的过程中两种同时使用，可能默认都是充值得到的，这时概率会比用肝到的大。</p><h3 id="与抽卡促销的其他玩法">⑦与抽卡促销的其他玩法</h3><p>常见的表现方式是进入游戏，就给玩家一笔足够首抽的钱，引导玩家进行抽奖然后获得珍贵道具。</p><p>或者抽奖时，系统突然提醒你：你获得了一个购买稀有道具的机会，并附带增加时间限制。</p><p>还有一种方法是根据新玩家的道具需求，调整不同物品的爆率。比如收集套装正缺那一个部件，很可能抽奖的时候就爆出来。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;写在前面&quot;&gt;写在前面&lt;/h2&gt;
&lt;p&gt;卡牌类游戏很好地搭载了二次元的核心元素——“角色”，抽卡活动对库存货币消耗和新增货币均有很大的正面作用，且参与了抽卡活动的玩家也占了充值用户相当高的比例。抽卡活动确实是当前非常重要的付费点&lt;/p&gt;
&lt;p&gt;但本人深知“玄不改</summary>
      
    
    
    
    <category term="游戏" scheme="https://serika-onoe.github.io/categories/%E6%B8%B8%E6%88%8F/"/>
    
    
    <category term="二次元" scheme="https://serika-onoe.github.io/tags/%E4%BA%8C%E6%AC%A1%E5%85%83/"/>
    
    <category term="抽卡" scheme="https://serika-onoe.github.io/tags/%E6%8A%BD%E5%8D%A1/"/>
    
    <category term="游戏" scheme="https://serika-onoe.github.io/tags/%E6%B8%B8%E6%88%8F/"/>
    
  </entry>
  
  <entry>
    <title>我的第一篇博客</title>
    <link href="https://serika-onoe.github.io/2020/02/11/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/"/>
    <id>https://serika-onoe.github.io/2020/02/11/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/</id>
    <published>2020-02-11T04:14:00.000Z</published>
    <updated>2022-12-12T14:40:38.284Z</updated>
    
    <content type="html"><![CDATA[<h1 id="为什么要写博客">为什么要写博客</h1><p>记录博客是酝酿很久的想法，相信多数人作出这一决定也都经历了较长时间的拖延症hh。不过除了习惯性偷懒，也有出于对自身技术水平不自信的考量，毕竟大牛是极少数，多数人不过是在平均线上徘徊。</p><p>不过大脑做决定并不是纯粹理性的，反而主要凭感性。立下了靶子，定下来方向，理性思维才会积极地把行为合理化。</p><p>对为什么突发奇想开始记录博客，个人总结了如下动机：</p><ul><li><p>无论课内外，本人都已养成了动笔前先查阅大量资料的习惯。心里对那些具有开源精神的大牛们、前辈们充满敬意和感激。很多时候，一个简洁清晰的结论、一行高度概括的代码，单靠自己的探索往往要事倍功半，甚至还可能因为其在知识盲区(UnknownUnknown)而作不必要的苦恼，被前辈们留下的博客文章中不经意地一语道破，这样的瞬间简直不要太多。</p></li><li><p>从一个纯小白进化到现在一个在很多领域都有些入门经验的....小白来说，也很希望把当时掉进去的坑补上，最起码在前面做个警示，新人在环境搭建阶段没必要走弯路，把重心放在解决需求的程序调试阶段，实现更高的自我提升效率。</p></li><li><p>俗话说得好：“好记性不如烂笔头。”之前看过一本讲如何高效记笔记的书，但纸面的笔记也常常无法翻阅。加上现在经常用手机浏览很多碎片化的知识点，得不到有效的整理，博客的存在比起私人笔记，也有种民主监督的意味在里头，避免个人认知偏差和局限。</p></li><li><p>还有《暗时间》，让我受益匪浅，学习的时候我也会经常想象如何把知识向一个小白讲解，而博客也相当于把这个过程实例化，可视化。</p></li></ul><h1 id="博客记录什么">博客记录什么</h1><p>大学期间，课内学的很多是原理层面的东西，课外兴趣广泛，为避免犯蜻蜓点水般浅尝辄止的毛病，我总结所学以下几个方面的知识技术，抽空进行记录：</p><ul><li>编程语言类：C、Python、JAVA等</li><li>软件安装类: Android Studio，WordPress等</li><li>音频编辑类：pr，ps，au等等</li></ul><p>博客更新频率尽量保持在一周一两次，在此先作个纪念，日后若需要再加更改。</p><p>有诗云:“青山一道同云雨，明月何曾是两乡。”</p><p>愿与诸君共勉。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;为什么要写博客&quot;&gt;为什么要写博客&lt;/h1&gt;
&lt;p&gt;记录博客是酝酿很久的想法，相信多数人作出这一决定也都经历了较长时间的拖延症hh。不过除了习惯性偷懒，也有出于对自身技术水平不自信的考量，毕竟大牛是极少数，多数人不过是在平均线上徘徊。&lt;/p&gt;
&lt;p&gt;不过大脑做决</summary>
      
    
    
    
    <category term="总结" scheme="https://serika-onoe.github.io/categories/%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="介绍" scheme="https://serika-onoe.github.io/tags/%E4%BB%8B%E7%BB%8D/"/>
    
  </entry>
  
  <entry>
    <title>My first blog</title>
    <link href="https://serika-onoe.github.io/2020/02/11/My%20first%20blog/"/>
    <id>https://serika-onoe.github.io/2020/02/11/My%20first%20blog/</id>
    <published>2020-02-11T04:14:00.000Z</published>
    <updated>2022-12-12T14:43:01.233Z</updated>
    
    <content type="html"><![CDATA[<h1 id="why-i-make-this-blog">Why I make this blog</h1><p>Blogging is an idea that has been brewing for a long time, and Ibelieve that most people have been procrastinating for a long time tomake this decision hh. However, besides habitual laziness, there is alsothe consideration that they are not confident of their technical level,after all, the big cows are very few, and most people are just hoveringaround the average line.</p><p>But the brain does not make decisions purely rational, but mainlybased on emotion. After setting up a target and setting down adirection, the rational mind will actively rationalize the behavior.</p><p>I have summarized the following motivations as to why I startedblogging on a whim.</p><ul><li><p>I have developed the habit of consulting a lot of informationbefore I start writing, both inside and outside the classroom. I have alot of respect and gratitude for those who have the spirit of opensource, the seniors. Many times, a concise and clear conclusion, a lineof highly generalized code, often rely on their own exploration to halfthe effort, and may even be in the knowledge of the blind (UnknownUnknown) and make unnecessary suffering, was left by the seniors in theblog article inadvertently a break, such moments simply not toomuch.</p></li><li><p>Evolved from a pure white to now a in many areas have someexperience in the beginning of the .... For the white guy, I also hopeto make up for the pit that I fell into at that time, at least to make awarning in front that there is no need for newcomers to take detours inthe environment building stage, and to focus on the debugging stage ofthe program to solve the needs and achieve higher self-improvementefficiency.</p></li><li><p>As the saying goes: "Good memory is better than bad penmanship."Before reading a book on how to take notes efficiently, but the papernotes are also often impossible to flip through. Nowadays, I often usemy cell phone to browse many fragmented knowledge points, which are noteffectively organized. The existence of blogs also has a kind ofdemocratic supervision in it than private notes, to avoid personalcognitive bias and limitations.</p></li><li><p>I often imagine how to explain the knowledge to a novice when Istudy, and blogging is equivalent to instantiating and visualizing thisprocess.</p></li></ul><h1 id="what-to-record">What to record</h1><p>During my bachelor years, I learned a lot of things at the principlelevel in class, and I have a wide range of interests outside of class.In order to avoid the problem of making a slapdash approach, I summarizethe knowledge and techniques I learned in the following areas and takethe time to record them.</p><ul><li>Programming languages: C, Python, JAVA, etc.</li><li>Software installation classes: Android Studio, WordPress, etc.</li><li>Audio editing: pr, ps, au, etc.</li></ul><p>Blog update frequency try to keep in a week or two, here first for amemorial, later if you need to add changes.</p><p>There is a poem: "green hills together with the clouds and rain, themoon has been two hometowns."</p><p>I hope the content in my blog may help you.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;why-i-make-this-blog&quot;&gt;Why I make this blog&lt;/h1&gt;
&lt;p&gt;Blogging is an idea that has been brewing for a long time, and I
believe that m</summary>
      
    
    
    
    <category term="summary" scheme="https://serika-onoe.github.io/categories/summary/"/>
    
    
    <category term="first" scheme="https://serika-onoe.github.io/tags/first/"/>
    
    <category term="introduction" scheme="https://serika-onoe.github.io/tags/introduction/"/>
    
  </entry>
  
</feed>
