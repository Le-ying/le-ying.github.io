<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Kung&#39;s Blog</title>
  
  <subtitle>Welcome to my blog!</subtitle>
  <link href="https://serika-onoe.github.io/atom.xml" rel="self"/>
  
  <link href="https://serika-onoe.github.io/"/>
  <updated>2022-12-30T14:02:48.011Z</updated>
  <id>https://serika-onoe.github.io/</id>
  
  <author>
    <name>Richard KUNG</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CS231n Assignment 1 (Updating)</title>
    <link href="https://serika-onoe.github.io/2022/12/20/CS231n-Assignment-1/"/>
    <id>https://serika-onoe.github.io/2022/12/20/CS231n-Assignment-1/</id>
    <published>2022-12-20T14:49:13.000Z</published>
    <updated>2022-12-30T14:02:48.011Z</updated>
    
    <content type="html"><![CDATA[<h1 id="cs231n-assignment-1">CS231n Assignment 1</h1><p>作业1分为五个部分：KNN、SVM、Softmax classifier、2层神经网络、HigherLevel Representations: Image Features.</p><p>建议作业完成顺序：</p><ol type="1"><li>k近邻分类：knn.ipynb &amp; k_nearest_neighbor.py</li><li>svm线性分类：svm.ipynb &amp; linear_svm.py &amp;linear_classifier.py</li><li>softmax线性分类：softmax.ipynb &amp; softmax.py</li><li>两层神经网络：two_layer_net.ipynb &amp; neural_net.py</li></ol><h1 id="k-nearest-neighbor-knn">k-Nearest Neighbor (kNN)</h1><p>在knn.ipynb中，调用了k_nearest_neighbor.py文件。</p><p>k近邻分类算法步骤如下介绍：</p><ol type="1"><li>记住所有训练图像</li><li>计算测试图像与所有训练图像的距离（常用L2距离）</li><li>选择与测试图像距离最小的k张训练图像</li><li>计算这k张图像所对应的类别出现的次数，选择出现次数最多的类别记为预测类别</li></ol><h2 id="k_nearest_neighbor.py">k_nearest_neighbor.py</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">KNearestNeighbor</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; a kNN classifier with L2 distance &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">#定义一个k近邻分类器的类</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h3 id="训练">训练</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, X, y</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Train the classifier. For k-nearest neighbors this is just</span></span><br><span class="line"><span class="string">    memorizing the training data.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - X: A numpy array of shape (num_train, D) containing the training data</span></span><br><span class="line"><span class="string">      consisting of num_train samples each of dimension D.</span></span><br><span class="line"><span class="string">    - y: A numpy array of shape (N,) containing the training labels, where</span></span><br><span class="line"><span class="string">         y[i] is the label for X[i].</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">#self.X_train 是训练数据，维度是 (N,D)，训练集有N个样本，每个样本特征是D维</span></span><br><span class="line">    <span class="comment">#self.y_train 是标签，维度是（N,）,即N个训练样本对应的标签</span></span><br><span class="line">    self.X_train = X</span><br><span class="line">    self.y_train = y</span><br></pre></td></tr></table></figure><h3id="预测计算测试图像和所有训练图像的l2距离">预测：计算测试图像和所有训练图像的L2距离</h3><p>预测时首先需要计算测试样本与所有训练样本的距离,然后根据距离判断样本的类别。</p><p>计算距离需要我们实现三种方法，分别为需要双重循环，单循环，不需要循环。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X, k=<span class="number">1</span>, num_loops=<span class="number">0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Predict labels for test data using this classifier.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - X: A numpy array of shape (num_test, D) containing test data consisting</span></span><br><span class="line"><span class="string">         of num_test samples each of dimension D.</span></span><br><span class="line"><span class="string">    - k: The number of nearest neighbors that vote for the predicted labels.</span></span><br><span class="line"><span class="string">    - num_loops: Determines which implementation to use to compute distances</span></span><br><span class="line"><span class="string">      between training points and testing points.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    - y: A numpy array of shape (num_test,) containing predicted labels for the</span></span><br><span class="line"><span class="string">      test data, where y[i] is the predicted label for the test point X[i].</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> num_loops == <span class="number">0</span>:</span><br><span class="line">        dists = self.compute_distances_no_loops(X)</span><br><span class="line">    <span class="keyword">elif</span> num_loops == <span class="number">1</span>:</span><br><span class="line">        dists = self.compute_distances_one_loop(X)</span><br><span class="line">    <span class="keyword">elif</span> num_loops == <span class="number">2</span>:</span><br><span class="line">        dists = self.compute_distances_two_loops(X)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;Invalid value %d for num_loops&quot;</span> % num_loops)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> self.predict_labels(dists, k=k)</span><br></pre></td></tr></table></figure><hr /><h4 id="双重循环实现">双重循环实现</h4><p>第i个测试样本与第j个训练样本的距离<spanclass="math inline">\(dist[i,j]\)</span>等于用第i个测试图像的特征向量减去第j个训练图像的特征向量的值</p><p><spanclass="math inline">\(dist[i,j]=\sqrt{\sum_{d}(x_{test[i,d]}-x_{train[j,d]})^2}\)</span></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/dij.png" /></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_distances_two_loops</span>(<span class="params">self, X</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute the distance between each test point in X and each training point</span></span><br><span class="line"><span class="string">    in self.X_train using a nested loop over both the training data and the</span></span><br><span class="line"><span class="string">    test data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - X: A numpy array of shape (num_test, D) containing test data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]</span></span><br><span class="line"><span class="string">      is the Euclidean distance between the ith test point and the jth training</span></span><br><span class="line"><span class="string">      point.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    num_test = X.shape[<span class="number">0</span>]</span><br><span class="line">    num_train = self.X_train.shape[<span class="number">0</span>]</span><br><span class="line">    dists = np.zeros((num_test, num_train))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_test):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(num_train):</span><br><span class="line">            <span class="comment">#####################################################################</span></span><br><span class="line">            <span class="comment"># <span class="doctag">TODO:</span>                                                             #</span></span><br><span class="line">            <span class="comment"># Compute the l2 distance between the ith test point and the jth    #</span></span><br><span class="line">            <span class="comment"># training point, and store the result in dists[i, j]. You should   #</span></span><br><span class="line">            <span class="comment"># not use a loop over dimension, nor use np.linalg.norm().          #</span></span><br><span class="line">            <span class="comment">#####################################################################</span></span><br><span class="line">            <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">            dists[i][j]=np.sqrt(np.<span class="built_in">sum</span>(np.square(X[i,:]-self.X_train[j,:])))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">    <span class="keyword">return</span> dists</span><br></pre></td></tr></table></figure><hr /><h4 id="单循环实现">单循环实现</h4><p>利用numpy的broadcast机制，可以直接计算第i张测试图像与所有训练样本的距离</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/dij_single.png" /></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_distances_one_loop</span>(<span class="params">self, X</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute the distance between each test point in X and each training point</span></span><br><span class="line"><span class="string">    in self.X_train using a single loop over the test data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Input / Output: Same as compute_distances_two_loops</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    num_test = X.shape[<span class="number">0</span>]</span><br><span class="line">    num_train = self.X_train.shape[<span class="number">0</span>]</span><br><span class="line">    dists = np.zeros((num_test, num_train))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_test):</span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span>                                                               #</span></span><br><span class="line">        <span class="comment"># Compute the l2 distance between the ith test point and all training #</span></span><br><span class="line">        <span class="comment"># points, and store the result in dists[i, :].                        #</span></span><br><span class="line">        <span class="comment"># Do not use np.linalg.norm().                                        #</span></span><br><span class="line">        <span class="comment">#######################################################################</span></span><br><span class="line">        <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">        dists[i,:]=np.sqrt(np.<span class="built_in">sum</span>(np.square(X[i,:]-self.X_train),axis=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">    <span class="keyword">return</span> dists</span><br></pre></td></tr></table></figure><hr /><h4 id="无循环实现">无循环实现</h4><p>两个矩阵不能直接相减，不用循环计算距离，考虑距离公式，同时需保证最后得到的dists.shape满足(num_test,num_train)=(500,5000)</p><p><span class="math inline">\((a-b)^2=a^2+b^2-2ab\)</span></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/dij_no.png" /></p><p>注意点：</p><ol type="1"><li>np.square，返回原列表每个元素的平方值，shape不变。</li><li>np.sum(,axis=1)按列相加（横向），我之前在这个地方没想通。以np.sum(np.square(self.X_train),axis = 1)为例：</li></ol><ul><li>np.shape(self.X_train)=(5000,3072)</li><li>np.shape(np.square(self.X_train))=(5000,3072)</li><li>np.shape(np.sum(np.square(self.X_train)))=(5000,)这表示的是一个含有5000个元素的一维数组，并不是(5000,1)具有5000行的二维list。因此可以被boardcasting,(1,5000)-&gt;(500,5000)</li></ul><ol start="3" type="1"><li>transpose针对二维及以上list有效。以np.transpose([np.sum(np.square(X),axis = 1)]))为例，结合第2点可知:</li></ol><ul><li>得到的np.sum(np.square(X), axis =1)]))是一个一维数组，shape为(500,)</li><li>因此加上[]变成(1,500)</li><li>之后转置得到(500,1),因此可以被boardcasting,(500,1)-&gt;(500,5000)</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_distances_no_loops</span>(<span class="params">self, X</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute the distance between each test point in X and each training point</span></span><br><span class="line"><span class="string">    in self.X_train using no explicit loops.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Input / Output: Same as compute_distances_two_loops</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    num_test = X.shape[<span class="number">0</span>]</span><br><span class="line">    num_train = self.X_train.shape[<span class="number">0</span>]</span><br><span class="line">    dists = np.zeros((num_test, num_train))</span><br><span class="line">    <span class="comment">#########################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span>                                                                 #</span></span><br><span class="line">    <span class="comment"># Compute the l2 distance between all test points and all training      #</span></span><br><span class="line">    <span class="comment"># points without using any explicit loops, and store the result in      #</span></span><br><span class="line">    <span class="comment"># dists.                                                                #</span></span><br><span class="line">    <span class="comment">#                                                                       #</span></span><br><span class="line">    <span class="comment"># You should implement this function using only basic array operations; #</span></span><br><span class="line">    <span class="comment"># in particular you should not use functions from scipy,                #</span></span><br><span class="line">    <span class="comment"># nor use np.linalg.norm().                                             #</span></span><br><span class="line">    <span class="comment">#                                                                       #</span></span><br><span class="line">    <span class="comment"># HINT: Try to formulate the l2 distance using matrix multiplication    #</span></span><br><span class="line">    <span class="comment">#       and two broadcast sums.                                         #</span></span><br><span class="line">    <span class="comment">#########################################################################</span></span><br><span class="line">    <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">    dists = np.sqrt(-<span class="number">2</span>*np.dot(X, self.X_train.T) + np.<span class="built_in">sum</span>(np.square(self.X_train), axis = <span class="number">1</span>) + np.transpose([np.<span class="built_in">sum</span>(np.square(X), axis = <span class="number">1</span>)]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">    <span class="keyword">return</span> dists</span><br></pre></td></tr></table></figure><h3id="预测根据k个最邻近距离中的多数确定标签">预测：根据K个最邻近距离中的多数确定标签</h3><ul><li>np.argsort() 返回一个数组排好序后各元素对应的原来的位置序号</li></ul><p>Examples:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#One dimensional array:</span></span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">np.argsort(x)</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#Two-dimensional array:</span></span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">0</span>, <span class="number">3</span>], [<span class="number">2</span>, <span class="number">2</span>]])</span><br><span class="line">x</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">2</span>]])</span><br><span class="line">ind = np.argsort(x, axis=<span class="number">0</span>)  <span class="comment"># sorts along first axis (down)</span></span><br><span class="line">ind</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">0</span>]])</span><br><span class="line">np.take_along_axis(x, ind, axis=<span class="number">0</span>)  <span class="comment"># same as np.sort(x, axis=0)</span></span><br><span class="line">array([[<span class="number">0</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">3</span>]])</span><br></pre></td></tr></table></figure><ul><li>np.bincount() 计算非负整数数组中每个值的出现次数。</li></ul><p>Examples:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#[0,1,2,3,4]</span></span><br><span class="line">np.bincount(np.arange(<span class="number">5</span>))</span><br><span class="line">array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">np.bincount(np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">7</span>]))</span><br><span class="line">array([<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br></pre></td></tr></table></figure><hr /><p>需要实现两个功能</p><ol type="1"><li><p>选择与测试图像最相似（距离最小）的k张训练图像np.argsort(dists[i])函数是将dist中的i行元素从小到大排列，并得到对应的index。然后再取前k个索引（也就是得到距离最近的k张图像的索引）</p></li><li><p>计算这k张图像所对应的类别出现的次数，选择出现次数最多的类别</p></li></ol><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict_labels</span>(<span class="params">self, dists, k=<span class="number">1</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Given a matrix of distances between test points and training points,</span></span><br><span class="line"><span class="string">    predict a label for each test point.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]</span></span><br><span class="line"><span class="string">      gives the distance betwen the ith test point and the jth training point.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    - y: A numpy array of shape (num_test,) containing predicted labels for the</span></span><br><span class="line"><span class="string">      test data, where y[i] is the predicted label for the test point X[i].</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    num_test = dists.shape[<span class="number">0</span>]</span><br><span class="line">    y_pred = np.zeros(num_test)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_test):</span><br><span class="line">        <span class="comment"># A list of length k storing the labels of the k nearest neighbors to</span></span><br><span class="line">        <span class="comment"># the ith test point.</span></span><br><span class="line">        closest_y = []</span><br><span class="line">        <span class="comment">#########################################################################</span></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span>                                                                 #</span></span><br><span class="line">        <span class="comment"># Use the distance matrix to find the k nearest neighbors of the ith    #</span></span><br><span class="line">        <span class="comment"># testing point, and use self.y_train to find the labels of these       #</span></span><br><span class="line">        <span class="comment"># neighbors. Store these labels in closest_y.                           #</span></span><br><span class="line">        <span class="comment"># Hint: Look up the function numpy.argsort.                             #</span></span><br><span class="line">        <span class="comment">#########################################################################</span></span><br><span class="line">        <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">        closest_y = self.y_train[np.argsort(dists[i])[:k]]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">        <span class="comment">#########################################################################</span></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span>                                                                 #</span></span><br><span class="line">        <span class="comment"># Now that you have found the labels of the k nearest neighbors, you    #</span></span><br><span class="line">        <span class="comment"># need to find the most common label in the list closest_y of labels.   #</span></span><br><span class="line">        <span class="comment"># Store this label in y_pred[i]. Break ties by choosing the smaller     #</span></span><br><span class="line">        <span class="comment"># label.                                                                #</span></span><br><span class="line">        <span class="comment">#########################################################################</span></span><br><span class="line">        <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">        y_pred[i] = np.argmax(np.bincount(closest_y))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="knn.ipynb">knn.ipynb</h2><p>讨论knn中k的取值问题</p><ul><li>np.array_split() 将一个数组拆分为多个子数组，可以大小不等。</li></ul><p>Examples:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.arange(<span class="number">8.0</span>)</span><br><span class="line">np.array_split(x, <span class="number">3</span>)</span><br><span class="line">[array([<span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>]), array([<span class="number">3.</span>,  <span class="number">4.</span>,  <span class="number">5.</span>]), array([<span class="number">6.</span>,  <span class="number">7.</span>])]</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">9</span>)</span><br><span class="line">np.array_split(x, <span class="number">4</span>)</span><br><span class="line">[array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]), array([<span class="number">3</span>, <span class="number">4</span>]), array([<span class="number">5</span>, <span class="number">6</span>]), array([<span class="number">7</span>, <span class="number">8</span>])]</span><br></pre></td></tr></table></figure><ul><li>dictionary.setdefault(keyname, value)返回具有指定键的项目的值。</li></ul><p>Examples:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">car = &#123;</span><br><span class="line">  <span class="string">&quot;brand&quot;</span>: <span class="string">&quot;Ford&quot;</span>,</span><br><span class="line">  <span class="string">&quot;model&quot;</span>: <span class="string">&quot;Mustang&quot;</span>,</span><br><span class="line">  <span class="string">&quot;year&quot;</span>: <span class="number">1964</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">x = car.setdefault(<span class="string">&quot;color&quot;</span>, <span class="string">&quot;White&quot;</span>)</span><br></pre></td></tr></table></figure><ul><li>hstack() 按列顺序(横向)把数组给堆叠起来</li></ul><p>Examples:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">b=[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line"><span class="built_in">print</span>(np.hstack((a,b)))</span><br><span class="line"><span class="comment">#[1 2 3 4 5 6 ]</span></span><br><span class="line"></span><br><span class="line">a=[[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>]]</span><br><span class="line">b=[[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>]]</span><br><span class="line">c=[[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>]]</span><br><span class="line">d=[[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>]]</span><br><span class="line"><span class="built_in">print</span>(np.hstack((a,b,c,d)))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[[1 1 1 1]</span></span><br><span class="line"><span class="string"> [2 2 2 2]</span></span><br><span class="line"><span class="string"> [3 3 3 3]]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><hr /><p>knn需要计算这k张图像所对应的类别出现的次数，选择出现次数最多的类别，那么问题来了，k应该取几效果会比较好呢？</p><p>这需要做两个任务：</p><ol type="1"><li>划分训练集</li><li>交叉验证</li></ol><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num_folds = <span class="number">5</span></span><br><span class="line">k_choices = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">8</span>, <span class="number">10</span>, <span class="number">12</span>, <span class="number">15</span>, <span class="number">20</span>, <span class="number">50</span>, <span class="number">100</span>]</span><br><span class="line"></span><br><span class="line">X_train_folds = []</span><br><span class="line">y_train_folds = []</span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span>                                                                        #</span></span><br><span class="line"><span class="comment"># Split up the training data into folds. After splitting, X_train_folds and    #</span></span><br><span class="line"><span class="comment"># y_train_folds should each be lists of length num_folds, where                #</span></span><br><span class="line"><span class="comment"># y_train_folds[i] is the label vector for the points in X_train_folds[i].     #</span></span><br><span class="line"><span class="comment"># Hint: Look up the numpy array_split function.                                #</span></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">X_train_folds = np.array_split(X_train,num_folds)</span><br><span class="line">y_train_folds = np.array_split(y_train,num_folds)</span><br><span class="line"></span><br><span class="line"><span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># A dictionary holding the accuracies for different values of k that we find</span></span><br><span class="line"><span class="comment"># when running cross-validation. After running cross-validation,</span></span><br><span class="line"><span class="comment"># k_to_accuracies[k] should be a list of length num_folds giving the different</span></span><br><span class="line"><span class="comment"># accuracy values that we found when using that value of k.</span></span><br><span class="line">k_to_accuracies = &#123;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span>                                                                        #</span></span><br><span class="line"><span class="comment"># Perform k-fold cross validation to find the best value of k. For each        #</span></span><br><span class="line"><span class="comment"># possible value of k, run the k-nearest-neighbor algorithm num_folds times,   #</span></span><br><span class="line"><span class="comment"># where in each case you use all but one of the folds as training data and the #</span></span><br><span class="line"><span class="comment"># last fold as a validation set. Store the accuracies for all fold and all     #</span></span><br><span class="line"><span class="comment"># values of k in the k_to_accuracies dictionary.                               #</span></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> k_choices:</span><br><span class="line">    k_to_accuracies.setdefault(k, [])</span><br><span class="line">    <span class="comment">#print(k_to_accuracies)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_folds):</span><br><span class="line">    classifier = KNearestNeighbor()</span><br><span class="line">    X_val_train = np.vstack(X_train_folds[<span class="number">0</span>:i] + X_train_folds[i+<span class="number">1</span>:])</span><br><span class="line">    y_val_train = np.hstack(y_train_folds[<span class="number">0</span>:i] + y_train_folds[i+<span class="number">1</span>:])</span><br><span class="line">    <span class="comment">#print(X_val_train, y_val_train)</span></span><br><span class="line">    classifier.train(X_val_train, y_val_train)</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> k_choices:</span><br><span class="line">        y_val_pred = classifier.predict(X_train_folds[i], k)</span><br><span class="line">        num_correct = np.<span class="built_in">sum</span>(y_val_pred == y_train_folds[i])</span><br><span class="line">        accuracy = <span class="built_in">float</span>(num_correct) / <span class="built_in">len</span>(y_val_pred)</span><br><span class="line">        k_to_accuracies[k] += [accuracy]</span><br><span class="line">        <span class="comment">#print(k,k_to_accuracies[k])</span></span><br><span class="line">    <span class="comment">#print(k_to_accuracies)</span></span><br><span class="line"><span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Print out the computed accuracies</span></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">sorted</span>(k_to_accuracies):</span><br><span class="line">    <span class="keyword">for</span> accuracy <span class="keyword">in</span> k_to_accuracies[k]:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;k = %d, accuracy = %f&#x27;</span> % (k, accuracy))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#OUTPUT</span></span><br><span class="line">    k = <span class="number">1</span>, accuracy = <span class="number">0.263000</span></span><br><span class="line">    k = <span class="number">1</span>, accuracy = <span class="number">0.257000</span> </span><br><span class="line">    k = <span class="number">1</span>, accuracy = <span class="number">0.264000</span></span><br><span class="line">    k = <span class="number">1</span>, accuracy = <span class="number">0.278000</span></span><br><span class="line">    k = <span class="number">1</span>, accuracy = <span class="number">0.266000</span></span><br><span class="line">    k = <span class="number">3</span>, accuracy = <span class="number">0.239000</span></span><br><span class="line">    k = <span class="number">3</span>, accuracy = <span class="number">0.249000</span></span><br><span class="line">    k = <span class="number">3</span>, accuracy = <span class="number">0.240000</span></span><br><span class="line">    k = <span class="number">3</span>, accuracy = <span class="number">0.266000</span></span><br><span class="line">    k = <span class="number">3</span>, accuracy = <span class="number">0.254000</span></span><br><span class="line">    k = <span class="number">5</span>, accuracy = <span class="number">0.248000</span></span><br><span class="line">    k = <span class="number">5</span>, accuracy = <span class="number">0.266000</span></span><br><span class="line">    k = <span class="number">5</span>, accuracy = <span class="number">0.280000</span></span><br><span class="line">    k = <span class="number">5</span>, accuracy = <span class="number">0.292000</span></span><br><span class="line">    k = <span class="number">5</span>, accuracy = <span class="number">0.280000</span></span><br><span class="line">    k = <span class="number">8</span>, accuracy = <span class="number">0.262000</span></span><br><span class="line">    k = <span class="number">8</span>, accuracy = <span class="number">0.282000</span></span><br><span class="line">    k = <span class="number">8</span>, accuracy = <span class="number">0.273000</span></span><br><span class="line">    k = <span class="number">8</span>, accuracy = <span class="number">0.290000</span></span><br><span class="line">    k = <span class="number">8</span>, accuracy = <span class="number">0.273000</span></span><br><span class="line">    k = <span class="number">10</span>, accuracy = <span class="number">0.265000</span></span><br><span class="line">    k = <span class="number">10</span>, accuracy = <span class="number">0.296000</span></span><br><span class="line">    k = <span class="number">10</span>, accuracy = <span class="number">0.276000</span></span><br><span class="line">    k = <span class="number">10</span>, accuracy = <span class="number">0.284000</span></span><br><span class="line">    k = <span class="number">10</span>, accuracy = <span class="number">0.280000</span></span><br><span class="line">    k = <span class="number">12</span>, accuracy = <span class="number">0.260000</span></span><br><span class="line">    k = <span class="number">12</span>, accuracy = <span class="number">0.295000</span></span><br><span class="line">    k = <span class="number">12</span>, accuracy = <span class="number">0.279000</span></span><br><span class="line">    k = <span class="number">12</span>, accuracy = <span class="number">0.283000</span></span><br><span class="line">    k = <span class="number">12</span>, accuracy = <span class="number">0.280000</span></span><br><span class="line">    k = <span class="number">15</span>, accuracy = <span class="number">0.252000</span></span><br><span class="line">    k = <span class="number">15</span>, accuracy = <span class="number">0.289000</span></span><br><span class="line">    k = <span class="number">15</span>, accuracy = <span class="number">0.278000</span></span><br><span class="line">    k = <span class="number">15</span>, accuracy = <span class="number">0.282000</span></span><br><span class="line">    k = <span class="number">15</span>, accuracy = <span class="number">0.274000</span></span><br><span class="line">    k = <span class="number">20</span>, accuracy = <span class="number">0.270000</span></span><br><span class="line">    k = <span class="number">20</span>, accuracy = <span class="number">0.279000</span></span><br><span class="line">    k = <span class="number">20</span>, accuracy = <span class="number">0.279000</span></span><br><span class="line">    k = <span class="number">20</span>, accuracy = <span class="number">0.282000</span></span><br><span class="line">    k = <span class="number">20</span>, accuracy = <span class="number">0.285000</span></span><br><span class="line">    k = <span class="number">50</span>, accuracy = <span class="number">0.271000</span></span><br><span class="line">    k = <span class="number">50</span>, accuracy = <span class="number">0.288000</span></span><br><span class="line">    k = <span class="number">50</span>, accuracy = <span class="number">0.278000</span></span><br><span class="line">    k = <span class="number">50</span>, accuracy = <span class="number">0.269000</span></span><br><span class="line">    k = <span class="number">50</span>, accuracy = <span class="number">0.266000</span></span><br><span class="line">    k = <span class="number">100</span>, accuracy = <span class="number">0.256000</span></span><br><span class="line">    k = <span class="number">100</span>, accuracy = <span class="number">0.270000</span></span><br><span class="line">    k = <span class="number">100</span>, accuracy = <span class="number">0.263000</span></span><br><span class="line">    k = <span class="number">100</span>, accuracy = <span class="number">0.256000</span></span><br><span class="line">    k = <span class="number">100</span>, accuracy = <span class="number">0.263000</span></span><br></pre></td></tr></table></figure><p>通过这行代码可以选出最好的k值</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">best_k = k_choices[accuracies_mean.argmax()]</span><br></pre></td></tr></table></figure><hr /><h3 id="inline-question-1"><strong>Inline Question 1</strong></h3><p>Notice the structured patterns in the distance matrix, where somerows or columns are visibly brighter. (Note that with the default colorscheme black indicates low distances while white indicates highdistances.)</p><ul><li>What in the data is the cause behind the distinctly brightrows?</li><li>What causes the columns?</li></ul><p><span class="math inline">\(\color{blue}{\textit YourAnswer:}\)</span> <em>fill this in.</em></p><ol type="1"><li><p>The test image is far different from all the trainimage.</p></li><li><p>The train image is unsimilar to all the test image.</p></li></ol><hr /><h3 id="inline-question-2"><strong>Inline Question 2</strong></h3><p>We can also use other distance metrics such as L1 distance. For pixelvalues <span class="math inline">\(p_{ij}^{k}\)</span> at location <spanclass="math inline">\((i,j)\)</span> of some image <spanclass="math inline">\(I_k\)</span>,</p><p>the mean <span class="math inline">\(\mu\)</span> across all pixelsover all images is <spanclass="math display">\[\mu=\frac{1}{nhw}\sum_{k=1}^n\sum_{i=1}^{h}\sum_{j=1}^{w}p_{ij}^{(k)}\]</span>And the pixel-wise mean <span class="math inline">\(\mu_{ij}\)</span>across all images is <spanclass="math display">\[\mu_{ij}=\frac{1}{n}\sum_{k=1}^np_{ij}^{(k)}.\]</span>The general standard deviation <spanclass="math inline">\(\sigma\)</span> and pixel-wise standard deviation<span class="math inline">\(\sigma_{ij}\)</span> is definedsimilarly.</p><p>Which of the following preprocessing steps will not change theperformance of a Nearest Neighbor classifier that uses L1 distance?Select all that apply.</p><ol type="1"><li><p>Subtracting the mean <span class="math inline">\(\mu\)</span>(<spanclass="math inline">\(\tilde{p}_{ij}^{(k)}=p_{ij}^{(k)}-\mu\)</span>.)</p></li><li><p>Subtracting the per pixel mean <spanclass="math inline">\(\mu_{ij}\)</span> (<spanclass="math inline">\(\tilde{p}_{ij}^{(k)}=p_{ij}^{(k)}-\mu_{ij}\)</span>.)</p></li><li><p>Subtracting the mean <span class="math inline">\(\mu\)</span> anddividing by the standard deviation <spanclass="math inline">\(\sigma\)</span>.</p></li><li><p>Subtracting the pixel-wise mean <spanclass="math inline">\(\mu_{ij}\)</span> and dividing by the pixel-wisestandard deviation <spanclass="math inline">\(\sigma_{ij}\)</span>.</p></li><li><p>Rotating the coordinate axes of the data.</p></li></ol><p><span class="math inline">\(\color{blue}{\textit YourAnswer:}\)</span></p><p>1, 3 will not change the L1 Distance.</p><p><span class="math inline">\(\color{blue}{\textit YourExplanation:}\)</span></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/inline1.jpg" /></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/inline2.jpg" /></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/inline3.jpg" /></p><hr /><h3 id="inline-question-3"><strong>Inline Question 3</strong></h3><p>Which of the following statements about <spanclass="math inline">\(k\)</span>-Nearest Neighbor (<spanclass="math inline">\(k\)</span>-NN) are true in a classificationsetting, and for all <span class="math inline">\(k\)</span>? Select allthat apply. 1. The decision boundary of the k-NN classifier is linear.2. The training error of a 1-NN will always be lower than or equal tothat of 5-NN. 3. The test error of a 1-NN will always be lower than thatof a 5-NN. 4. The time needed to classify a test example with the k-NNclassifier grows with the size of the training set. 5. None of theabove.</p><p><span class="math inline">\(\color{blue}{\textit YourAnswer:}\)</span></p><p>2, 4.</p><p><span class="math inline">\(\color{blue}{\textit YourExplanation:}\)</span></p><ol type="1"><li><p>False. It depends on the given categories of data, if you give acategory with a circle boundary to its neighborhood, it isnon-linear.</p></li><li><p>True. In fact the training error of a 1-NN is always 0, and5-NN's lower bound is 0. It is because the nearest neighbor of test datais always going to be itself in 1-NN.</p></li><li><p>False. The value of k is thus data-dependent, that is why we needto perform cross validation to determine the best k for your intendedapplication and dataset.</p></li><li><p>True. At test, KNN needs to make a full pass through the entiredata set and sort points by distance. The time needed thus grows withthe size of the data.</p></li></ol><hr /><h2 id="knn部分参考链接">KNN部分参考链接:</h2><ol type="1"><li><p>cs231n官网: <ahref="https://cs231n.github.io/">https://cs231n.github.io/</a></p></li><li><p>cs231n作业，assignment1-knn详解（注重算法与代码的结合）: <ahref="https://blog.csdn.net/qq_24906797/article/details/89245722">https://blog.csdn.net/qq_24906797/article/details/89245722</a></p></li><li><p>cs231n assignment1 knn: <ahref="https://blog.csdn.net/SpicyCoder/article/details/94992552">https://blog.csdn.net/SpicyCoder/article/details/94992552</a></p></li><li><p>【本课程配套的代码作业讲解见置顶评论】斯坦福CS231N计算机视觉作业讲解：<ahref="https://www.bilibili.com/video/BV1t4411U78z/?spm_id_from=333.337.search-card.all.click&amp;vd_source=f0de9c6453942ba082fa767eb7aa958a">https://www.bilibili.com/video/BV1t4411U78z/?spm_id_from=333.337.search-card.all.click&amp;vd_source=f0de9c6453942ba082fa767eb7aa958a</a></p></li><li><p>CS231N作业详解零基础版： <ahref="https://www.bilibili.com/video/BV19z411b7u9/?p=6&amp;vd_source=f0de9c6453942ba082fa767eb7aa958a">https://www.bilibili.com/video/BV19z411b7u9/?p=6&amp;vd_source=f0de9c6453942ba082fa767eb7aa958a</a></p></li></ol><h1 id="support-vector-machine-svm">Support Vector Machine (SVM)</h1><p>在svm.ipynb中，调用了linear_svm.py和linear_classifier.py两个文件。</p><p>为方便理解，先介绍SVM的引入基于的几个概念：</p><ol type="1"><li><p>我们要实现一种更强大的方法来解决图像分类问题，该方法可以自然地延伸到神经网络和卷积神经网络上。这种方法主要有两部分组成：</p><ul><li><p>一个是评分函数（scorefunction），它是原始图像数据到类别分值的映射。</p></li><li><p>另一个是损失函数（lossfunction），它是用来量化预测分类标签的得分与真实标签之间一致性的。</p></li></ul><p>该方法可转化为一个最优化问题，在最优化过程中，将通过更新评分函数的参数来最小化损失函数值。从图像像素值到所属类别的评分函数（scorefunction）</p></li><li><p>该我们现在定义评分函数为<span class="math inline">\(f:R^D \toR^K\)</span>，该函数是原始图像像素到分类分值的映射。在<strong>线性分类器</strong>中，一个线性映射：<spanclass="math inline">\(f(x_i,W,b)=Wx_i+b\)</span>。在函数中，数据<spanclass="math inline">\((x_i,y_i)\)</span>是给定的，不能修改。但是我们可以调整权重矩阵<spanclass="math inline">\(W\)</span>这个参数，使得评分函数的结果与训练数据集中图像的真实类别一致，即评分函数在正确的分类的位置应当得到最高的评分（score）。</p></li><li><p>我们将使用损失函数（****Loss Function）（有时也叫代价函数****CostFunction或目标函数****Objective）来衡量我们对结果的不满意程度。直观地讲，当评分函数输出结果与真实结果之间差异越大，损失函数输出越大，反之越小。多类支持向量机（SVM）损失函数是其中一种。SVM的损失函数想要SVM在正确分类上的得分始终比不正确分类上的得分高出一个边界值Delta$ $。</p></li></ol><h2 id="svm简介">SVM简介</h2><h3 id="公式说明">公式说明</h3><p>SVM算法由两个部分组成：数据损失（dataloss），即所有样例的的平均损失L_i，以及正则化损失（regularizationloss）。完整公式如下：</p><p><imgsrc="https://camo.githubusercontent.com/19467d143a4397b56c0aaf83d66de6ba9a4615c801e5ed3f2e1272b80748e789/687474703a2f2f7a686968752e636f6d2f6571756174696f6e3f7465783d4c253344253543646973706c61797374796c652b253543756e64657262726163652537422b25354366726163253742312537442537424e25374425354373756d5f692b4c5f692537445f253742646174612b2535432b2b6c6f7373253744253242253543756e64657262726163652537422535436c616d6264612b52253238572532392537445f253742726567756c6172697a6174696f6e2b2535432b6c6f7373253744" /></p><p>将其展开完整公式是：</p><p><span class="math inline">\(L=\frac{1}{N}\sum_i\sum_{j \not=y_i}[\max(0,f(x_i;W)j-f(x_i;W){y_i}+\Delta)]+\lambda \sum_k \sum_lW^2_{k,l}\)</span></p><p>其中参数意义如下： * X(N,D),N是训练集的数据量。 *W(D,C),C代表图片分类的数量。 * y(N,) * i 是迭代第N个训练集数据 * j是第C个图片分类 * <span class="math inline">\(\lambda\)</span>正则化惩罚，添加到了损失函数里面，并用超参数<spanclass="math inline">\(\lambda\)</span>来计算其权重。该超参数无法简单确定，需要通过交叉验证来获取。引入正则化惩罚还带来很多良好的性质，其中最好的性质就是对大数值权重进行惩罚，可以提升其泛化能力，因为这就意味着没有哪个维度能够独自对于整体分值有过大的影响。</p><h3 id="注意点">注意点</h3><p>超参数在绝大多数情况下设为<spanclass="math inline">\(\Delta\)</span>=1.0都是安全的。超参数<spanclass="math inline">\(\Delta\)</span>和<spanclass="math inline">\(\lambda\)</span>看起来是两个不同的超参数，但实际上他们一起控制同一个权衡：即损失函数中的数据损失和正则化损失之间的权衡。</p><h2 id="linear_svm.py">linear_svm.py</h2><p>损失函数公式： <span class="math inline">\(L=\frac{1}{N}\sum_i\sum_{j\not= y_i}[\max(0,f(x_i;W)j-f(x_i;W){y_i}+\Delta)]+\lambda \sum_k \sum_lW^2_{k,l}\)</span></p><p>我们想通过一个方法来得到损失函数L的最小值，这里考虑使用计算W的梯度来不停的对L进行优化，这里想的就是初始化一个W，然后计算W的梯度，接着不停的迭代W，直到收敛或者达到迭代次数。那问题就变成如何求L对于W的梯度了。</p><h3 id="循环求解">循环求解</h3><p>后面的正则项，就是<span class="math inline">\(\lambda \sum_k \sum_lW^2_{k,l}\)</span>，求导即为 <span class="math display">\[\frac{dL}{dw}(正则项)=2*\lambda*W\]</span></p><p>主要是求前面数据损失函数的梯度。那么，我们先把L给拆分一下，这样可以去掉一个求和符号<span class="math display">\[L_i=\sum_{j \not=y_i}\max(0,x_iw_j-x_iw_{y_i}+\Delta)\]</span></p><p>（1）考虑<span class="math inline">\(j \not= y_i\)</span></p><p><span class="math display">\[\begin{aligned}\frac{dL_i}{dw_j}=1(x_iw_j-x_iw_{y_i}+\Delta&gt;0) *    \begin{array}    {|c|}    x_{i1} \\    x_{i2}\\    \vdots&amp;\\    x_{iD}    \end{array}\end{aligned}\]</span> 所以得到 <span class="math display">\[\frac{dL_i}{dw_j}=1(x_iw_j-x_iw_{y_i}+\Delta&gt;0) *{x_i}\]</span></p><p>（2）考虑<span class="math inline">\(j = y_i\)</span>，则满足</p><ul><li><spanclass="math display">\[\frac{d(x_iw_j)}{dw_{y_i}}=0\]</span></li><li><spanclass="math display">\[\frac{d(-x_iw_{y_i})}{dw_{y_i}}=-x_i\]</span></li></ul><p>因此代入以下公式 <span class="math display">\[\begin{aligned}\frac{dL_i}{dw_{y_i}}=-\sum_{j \not= y_i}1(x_iw_j-x_iw_{y_i}+\Delta&gt;0) *    \begin{array}    {|c|}    x_{i1} \\    x_{i2}\\    \vdots&amp;\\    x_{iD}    \end{array}\end{aligned}\]</span></p><p>最终可以得到</p><p><span class="math display">\[\frac{dL_i}{dw_{y_i}}=-\sum_{j \not= y_i}1(x_iw_j-x_iw_{y_i}+\Delta&gt;0) * x_i\]</span></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">svm_loss_naive</span>(<span class="params">W, X, y, reg</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Structured SVM loss function, naive implementation (with loops).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs have dimension D, there are C classes, and we operate on minibatches</span></span><br><span class="line"><span class="string">    of N examples.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - W: A numpy array of shape (D, C) containing weights.</span></span><br><span class="line"><span class="string">    - X: A numpy array of shape (N, D) containing a minibatch of data.</span></span><br><span class="line"><span class="string">    - y: A numpy array of shape (N,) containing training labels; y[i] = c means</span></span><br><span class="line"><span class="string">      that X[i] has label c, where 0 &lt;= c &lt; C.</span></span><br><span class="line"><span class="string">    - reg: (float) regularization strength</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - loss as single float</span></span><br><span class="line"><span class="string">    - gradient with respect to weights W; an array of same shape as W</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    dW = np.zeros(W.shape)  <span class="comment"># initialize the gradient as zero</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute the loss and the gradient</span></span><br><span class="line">    num_classes = W.shape[<span class="number">1</span>]</span><br><span class="line">    num_train = X.shape[<span class="number">0</span>]</span><br><span class="line">    loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_train):</span><br><span class="line">        scores = X[i].dot(W)</span><br><span class="line">        correct_class_score = scores[y[i]]</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(num_classes):</span><br><span class="line">            <span class="keyword">if</span> j == y[i]:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            margin = scores[j] - correct_class_score + <span class="number">1</span>  <span class="comment"># note delta = 1</span></span><br><span class="line">            <span class="keyword">if</span> margin &gt; <span class="number">0</span>:</span><br><span class="line">                loss += margin</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Right now the loss is a sum over all training examples, but we want it</span></span><br><span class="line">    <span class="comment"># to be an average instead so we divide by num_train.</span></span><br><span class="line">    loss /= num_train</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Add regularization to the loss.</span></span><br><span class="line">    loss += reg * np.<span class="built_in">sum</span>(W * W)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span>                                                                     #</span></span><br><span class="line">    <span class="comment"># Compute the gradient of the loss function and store it dW.                #</span></span><br><span class="line">    <span class="comment"># Rather that first computing the loss and then computing the derivative,   #</span></span><br><span class="line">    <span class="comment"># it may be simpler to compute the derivative at the same time that the     #</span></span><br><span class="line">    <span class="comment"># loss is being computed. As a result you may need to modify some of the    #</span></span><br><span class="line">    <span class="comment"># code above to compute the gradient.                                       #</span></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_train):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(num_classes):</span><br><span class="line">            <span class="keyword">if</span> j == y[i]:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            margin = scores[j] - correct_class_score + <span class="number">1</span>  <span class="comment">#note delta = 1 </span></span><br><span class="line">            <span class="keyword">if</span> margin &gt; <span class="number">0</span>:</span><br><span class="line">                dW[:,j]+=X[i,:]</span><br><span class="line">                dW[:,y[i]]+=-X[i,:]</span><br><span class="line">    </span><br><span class="line">    dW /= num_train</span><br><span class="line">    dW += <span class="number">2</span>*reg*dW</span><br><span class="line">    <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss, dW</span><br></pre></td></tr></table></figure><h3 id="向量化实现">向量化实现</h3><p>第一个部分，损失函数。公式和前面基本一致，数据损失函数部分</p><p>分类正确即对应 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scores[<span class="built_in">range</span>(N),y]=<span class="number">0</span> </span><br></pre></td></tr></table></figure></p><p>分类错误即对应</p><p><span class="math display">\[L_i=\sum_{j \not=y_i}\max(0,x_iw_j-x_iw_{y_i}+\Delta)\]</span></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scores = np.dot(X,W) - scores[<span class="built_in">range</span>(N),[y]].T + <span class="number">1</span></span><br><span class="line">np.maximum(<span class="number">0</span>,scores)</span><br></pre></td></tr></table></figure><p>因为X(N,D),N是训练集的数据量。W(D,C),C代表图片分类的数量。所以一开始保证维数一致:<spanclass="math display">\[scores = X * W\]</span></p><ul><li><p>np.dot(X,W) shape: (N,C)</p></li><li><p>scores shape: (N,C)</p><ul><li>scores[range(N),[y]].T shape: (N,C) -&gt; (1,N) -&gt; (N,1)</li><li>表示选取每个图片的正确分类，给它们评分函数的相应位置置0，说明损失为0，而其他位置则需要按照SVM的公式计算损失并且和0比较大小。</li></ul></li></ul><p>后面的正则项损失函数部分，</p><p><span class="math display">\[\frac{dL}{dw}(正则项)=2*\lambda*W\]</span></p><p>二维数组的np.sum, shape是( , ) 也就是一个数值。</p><p>第二个部分，梯度求解。用到了链式法则： <span class="math display">\[\frac{dL}{dw}=\frac{dL}{dS}*\frac{dS}{dw}\]</span></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/SVMdw.png" /></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">svm_loss_vectorized</span>(<span class="params">W, X, y, reg</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Structured SVM loss function, vectorized implementation.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs and outputs are the same as svm_loss_naive.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    loss = <span class="number">0.0</span></span><br><span class="line">    dW = np.zeros(W.shape)  <span class="comment"># initialize the gradient as zero</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span>                                                                     #</span></span><br><span class="line">    <span class="comment"># Implement a vectorized version of the structured SVM loss, storing the    #</span></span><br><span class="line">    <span class="comment"># result in loss.                                                           #</span></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">    N=<span class="built_in">len</span>(y)</span><br><span class="line">    scores = np.dot(X,W)</span><br><span class="line">    scores -= scores[<span class="built_in">range</span>(N),[y]].T</span><br><span class="line">    scores += <span class="number">1</span></span><br><span class="line">    scores[<span class="built_in">range</span>(N),y]=<span class="number">0</span></span><br><span class="line">    margin = np.maximum(<span class="number">0</span>,scores)</span><br><span class="line">    loss = np.<span class="built_in">sum</span>(margin) / N + reg * np.<span class="built_in">sum</span>(np.square(W)) </span><br><span class="line"></span><br><span class="line">    <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span>                                                                     #</span></span><br><span class="line">    <span class="comment"># Implement a vectorized version of the gradient for the structured SVM     #</span></span><br><span class="line">    <span class="comment"># loss, storing the result in dW.                                           #</span></span><br><span class="line">    <span class="comment">#                                                                           #</span></span><br><span class="line">    <span class="comment"># Hint: Instead of computing the gradient from scratch, it may be easier    #</span></span><br><span class="line">    <span class="comment"># to reuse some of the intermediate values that you used to compute the     #</span></span><br><span class="line">    <span class="comment"># loss.                                                                     #</span></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">    ds = np.zeros_like(margin)</span><br><span class="line">    ds[margin&gt;<span class="number">0</span>]=<span class="number">1</span></span><br><span class="line">    ds[<span class="built_in">range</span>(N),y]-=np.<span class="built_in">sum</span>(ds,axis=<span class="number">1</span>)</span><br><span class="line">    ds /= N</span><br><span class="line">    dW = X.T.dot(ds)</span><br><span class="line">    dW += <span class="number">2</span> * reg * W</span><br><span class="line"></span><br><span class="line">    <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss, dW</span><br></pre></td></tr></table></figure><h2 id="linear_classifier.py">linear_classifier.py</h2><h3 id="训练-1">训练</h3><ul><li>np.random.choice() 从给定的一维数组生成随机样本。</li></ul><p>Examples:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#从大小为 3 的 np.arange(5) 生成均匀随机样本：</span></span><br><span class="line">np.random.choice(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">array([<span class="number">0</span>, <span class="number">3</span>, <span class="number">4</span>]) <span class="comment"># random</span></span><br><span class="line"><span class="comment">#This is equivalent to np.random.randint(0,5,3)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#从大小为 3 的 np.arange(5) 生成一个非均匀随机样本：</span></span><br><span class="line">np.random.choice(<span class="number">5</span>, <span class="number">3</span>, p=[<span class="number">0.1</span>, <span class="number">0</span>, <span class="number">0.3</span>, <span class="number">0.6</span>, <span class="number">0</span>])</span><br><span class="line">array([<span class="number">3</span>, <span class="number">3</span>, <span class="number">0</span>]) <span class="comment"># random</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#从大小为 3 的 np.arange(5) 生成一个统一的随机样本，无需替换，说明没有重复取值：</span></span><br><span class="line">np.random.choice(<span class="number">5</span>, <span class="number">3</span>, replace=<span class="literal">False</span>)</span><br><span class="line">array([<span class="number">3</span>,<span class="number">1</span>,<span class="number">0</span>]) <span class="comment"># random</span></span><br><span class="line"><span class="comment">#This is equivalent to np.random.permutation(np.arange(5))[:3]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#从大小为 3 的 np.arange(5) 生成非均匀随机样本，无需替换：</span></span><br><span class="line">np.random.choice(<span class="number">5</span>, <span class="number">3</span>, replace=<span class="literal">False</span>, p=[<span class="number">0.1</span>, <span class="number">0</span>, <span class="number">0.3</span>, <span class="number">0.6</span>, <span class="number">0</span>])</span><br><span class="line">array([<span class="number">2</span>, <span class="number">3</span>, <span class="number">0</span>]) <span class="comment"># random</span></span><br></pre></td></tr></table></figure><p>实现train函数，作用是从每一个 iteration 中选出 batch_size个训练样本投入到 SVM 中，然后再计算一次 Loss函数进行梯度下降，避免计算太频繁导致时间消耗过大。有两部分需要补全，第一个是随机选择数据，第二个是梯度下降，实现都比较简单</p><p>梯度下降公式： <imgsrc="https://math.jianshu.com/math?formula=%5Ctheta%20%3D%5Ctheta%20-%5Ceta%20%5Ccdot%20%5Ctriangledown%20_%7B%5Ctheta%20%7DJ%5Cleft%20(%20%5Ctheta%20%5Cright%20)" /></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LinearClassifier</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.W = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        X,</span></span><br><span class="line"><span class="params">        y,</span></span><br><span class="line"><span class="params">        learning_rate=<span class="number">1e-3</span>,</span></span><br><span class="line"><span class="params">        reg=<span class="number">1e-5</span>,</span></span><br><span class="line"><span class="params">        num_iters=<span class="number">100</span>,</span></span><br><span class="line"><span class="params">        batch_size=<span class="number">200</span>,</span></span><br><span class="line"><span class="params">        verbose=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Train this linear classifier using stochastic gradient descent.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Inputs:</span></span><br><span class="line"><span class="string">        - X: A numpy array of shape (N, D) containing training data; there are N</span></span><br><span class="line"><span class="string">          training samples each of dimension D.</span></span><br><span class="line"><span class="string">        - y: A numpy array of shape (N,) containing training labels; y[i] = c</span></span><br><span class="line"><span class="string">          means that X[i] has label 0 &lt;= c &lt; C for C classes.</span></span><br><span class="line"><span class="string">        - learning_rate: (float) learning rate for optimization.</span></span><br><span class="line"><span class="string">        - reg: (float) regularization strength.</span></span><br><span class="line"><span class="string">        - num_iters: (integer) number of steps to take when optimizing</span></span><br><span class="line"><span class="string">        - batch_size: (integer) number of training examples to use at each step.</span></span><br><span class="line"><span class="string">        - verbose: (boolean) If true, print progress during optimization.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Outputs:</span></span><br><span class="line"><span class="string">        A list containing the value of the loss function at each training iteration.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        num_train, dim = X.shape</span><br><span class="line">        num_classes = (</span><br><span class="line">            np.<span class="built_in">max</span>(y) + <span class="number">1</span></span><br><span class="line">        )  <span class="comment"># assume y takes values 0...K-1 where K is number of classes</span></span><br><span class="line">        <span class="keyword">if</span> self.W <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># lazily initialize W</span></span><br><span class="line">            self.W = <span class="number">0.001</span> * np.random.randn(dim, num_classes)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Run stochastic gradient descent to optimize W</span></span><br><span class="line">        loss_history = []</span><br><span class="line">        <span class="keyword">for</span> it <span class="keyword">in</span> <span class="built_in">range</span>(num_iters):</span><br><span class="line">            X_batch = <span class="literal">None</span></span><br><span class="line">            y_batch = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">#########################################################################</span></span><br><span class="line">            <span class="comment"># <span class="doctag">TODO:</span>                                                                 #</span></span><br><span class="line">            <span class="comment"># Sample batch_size elements from the training data and their           #</span></span><br><span class="line">            <span class="comment"># corresponding labels to use in this round of gradient descent.        #</span></span><br><span class="line">            <span class="comment"># Store the data in X_batch and their corresponding labels in           #</span></span><br><span class="line">            <span class="comment"># y_batch; after sampling X_batch should have shape (batch_size, dim)   #</span></span><br><span class="line">            <span class="comment"># and y_batch should have shape (batch_size,)                           #</span></span><br><span class="line">            <span class="comment">#                                                                       #</span></span><br><span class="line">            <span class="comment"># Hint: Use np.random.choice to generate indices. Sampling with         #</span></span><br><span class="line">            <span class="comment"># replacement is faster than sampling without replacement.              #</span></span><br><span class="line">            <span class="comment">#########################################################################</span></span><br><span class="line">            <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">            bindex = np.random.choice(num_train,batch_size)</span><br><span class="line">            X_batch = X[bindex]</span><br><span class="line">            y_batch = y[bindex]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># evaluate loss and gradient</span></span><br><span class="line">            loss, grad = self.loss(X_batch, y_batch, reg)</span><br><span class="line">            loss_history.append(loss)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># perform parameter update</span></span><br><span class="line">            <span class="comment">#########################################################################</span></span><br><span class="line">            <span class="comment"># <span class="doctag">TODO:</span>                                                                 #</span></span><br><span class="line">            <span class="comment"># Update the weights using the gradient and the learning rate.          #</span></span><br><span class="line">            <span class="comment">#########################################################################</span></span><br><span class="line">            <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">            self.W = self.W - learning_rate * grad</span><br><span class="line"></span><br><span class="line">            <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> verbose <span class="keyword">and</span> it % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;iteration %d / %d: loss %f&quot;</span> % (it, num_iters, loss))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> loss_history</span><br></pre></td></tr></table></figure><h3 id="预测">预测</h3><p>调参环节，从不同的 learning rate 与 regularization strengths中选出使验证集正确率最高的组合。对每一种组合都训一遍SVM，然后计算一次正确率。不过在 learning rate较大的两个情况训练时，发生了计算溢出的情况。题面中说这是正常现象，正确率接近39%​就算成功。</p><ul><li>np.mean(y_train == y_train_pred)解释：<ul><li>mean是求平均值的意思</li><li>y_train ==y_train_pred意思就是判断训练的值和预测的值是否相同，相等返回1</li><li>将相等的全部加起来/总训练数，就是训练集的准确率了，mean这里就是统计相等的做除法算出准确率的作用</li><li>所以 np.mean(y_train == y_train_pred)就是算训练集准确率的意思</li></ul></li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Use the validation set to tune hyperparameters (regularization strength and</span></span><br><span class="line"><span class="comment"># learning rate). You should experiment with different ranges for the learning</span></span><br><span class="line"><span class="comment"># rates and regularization strengths; if you are careful you should be able to</span></span><br><span class="line"><span class="comment"># get a classification accuracy of about 0.39 (&gt; 0.385) on the validation set.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Note: you may see runtime/overflow warnings during hyper-parameter search. </span></span><br><span class="line"><span class="comment"># This may be caused by extreme values, and is not a bug.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># results is dictionary mapping tuples of the form</span></span><br><span class="line"><span class="comment"># (learning_rate, regularization_strength) to tuples of the form</span></span><br><span class="line"><span class="comment"># (training_accuracy, validation_accuracy). The accuracy is simply the fraction</span></span><br><span class="line"><span class="comment"># of data points that are correctly classified.</span></span><br><span class="line">results = &#123;&#125;</span><br><span class="line">best_val = -<span class="number">1</span>   <span class="comment"># The highest validation accuracy that we have seen so far.</span></span><br><span class="line">best_svm = <span class="literal">None</span> <span class="comment"># The LinearSVM object that achieved the highest validation rate.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span>                                                                        #</span></span><br><span class="line"><span class="comment"># Write code that chooses the best hyperparameters by tuning on the validation #</span></span><br><span class="line"><span class="comment"># set. For each combination of hyperparameters, train a linear SVM on the      #</span></span><br><span class="line"><span class="comment"># training set, compute its accuracy on the training and validation sets, and  #</span></span><br><span class="line"><span class="comment"># store these numbers in the results dictionary. In addition, store the best   #</span></span><br><span class="line"><span class="comment"># validation accuracy in best_val and the LinearSVM object that achieves this  #</span></span><br><span class="line"><span class="comment"># accuracy in best_svm.                                                        #</span></span><br><span class="line"><span class="comment">#                                                                              #</span></span><br><span class="line"><span class="comment"># Hint: You should use a small value for num_iters as you develop your         #</span></span><br><span class="line"><span class="comment"># validation code so that the SVMs don&#x27;t take much time to train; once you are #</span></span><br><span class="line"><span class="comment"># confident that your validation code works, you should rerun the validation   #</span></span><br><span class="line"><span class="comment"># code with a larger value for num_iters.                                      #</span></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Provided as a reference. You may or may not want to change these hyperparameters</span></span><br><span class="line">learning_rates = [<span class="number">1e-7</span>, <span class="number">5e-5</span>]</span><br><span class="line">regularization_strengths = [<span class="number">2.5e4</span>, <span class="number">5e4</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line"><span class="keyword">for</span> rs <span class="keyword">in</span> regularization_strengths:</span><br><span class="line">  <span class="keyword">for</span> lr <span class="keyword">in</span> learning_rates:</span><br><span class="line">    svm = LinearSVM()</span><br><span class="line">    loss_hist = svm.train(X_train,y_train,lr,rs,num_iters=<span class="number">1500</span>)</span><br><span class="line">    y_train_pred = svm.predict(X_train)</span><br><span class="line">    train_accuracy = np.mean(y_train == y_train_pred)</span><br><span class="line">    y_val_pred = svm.predict(X_val)</span><br><span class="line">    val_accuracy = np.mean(y_val == y_val_pred)</span><br><span class="line">    <span class="keyword">if</span> val_accuracy &gt; best_val:</span><br><span class="line">      best_val = val_accuracy</span><br><span class="line">      best_svm = svm</span><br><span class="line">    results[(lr,rs)] = train_accuracy,val_accuracy</span><br><span class="line"><span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># Print out results.</span></span><br><span class="line"><span class="keyword">for</span> lr, reg <span class="keyword">in</span> <span class="built_in">sorted</span>(results):</span><br><span class="line">    train_accuracy, val_accuracy = results[(lr, reg)]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;lr %e reg %e train accuracy: %f val accuracy: %f&#x27;</span> % (</span><br><span class="line">                lr, reg, train_accuracy, val_accuracy))</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best validation accuracy achieved during cross-validation: %f&#x27;</span> % best_val)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#output result</span></span><br><span class="line">    lr <span class="number">1.000000e-07</span> reg <span class="number">2.500000e+04</span> train accuracy: <span class="number">0.371204</span> val accuracy: <span class="number">0.387000</span></span><br><span class="line">    lr <span class="number">1.000000e-07</span> reg <span class="number">5.000000e+04</span> train accuracy: <span class="number">0.351857</span> val accuracy: <span class="number">0.356000</span></span><br><span class="line">    lr <span class="number">5.000000e-05</span> reg <span class="number">2.500000e+04</span> train accuracy: <span class="number">0.054959</span> val accuracy: <span class="number">0.068000</span></span><br><span class="line">    lr <span class="number">5.000000e-05</span> reg <span class="number">5.000000e+04</span> train accuracy: <span class="number">0.100265</span> val accuracy: <span class="number">0.087000</span></span><br><span class="line">    best validation accuracy achieved during cross-validation: <span class="number">0.387000</span></span><br></pre></td></tr></table></figure><h3 id="inline-question-1-1"><strong>Inline Question 1</strong></h3><p>It is possible that once in a while a dimension in the gradcheck willnot match exactly. What could such a discrepancy be caused by? Is it areason for concern? What is a simple example in one dimension where agradient check could fail? How would change the margin affect of thefrequency of this happening? <em>Hint: the SVM loss function is notstrictly speaking differentiable</em></p><p><span class="math inline">\(\color{blue}{\textit YourAnswer:}\)</span></p><p>It is possible that the numerical gradient does not match the actualgradient, because the max function is non-linear, continuous at 0 butnot derivable, so the numerical gradient is inaccurate at thissituation.</p><h3 id="inline-question-2-1"><strong>Inline question 2</strong></h3><p>Describe what your visualized SVM weights look like, and offer abrief explanation for why they look the way they do.</p><p><span class="math inline">\(\color{blue}{\textit YourAnswer:}\)</span></p><p>Each class of weighted visual image shows roughly the shape of theobjects in that class as well as the background colour. When an imagehas a shape or background colour similar to that class, there is a highprobability that it will be classified as such.</p><h2 id="svm部分参考链接">SVM部分参考链接:</h2><ol type="1"><li><p>cs231n官网: <ahref="https://cs231n.github.io/">https://cs231n.github.io/</a></p></li><li><p>深度学习课程 CS231n Assignment1 SVM部分: <ahref="http://marvolo.top/archives/17202">http://marvolo.top/archives/17202</a></p></li><li><p>CS231-Multi-calss SVM的求导: <ahref="https://www.cnblogs.com/chenyusheng0803/p/10018306.html">https://www.cnblogs.com/chenyusheng0803/p/10018306.html</a></p></li><li><p>机器学习算法：梯度下降法——原理篇 <ahref="https://www.jianshu.com/p/424b7b70df7b">https://www.jianshu.com/p/424b7b70df7b</a></p></li><li><p>CS231N作业详解零基础版： <ahref="https://www.bilibili.com/video/BV19z411b7u9/?p=9&amp;vd_source=f0de9c6453942ba082fa767eb7aa958a">https://www.bilibili.com/video/BV19z411b7u9/?p=9&amp;vd_source=f0de9c6453942ba082fa767eb7aa958a</a></p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;cs231n-assignment-1&quot;&gt;CS231n Assignment 1&lt;/h1&gt;
&lt;p&gt;作业1分为五个部分：KNN、SVM、Softmax classifier、2层神经网络、Higher
Level Representations: Image F</summary>
      
    
    
    
    <category term="笔记" scheme="https://serika-onoe.github.io/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="介绍" scheme="https://serika-onoe.github.io/tags/%E4%BB%8B%E7%BB%8D/"/>
    
    <category term="深度学习" scheme="https://serika-onoe.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="cs231n" scheme="https://serika-onoe.github.io/tags/cs231n/"/>
    
    <category term="作业" scheme="https://serika-onoe.github.io/tags/%E4%BD%9C%E4%B8%9A/"/>
    
  </entry>
  
  <entry>
    <title>Transformer模型初探</title>
    <link href="https://serika-onoe.github.io/2022/12/14/Transformer%E6%A8%A1%E5%9E%8B%E5%88%9D%E6%8E%A2/"/>
    <id>https://serika-onoe.github.io/2022/12/14/Transformer%E6%A8%A1%E5%9E%8B%E5%88%9D%E6%8E%A2/</id>
    <published>2022-12-14T01:42:13.000Z</published>
    <updated>2022-12-20T14:48:56.160Z</updated>
    
    <content type="html"><![CDATA[<h1 id="transformer模型初探">Transformer模型初探</h1><h2 id="位置编码">位置编码</h2><ol type="1"><li>embedding</li><li>位置编码 面试题：RNN的梯度消失有什么不同 ## 多头注意力机制</li></ol><h2 id="残差和laternorm">残差和laterNorm</h2><h2 id="前馈神经网络">前馈神经网络</h2><h2 id="trm面试题讲解">TRM面试题讲解</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;transformer模型初探&quot;&gt;Transformer模型初探&lt;/h1&gt;
&lt;h2 id=&quot;位置编码&quot;&gt;位置编码&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;embedding&lt;/li&gt;
&lt;li&gt;位置编码 面试题：RNN的梯度消失有什么不同 ## 多头注</summary>
      
    
    
    
    <category term="笔记" scheme="https://serika-onoe.github.io/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="科研" scheme="https://serika-onoe.github.io/tags/%E7%A7%91%E7%A0%94/"/>
    
    <category term="项目" scheme="https://serika-onoe.github.io/tags/%E9%A1%B9%E7%9B%AE/"/>
    
  </entry>
  
  <entry>
    <title>强化学习初探</title>
    <link href="https://serika-onoe.github.io/2022/12/12/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%9D%E6%8E%A2/"/>
    <id>https://serika-onoe.github.io/2022/12/12/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%9D%E6%8E%A2/</id>
    <published>2022-12-12T15:17:01.000Z</published>
    <updated>2022-12-13T02:17:47.012Z</updated>
    
    <content type="html"><![CDATA[<h1 id="强化学习">强化学习</h1><p>强化学习是一类对目标导向的学习与决策问题进行理解和自动化处理的算法。它强调智能体通过与环境的直接互动来学习，无需像监督学习一样密集的样本级标签标注，通过奖励来学习合理的策略。</p><p>强化学习包含2个可以进行交互的对象：智能体和环境，它们的定义与介绍如下：</p><p>智能体：可以感知环境的状态，并根据反馈的奖励学习选择一个合适的动作，我们希望它能最大化长期总收益。环境：环境会接收智能体执行的一系列动作，对这一系列动作进行评价并转换为一种可量化的信号反馈给智能体。环境对智能体来说是一套相对固定的规则。</p><h2 id="目的">目的</h2><p>强化学习的目的是让计算机自行学习，以获得最好的未来结果。它通过不断的尝试和评估来实现这一目标，从而使计算机能够根据结果自动调整自身来获得最佳结果。</p><h2 id="典型算法">典型算法</h2><p>强化学习中使用的典型算法有：Q学习、蒙特卡洛树搜索、模仿学习、深度强化学习等。</p><h2 id="优点">优点</h2><p>强化学习的优点有：</p><ul><li>可以解决复杂的决策问题，比如游戏、控制和规划。</li><li>可以快速解决不断变化的环境问题和复杂的决策问题。</li><li>可以在非常少的知识和计算量情况下学习。</li></ul><h2 id="缺点">缺点</h2><p>强化学习的缺点有：</p><ul><li>需要大量的试验数据，因此在小数据集上表现不佳。</li><li>可能会出现“收敛停滞”现象，即它可能会在局部最优解上停止收敛。</li><li>它可能会陷入错误的局部最优解。</li></ul><h2 id="应用">应用</h2><p>强化学习在实际应用中有很多，比如：自动驾驶、智能家居、游戏、虚拟助手、自动投资、博弈机器人等。</p><h2 id="参考网站">参考网站</h2><ol type="1"><li>Reinforcement Learning and ArtificialIntelligence：https://www.reinforcementlearning.ai/</li><li>Deep ReinforcementLearning：https://deepreinforcementlearning.ai/</li><li>Andrew Ng Reinforcement Learning：https://www.andrewng.org/</li><li>Open AI Gym：https://gym.openai.com/</li><li>Google DeepMind：https://deepmind.com/research/open-source/</li><li>Berkeley AI Research：https://bair.berkeley.edu/</li><li>Udacity ReinforcementLearning：https://www.udacity.com/course/reinforcement-learning--ud600</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;强化学习&quot;&gt;强化学习&lt;/h1&gt;
&lt;p&gt;强化学习是一类对目标导向的学习与决策问题进行理解和自动化处理的算法。它强调智能体通过与环境的直接互动来学习，无需像监督学习一样密集的样本级标签标注，通过奖励来学习合理的策略。&lt;/p&gt;
&lt;p&gt;强化学习包含2个可以进行交互的对</summary>
      
    
    
    
    <category term="介绍" scheme="https://serika-onoe.github.io/categories/%E4%BB%8B%E7%BB%8D/"/>
    
    
    <category term="强化学习" scheme="https://serika-onoe.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="人工智能" scheme="https://serika-onoe.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="算法" scheme="https://serika-onoe.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>My Projects</title>
    <link href="https://serika-onoe.github.io/2022/12/09/My%20projects/"/>
    <id>https://serika-onoe.github.io/2022/12/09/My%20projects/</id>
    <published>2022-12-09T03:10:23.000Z</published>
    <updated>2022-12-12T14:45:37.714Z</updated>
    
    <content type="html"><![CDATA[<h1 id="software-programming-projects">Software ProgrammingProjects</h1><h2id="cluster-unmanned-aerial-vehicle-electromagnetic-calculations-and-applications">ClusterUnmanned Aerial Vehicle Electromagnetic Calculations andApplications</h2><p>2021.1 - 2021.8</p><hr /><h3 id="description.">Description.</h3><p>We solve the problem of acquiring target electromagneticcharacteristic data of UAV cluster by the following steps, and proposean innovative idea to solve the target detection of UAV clusterproblem.</p><p>First, a typical single fixed-wing UAV represented by the "Gremlin"UAV is used as an example for electromagnetic calculation based on themulti-stage fast multipole method (MLFMM). Then, radar scattering crosssection (RCS) simulation data and two-dimensional inverse syntheticaperture radar (ISAR) imaging are used to verify the accuracy of theresults of the above simulations. Finally, we simulated and validatedthe RCS simulation data for the UAV cluster.</p><p>The programming languages and software tools used are as follow:</p><ol type="1"><li>Solidworks - to build 3D models of both types of UAVs</li><li>Feko electromagnetic simulation software -- MLFMM-basedelectromagnetic simulation calculations for UAVs</li><li>MATLAB -- simulation data cleaning and processing, ISAR imagingalgorithm implementation</li></ol><h3 id="achievements.">Achievements.</h3><p>The process and conclusions of the project have been presented at theCIE Radar Conference 2021.</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/uav_prove.jpg" /></p><p>We summarize and analyze the EM scattering calculations for the UAVtarget "Gremlin" in single and clustered cases, which are based on theapplication requirements and technical difficulties. Fully polarizedstatic EM scattering was calculated for the "Gremlin" in typicalfrequency bands and the results were used to perform clustered targetimaging, where the wingtip characteristics of the "Gremlin" can beclearly seen.</p><h4 id="fixed-wing-representative-1---u.s.-army-predator-uav">Fixed WingRepresentative 1 - U.S. Army Predator UAV</h4><p><imgsrc="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Finews.gtimg.com%2Fnewsapp_match%2F0%2F2985298796%2F0.jpg&amp;refer=http%3A%2F%2Finews.gtimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1617869104&amp;t=54d2c95a6f95de01679291e9b76837dd" /></p><center>Fixed Wing Representative 1 - U.S. Army Predator drone in action</center><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/uav1.jpg" /></p><center>Fixed Wing Representative 1--Model view of U.S. Army Predator drone</center><h4 id="fixed-wing-representative-2---us-army-pixie-drone">Fixed-wingrepresentative 2 - US Army Pixie drone</h4><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/uav2.jpg" /></p><center>Fixed Wing Representative 2 - U.S. Army Pixie Drone Physical Image</center><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/uav3.jpg" /></p><center>Fixed-wing representative 2 - a model of the U.S. Army Pixie drone</center><h4 id="rotor-wing-representative---dji-f450-drone">Rotor wingrepresentative - DJI F450 drone</h4><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/uav4.jpg" /></p><center>Rotary wing representative - DJI F450 drone physical picture</center><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/uav5.jpg" /></p><center>Rotor representation - model image of DJI F450 drone</center><h2id="semantic-understanding-of-point-clouds-under-weakly-supervised-conditions">Semanticunderstanding of point clouds under weakly supervised conditions</h2><p>2020.10 - 2021.1</p><hr /><h3 id="description.-1">Description.</h3><p>To solve the problem of expensive data annotation in semanticsegmentation of 3D point clouds, an attempt is made to use a weaklysupervised learning approach for research. A review of the paper ispresented, and the "PointNet++" code is reproduced.</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/pointcloud%20mind.png" /></p><p>The programming languages and software tools used are.</p><ol type="1"><li>Python - code reproduction via Jupyter Notebook</li></ol><h3 id="achievements.-1">Achievements.</h3><p>Based on the PaddlePaddle framework of the Baidu AI platform, theclassification of disordered point clouds generated from ten sets offurniture images reproduced the 91.9% accuracy rate of the "PointNet++"paper.</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/point%20cloud2.jpg" /></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/point%20cloud3.jpg" /></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/point%20cloud4.jpg" /></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/point%20cloud5.jpg" /></p><h2 id="python-crawl-for-country-statistics">Python crawl for countrystatistics</h2><p>2021.1</p><hr /><h3 id="description.-2">Description.</h3><p>Independently, crawl the basic information of urban and ruralresidents' income and expenditure for eight provinces and six quartersfrom the "National Bureau of Statistics".</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/crawl%20mind.jpg" /></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/crawl2.jpg" /></p><p>The programming languages and software tools used are.</p><ol type="1"><li>Python -- crawler functionality through the panda library and tableprocessing through the xlwings library</li></ol><h3 id="achievements.-2">Achievements.</h3><p>Crawl the table data of eight provinces and six quarters of theNational Bureau of Statistics into excel tables, while the code cansieve invalid data, automatically organize the excel tables, and realizethe data centering and adaptive column width through xlwingslibrary.</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/crawl3.jpg" /></p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/crawl4.jpg" /></p><h2 id="app-creation-and-security-analysis">app creation and securityanalysis</h2><p>2019.10 - 2020.1</p><hr /><h3 id="description.-3">Description.</h3><p>App Implementation Requirements:The app has a user/password loginfunction and is available for user registration. The password forregistration is limited in length only (e.g. 8 digits in length), butthe strength is not required for now. The user name/password is saved onthe cell phone, and the password is encrypted when saved (choose yourown encryption algorithm).</p><p>The function is relatively simple, a floating window pops up, showingthat the app needs to obtain storage space, device information,geolocation permissions prompt, you can choose to authorize or deny. Byrunning the app on the phone, registering several accounts with strongand weak passwords, then analyzing the security and improving it.</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/app1.png" /></p><p>Code related to the client login function (Kotlin).</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/app2.png" /></p><p>Statements related to obtaining the permissions for storage space,device information, and geolocation permissions.</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/app3.png" /></p><p>Screenshot of Androbugs analysis.</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/app5.png" /></p><p>The analysis modifies the registration/login authentication method ofthe original app to use the authorization code pattern from the OAuth2specification: !</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/app6.png" /></p><p>Changed external storage to internal storage: !</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/app7.png" /></p><p>The programming languages and software tools used are.</p><ol type="1"><li>Kotlin -- implement app functions through Android Studio</li><li>Androbugs -- analyzing app security</li></ol><h3 id="accomplishments.">Accomplishments.</h3><p>The full runtime video is as follows.</p><p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTQwNjUwOA==' frameborder=0 allowfullscreen></iframe></p><h2id="experimenting-with-bypassing-authentication-systems">Experimentingwith bypassing authentication systems</h2><p>2019.9</p><hr /><h3 id="description.-4">Description.</h3><p>Many commercial WIFIs in shopping malls and restaurants use WEBPortal authentication, but some authentication systems are vulnerableand can bypass the gateway billing system using DNS TUNNEL. Thisvulnerability exists in commercial WIFI environments and can be verifiedto be able to use DNS TUNNEL to bypass the gateway billing system.</p><p>It is not really practical for DNS Tunnel to be used for"password-free Internet access". Even though our group had "cut out" theexpense of the cloud server (and moved the proxy server locally), thewhole experiment ended up costing $6 to purchase the domain name.</p><p>The programming languages and software tools used were</p><ol type="1"><li>Raspberry Pi -- build a local proxy server</li><li>Portal -- topology analysis and DNS simulation configuration</li></ol><h3 id="achievements.-3">Achievements.</h3><p>The whole experiment actually tells us: hackers will "see theneedle", DNS, a protocol dedicated to domain name queries, can also beused to transmit data. If you need to do network application layerprotocol design and maintenance work in the future, you must be doublycareful and be very cautious in network security. Also for individuals,if they connect to a public network, they must be vigilant to prevent"high-tech theft" because it is difficult to know where the hackers willtarget next.</p><iframe height="498" width="510" src="https://player.youku.com/embed/XNDg5NzI1OTY0OA==" frameborder="0" allowfullscreen></iframe><h2 id="ai-playing-tetris">AI playing Tetris</h2><p>2018.9</p><hr /><h3 id="description.-5">Description.</h3><p>Implementing a tetris game using pygame while setting up an AI (can'teven use machine learning algorithms)</p><p>The programming languages and software tools used are.</p><ol type="1"><li>Python - to implement Tetris logic and AI algorithms</li></ol><p>The basic idea of the AI algorithm is to traverse all possible futurescenarios consisting of the current operable tetris and the nextoperable tetris (according to different strategies, i.e., choosingdifferent positions and rotation angles) after they fall to thebottom</p><p>The merits of future scenes are judged based on.</p><pre><code>1) the number of rows that can be eliminated.2) the number of virtual holes inside the stacked Tetris blocks.3) the number of small squares in the stacked Tetris.(4) the highest point of the stacked tetris.5) the standard deviation of the heights (one height for each column) of the stacked Tetris.6) the first-order forward difference of the heights of the stacked Tetris blocks.7) the standard deviation of the first-order forward difference of the heights of the stacked Tetris blocks.8) the difference between the highest and lowest points of the stacked Tetris.</code></pre><p>Choose the optimal one from these future scenarios, whosecorresponding action strategy for the currently operable Tetris is thecurrent solution</p><h3 id="achievements.-4">Achievements.</h3><p>Video demonstration of dragging the source code while the game isrunning automatically to show that it is not a manual operation hh</p><p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTAwMTY4MA==' frameborder=0 allowfullscreen></iframe></p><h2 id="handwritten-number-recognition-gui">Handwritten numberrecognition GUI</h2><p>2020.11 - 2021.1</p><hr /><h3 id="description.-6">Description.</h3><p>Handwritten digit recognition GUI development without usingframeworks</p><p>The programming languages and software tools used are.</p><ol type="1"><li>Python - development of GUI interface (based on Qt5), involvingbasic bp algorithm implementation and optimization algorithms such asregularization (BN, L2 regularization, RMSProp), and implementation ofpyqt interface and three functions: extraction recognition in mnist,upload image recognition, and drawing board handwriting recognition</li></ol><h3 id="achievements.-5">Achievements.</h3><p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTAwMDg3Mg==' frameborder=0 allowfullscreen></iframe></p><h2 id="mario-diy-version">Mario DIY version</h2><p>2018.4 - 2018.6</p><hr /><h3 id="description.-7">Description.</h3><p>DIY a Mario with changed life settings and map scenes from theoriginal version.</p><p>Life cap can be increased by eating mushrooms and returning a portionof blood, while if the body is in villain form it turns into adult form.When hit, the form does not change and the HP is deductedaccordingly.</p><p>The programming language and software tools used are.</p><ol type="1"><li>Gamemaker - to develop the game interface, draw the game map andplay logic implementation</li></ol><p>Achievements.</p><p><strong>Pass demo and simple function demo</strong></p><p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTAwMjQxMg==' frameborder=0 allowfullscreen></iframe></p><p><strong>If HP is 0, then just die</strong></p><p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTAwNDE1Mg==' frameborder=0 allowfullscreen></iframe></p><h2 id="easy-version-of-magic-tower">Easy version of Magic Tower</h2><p>2017.11 - 2018.1</p><hr /><h3 id="description.-8">Description.</h3><p>Command line interface, operable simple version of Magic Tower</p><p>The programming languages and software tools used are.</p><ol type="1"><li>C++ -- drawing game maps and play logic implementation via commandline and strings</li></ol><h3 id="accomplishments.-1">Accomplishments.</h3><p><strong>Pass demo and simple functionality demo</strong></p><iframe height="498" width="510" src="https://player.youku.com/embed/XNDg5NzU4NDgzMg==" frameborder="0" allowfullscreen></iframe><h2 id="epidemic-map-applet">Epidemic map applet</h2><p>2020.6</p><hr /><h3 id="description.-9">Description.</h3><p>An epidemic map made during the epidemic, divided into two sections:domestic and foreign, each section is divided into two subsections:cumulative epidemic of the day and new epidemic of the day, citing thedata source of the open class bar, where the darker the color indicatesthe more infected people.</p><p>The programming languages and software tools used are.</p><ol type="1"><li>html -- citing the data source of Open Class Bar, trying tovisualize the figures</li></ol><h3 id="results.">Results.</h3><iframe height="498" width="510" src="https://player.youku.com/embed/XNDg5NzI4NDU0MA==" frameborder="0" allowfullscreen></iframe><h2 id="hardware-control-project">Hardware Control Project</h2><p>## Multiple switching methods for toy dogs</p><h2 id="gps-spoofing">GPS spoofing</h2><p>2019.9 - 2019.11</p><hr /><h3 id="description.-10">Description.</h3><p>In the Linux environment, the cell phone with GPS satellitepositioning is applied, and the HackRF One transmits a spoofing signalto achieve point-to-point spoofing or trajectory spoofing, which cansuccessfully spoof to the specified location within 1 or 2 minutes ofuninterrupted motion within the specified trajectory based on the givenacceleration and speed.</p><p>The programming language and software tools used are.</p><ol type="1"><li>Hardware: HackRF One - with TCXO clock module and antenna fortransmitting GPS signals</li><li>Software. | software | role | | ---- | ---- | | Google Earth |Selects the spoofed location and sketches the target trajectory | |SatGen | Target trajectory and store as motion path | | gps-sdr-sim |Samples data files to generate GPS data sources | | Gnuradio | Aflowchart-style program to run GPS spoofing | | hackrf-tools | Run GPSspoofing from the command line via the hackrf_transfer function |</li></ol><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Experience/gps%20mind.png" /></p><h3 id="achievements.-6">Achievements.</h3><p>The actual phone is located at a certain point in the living area ofGuangzhou University City and is stationary, and the position is spoofedto run at variable speed on the playground track of Shanghai JiaotongUniversity, 1,000 km away, within 5m accuracy throughout.</p><p><iframe height=498 width=510 src='https://player.youku.com/embed/XNDg0MTAwNDUyOA==' frameborder=0 allowfullscreen></iframe></p><p>2020.11 - 2021.1</p><hr /><h3 id="description.-11">Description.</h3><p>According to the toy electronic dog, through its circuit diagram ismodified accordingly, can get different switch corresponding way, inaddition to the following video has also been achieved magnetic control,small program control, Bluetooth control and other ways</p><p>The hardware modules used are.</p><ol type="1"><li>toy electronic dog -- with basic walking, barking function</li><li>circuit board -- to achieve different ways to switch and solder thecircuit</li><li>Bluetooth switch module -- with WeChat small program controlsystem</li></ol><h3 id="achievements.-7">Achievements.</h3><p><strong>keyed switch method</strong></p><iframe height="498" width="510" src="https://player.youku.com/embed/XNDg5NzI5MDU0MA==" frameborder="0" allowfullscreen></iframe><p><strong>Temperature control switch method</strong></p><iframe height="498" width="510" src="https://player.youku.com/embed/XNDg5NzI5MDcyMA==" frameborder="0" allowfullscreen></iframe><h2 id="arduino-based-music-player">Arduino-based music player</h2><p>2020.4 - 2020.6</p><hr /><h3 id="description.-12">Description.</h3><p>The basic functions of MP3 (track switching, multiple playback modes,volume adjustment) are implemented through cell phone (serial port) orcomputer input control.</p><p>The hardware modules used are.</p><ol type="1"><li>Arduino -- central processor</li><li>tf card -- storage of tracks</li><li>speaker -- play sound</li><li>LCD screen -- display playback mode, tracks</li></ol><h3 id="accomplishments.-2">Accomplishments.</h3><iframe height="498" width="510" src="https://player.youku.com/embed/XNDg0MTAzMDQwOA==" frameborder="0" allowfullscreen></iframe>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;software-programming-projects&quot;&gt;Software Programming
Projects&lt;/h1&gt;
&lt;h2
id=&quot;cluster-unmanned-aerial-vehicle-electromagnetic-calcula</summary>
      
    
    
    
    <category term="summary" scheme="https://serika-onoe.github.io/categories/summary/"/>
    
    
    <category term="research" scheme="https://serika-onoe.github.io/tags/research/"/>
    
    <category term="project" scheme="https://serika-onoe.github.io/tags/project/"/>
    
  </entry>
  
  <entry>
    <title>Develop Web Crawling in A National Statistic Institute</title>
    <link href="https://serika-onoe.github.io/2021/01/13/Develop%20Web%20Crawling%20in%20A%20National%20Statistic%20Institute/"/>
    <id>https://serika-onoe.github.io/2021/01/13/Develop%20Web%20Crawling%20in%20A%20National%20Statistic%20Institute/</id>
    <published>2021-01-12T16:12:47.000Z</published>
    <updated>2022-12-12T14:38:42.128Z</updated>
    
    <content type="html"><![CDATA[<h1 id="develop-web-crawling-in-a-national-statistic-institute">DevelopWeb Crawling in A National Statistic Institute</h1><p>** This experiment is to crawl the home page of "<ahref="https://data.stats.gov.cn/index.htm">National Bureau ofStatistics</a>" for the example of [Shanghai urban and rural residentsincome and expenditure basic information], other pages of the NationalBureau of Statistics crawl in a similar way **</p><h2 id="crawler-basic-process">1. Crawler basic process</h2><ol type="1"><li>initiate a request: launch a request to the target site through thehttp/https library, that is, send a request, the request can containadditional information such as headers, waiting for the server torespond</li><li>get the corresponding content: if the server can respond normally,it will get a response, the content of the response is the content ofthe page to be obtained, the type may be HTML, json string, binary data(such as pictures and videos) and other types</li><li>parsing content: the content may be HTML, you can use regularexpressions, web parsing library to parse, may be json, can be directlyconverted to json objects, may be binary data, you can do to save orfurther processing ** (The parsed content of this experiment isjson)**</li><li>save data: can be saved as text, can also be saved to the database,or a specific format file</li></ol><h2 id="open-the-web-page-and-analyze">2. Open the web page andanalyze</h2><p>The website of the National Bureau of Statistics is very strange, itis obviously https but it warns of insecurity, the first time theinterface is opened as follows (I use Google Chrome)</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/1.jpg" /></p><p>Click on "Advanced" - "Continue to" to enter the home page</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/2.jpg" /></p><p>Select "Quarterly Data" - "Quarterly Data by Province"</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/3.jpg" /></p><p>Select "People's Life" - "Urban and Rural Income and Expenditure"</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/4.jpg" /></p><p>Change the region to "Shanghai"</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/5.jpg" /></p><p>Press F12 to enter browser debugging mode</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/6.jpg" /></p><p>Refresh and re-fetch the page information, find easyquery.htm?m=QueryData&amp;dbc... file. You can check the "XHR" filter first to narrow thesearch</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/7.jpg" /></p><p>How can we make sure that this file contains the data we are lookingfor? By clicking on the "response" panel and dragging the slider to theright, you can see that the table data corresponds to each other (butthe data does not appear consecutively)</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/8.jpg" /></p><p>** Note: here data and strdata look the same, but the actual formatis not the same, data is int or double format, strdata is str format,this table has some empty data lines, string format is convenient to dojudgment, string to digital use eval () **</p><h2 id="full-code-and-parsing">3. Full code and parsing</h2><p>** Note: the missing libraries can be installed at the command lineusing the pip command, such as the lack of requests library, you canenter the command at the command line **</p><p>`<code>pip install requests</code></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib3 </span><br><span class="line"></span><br><span class="line"><span class="comment"># use urllib3.disable_warnings() with SSL authentication turned off (verify=False)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Disable secure request warnings for requests</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests <span class="comment"># Use Requests to send network requests</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time <span class="comment"># used to get timestamp (calculate current time for web validation)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json <span class="comment"># Process json files</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># Process arrays</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># np.array() to pd.DataFrame format, then use to_excel() to write to excel tables</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get millisecond timestamp for web validation</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getTime</span>():</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">int</span>(<span class="built_in">round</span>(time.time() * <span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># data preprocessing, get the srdata elements (data) wrapped in layers in a json list</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getList</span>(<span class="params">length</span>):</span><br><span class="line"></span><br><span class="line">  <span class="type">List</span>=[]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(length):</span><br><span class="line"></span><br><span class="line">temp = js[<span class="string">&#x27;returndata&#x27;</span>][<span class="string">&#x27;datanodes&#x27;</span>][i][<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;strdata&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># urban and rural residents income and expenditure list, the original site has a year-on-year growth data is empty, if you directly use eval() will report an error, you need to determine first</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(<span class="built_in">len</span>(temp)! =<span class="number">0</span>):</span><br><span class="line"></span><br><span class="line"><span class="comment"># eval() number to string</span></span><br><span class="line"></span><br><span class="line"><span class="type">List</span>.append(<span class="built_in">eval</span>(temp))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="type">List</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">  <span class="comment"># request target URL (link? preceded by something)</span></span><br><span class="line"></span><br><span class="line">  url=<span class="string">&#x27;https://data.stats.gov.cn/easyquery.htm&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># request headers, User-Agent: used to prove you are a browser, just meet a certain format, not necessarily the same as your own browser</span></span><br><span class="line"></span><br><span class="line">  headers=&#123;<span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0(Windows;U;Windows NT6.1;en-US;rv:1.9.1.6) Geko/20091201 Firefox/3.5.6&#x27;</span>&#125;<span class="comment"># browser agent</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Construct parameter key-value pairs, with specific values obtained from the page structure parameters</span></span><br><span class="line"></span><br><span class="line">  key=&#123;&#125;</span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;m&#x27;</span>]=<span class="string">&#x27;QueryData&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;dbcode&#x27;</span>]=<span class="string">&#x27;fsjd&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;rowcode&#x27;</span>]=<span class="string">&#x27;zb&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;colcode&#x27;</span>]=<span class="string">&#x27;sj&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;wds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;: &quot;reg&quot;, &quot;valuecode&quot;: &quot;310000&quot;&#125;]&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;k1&#x27;</span>]=<span class="built_in">str</span>(getTime()) </span><br><span class="line"></span><br><span class="line">  <span class="comment"># &quot;wdcode&quot;: &quot;reg&quot; region field</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Shanghai 310000 </span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;dfwds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;: &quot;zb&quot;, &quot;valuecode&quot;: &quot;A0300&quot;&#125;,&#123;&quot;wdcode&quot;: &quot;sj&quot;, &quot;valuecode&quot;: &quot;LAST6&quot;&#125;]&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># &quot;wdcode&quot;: &quot;zb&quot; select which entry on the left, &quot;wdcode&quot;: &quot;sj&quot; option box select &quot;LAST 6 QUARTERS&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Disable security request warnings</span></span><br><span class="line"></span><br><span class="line">  requests.packages.urllib3.disable_warnings()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Send the request, using the post method, here using the previous custom header and parameters</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># ! verify=False, the NSO switched to https protocol in the second half of 20 years, if not add the code can not pass SSL verification</span></span><br><span class="line"></span><br><span class="line">  r = requests.post(url, headers=headers, params=key,verify=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Use the json library loads function to parse the r.text string into a dict dictionary format and store it in js</span></span><br><span class="line"></span><br><span class="line">  js = json.loads(r.text)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># get the required data of a one-dimensional array, using np.array().reshape() to organize into two-dimensional arrays</span></span><br><span class="line"></span><br><span class="line">  length=<span class="built_in">len</span>(js[<span class="string">&#x27;returndata&#x27;</span>][<span class="string">&#x27;datanodes&#x27;</span>])</span><br><span class="line"></span><br><span class="line">  res=getList(length)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Total data divided into 6 rows of format</span></span><br><span class="line"></span><br><span class="line">  array=np.array(res).reshape(<span class="built_in">len</span>(res)//<span class="number">6</span>,<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># np.array() is converted to pd.DataFrame format, the subsequent can use to_excel() to write directly to excel tables</span></span><br><span class="line"></span><br><span class="line">  df_shanghai=pd.DataFrame(array)</span><br><span class="line"></span><br><span class="line">  df_shanghai.columns=[<span class="string">&#x27;2020 Q3&#x27;</span>,<span class="string">&#x27;2020 Q2&#x27;</span>,<span class="string">&#x27;2020 Q1&#x27;</span>,<span class="string">&#x27;2019 Q4&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;2019 third quarter&#x27;</span>,<span class="string">&#x27;2019 second quarter&#x27;</span>]</span><br><span class="line"></span><br><span class="line">  df_shanghai.index=[<span class="string">&#x27;Cumulative value of per capita disposable income of residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita disposable income of urban residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita disposable income of rural residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita consumption expenditure of residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita consumption expenditure of urban residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita consumption expenditure of rural residents (yuan)&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="built_in">print</span>(df_shanghai)</span><br></pre></td></tr></table></figure><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/9.jpg" /></p><h2 id="partial-code-description">4. Partial code description</h2><h3 id="data-extraction">data extraction</h3><p>Getting the data in the table requires first analyzing the extractedjs file, which prints the following.</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/10.jpg" /></p><p>Strip the five layers of the list layer by layer to get the requiredsrdata</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/11.jpg" /></p><h3 id="request-website">Request website</h3><p>Request target URL (''?'' preceded by something)</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url=<span class="string">&#x27;https://data.stats.gov.cn/easyquery.htm&#x27;</span></span><br></pre></td></tr></table></figure><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/12.jpg" /></p><p>Request header, User-Agent: used to prove that you are a browser,just meet a certain format, not necessarily the same as your ownbrowser</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">headers=&#123;<span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0(Windows;U;Windows NT6.1;en-US;rv:1.9.1.6) Geko/20091201 Firefox/3.5.6&#x27;</span>&#125;<span class="comment">#browser agent</span></span><br></pre></td></tr></table></figure><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/13.jpg" /></p><p>Construct the parameter key-value pairs, the following parameterswill be concatenated with &amp; and placed in the ''?'' of the linkfollowed by</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">key=&#123;&#125;</span><br><span class="line">key[<span class="string">&#x27;m&#x27;</span>]=<span class="string">&#x27;QueryData&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;dbcode&#x27;</span>]=<span class="string">&#x27;fsjd&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;rowcode&#x27;</span>]=<span class="string">&#x27;zb&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;colcode&#x27;</span>]=<span class="string">&#x27;sj&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;wds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;: &quot;reg&quot;, &quot;valuecode&quot;: &quot;310000&quot;&#125;]&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;k1&#x27;</span>]=<span class="built_in">str</span>(getTime())  </span><br><span class="line">key[<span class="string">&#x27;dfwds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;: &quot;zb&quot;, &quot;valuecode&quot;: &quot;A0300&quot;&#125;,&#123;&quot;wdcode&quot;: &quot;sj&quot;, &quot;valuecode&quot;: &quot;LAST6&quot;&#125;]&#x27;</span></span><br></pre></td></tr></table></figure><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/14.jpg" /></p><p>Some of the parameters can be seen in the position shown below, someof them are not shown by default, if you need to show the same page, youneed to select the corresponding option in the option box</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/15.jpg" /></p><h2 id="save-data-to-excel-sheet">5. Save data to excel sheet</h2><p>The data crawled by the crawler is now stored in panda.dataframeformat, and can be saved directly in an excel table using the to_excel()function</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># write object for this Excel workbook, use this method to save multiple worksheets</span></span><br><span class="line">    write = pd.ExcelWriter(<span class="string">&#x27;F:/Ivory_Tower/norm/provincial quarterly data_urban and rural residents income and expenditure.xls&#x27;</span>) <span class="comment"># The path can be set by yourself, there is no such file will create one on its own, if it exists, write will overwrite the original content</span></span><br><span class="line">    df_shanghai.to_excel(write,sheet_name=<span class="string">&#x27;Shanghai&#x27;</span>)</span><br><span class="line">    <span class="comment"># If you climb multiple provinces, you can write to multiple worksheets and must add save() to save the data</span></span><br><span class="line">    write.save()</span><br></pre></td></tr></table></figure><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/16.jpg" /></p><h2 id="table-optimization-optional">6. Table optimization(optional)</h2><p>You can optimize the table format with the help of python code, asshown above the results are not satisfactory, at least the need toautomatically adjust the column width.</p><p>Here I use xlwings library, you need to first download thecorresponding library in the command line</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install xlwings</span><br><span class="line">pip install pywin32</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Use the xlwings library to edit and organize Excel tables with python</span></span><br><span class="line"><span class="keyword">import</span> xlwings <span class="keyword">as</span> xw</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app=xw.App(visible=<span class="literal">False</span>,add_book=<span class="literal">False</span>) <span class="comment"># process is not visible, no new worksheet is added</span></span><br><span class="line">    wb=app.books.<span class="built_in">open</span>(<span class="string">r&#x27;F:/Ivory_Tower/norm/province_quarterly_income_and_expense_of_urban_rural_residents.xls&#x27;</span>)</span><br><span class="line">    <span class="comment"># wb is the new workbook (workbook)</span></span><br><span class="line">    <span class="comment"># For each of the 8 worksheets, do the following</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>): </span><br><span class="line">        rng=wb.sheets[i].<span class="built_in">range</span>(<span class="string">&#x27;A1:H20&#x27;</span>) <span class="comment"># select these cells</span></span><br><span class="line">        rng.api.HorizontalAlignment = -<span class="number">4108</span> <span class="comment"># center the text horizontally</span></span><br><span class="line">        rng.autofit() <span class="comment"># automatically adjust the row height and column width</span></span><br><span class="line">    wb.save()</span><br><span class="line">    wb.close()</span><br><span class="line">    app.quit()</span><br></pre></td></tr></table></figure><p>Run the code, you can get the following effect (subsequently crawledsome other provinces, modify the corresponding parameters at the key canbe)</p><p><imgsrc="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/17.jpg" /></p><h2 id="references">7. References</h2><p>The history of super detailed python crawl the National Bureau ofStatistics data:https://blog.csdn.net/qq_41988893/article/details/103017854</p><p>If you report a variety of other inexplicable errors, you can commentor private letter to ask ~</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;develop-web-crawling-in-a-national-statistic-institute&quot;&gt;Develop
Web Crawling in A National Statistic Institute&lt;/h1&gt;
&lt;p&gt;** This exp</summary>
      
    
    
    
    <category term="project" scheme="https://serika-onoe.github.io/categories/project/"/>
    
    
    <category term="python" scheme="https://serika-onoe.github.io/tags/python/"/>
    
    <category term="crawler" scheme="https://serika-onoe.github.io/tags/crawler/"/>
    
  </entry>
  
  <entry>
    <title>In-game Card Draw Mechanism Summary</title>
    <link href="https://serika-onoe.github.io/2020/09/06/In-game%20Card%20Draw%20Mechanism%20Summary/"/>
    <id>https://serika-onoe.github.io/2020/09/06/In-game%20Card%20Draw%20Mechanism%20Summary/</id>
    <published>2020-09-06T03:00:00.000Z</published>
    <updated>2022-12-12T14:42:09.150Z</updated>
    
    <content type="html"><![CDATA[<h2 id="write-in-front">Write in front</h2><p>Card games are very good at carrying the core element of acg -"character", card draws have a great positive effect on inventorycurrency consumption and new currency, and players who participated incard draws also account for a high percentage of rechargeable users.Card draw is indeed a very important payment point at the moment</p><p>But I know that "Xuan does not change the wrong, krypton can changethe life", and because it is a light player and do not want to chargemoney to become stronger, so the card game is not played, Yin Yang Shi,Tomorrow's Ark, sword and expedition are slightly contact, and each gamehas its own card draw probability.</p><p>The SSR is about 1%, and the probability of the sword and expeditionis about 4.8%, but for the sake of user experience, the most importantthing is not to let the time players open up the gap of RMB players, notto violate the principle of big R crush small R, so the so-called randomis basically pseudo-random.</p><p>The pure dry goods, in order not to affect the reading will not putthe picture, the following introduction of some common card drawmechanism.</p><h3 id="guarantee-mechanism">① Guarantee mechanism</h3><p>This is the simplest and most common mechanism, such as the "King ofGlory", the number of purchases reached 361 times, the probability ofglory crystal output is 100%. The two guaranteed mechanisms of "Swordand Expedition", 30 draws must be purple card, in the same card poolcumulative draw 30 times to get a purple card hero whether it is asingle draw or continuous draw, as long as the number reaches that mustbe purple card.</p><p>There is also a guaranteed mechanism is 10 consecutive draws must bea rare or elite level hero, and 30 draws is not the same place is onlyapplicable to ten consecutive draws and not applicable to ten singledraws.</p><p>The guarantee mechanism ensures the ultimate player experience</p><h3 id="metaphysical-lottery-method">② Metaphysical lottery method</h3><p>In some card-drawing games it is used for certain purposes, probablybecause the game developers sometimes refer to other data when writingthe card-drawing procedure, and then add certain algorithms to decidewhich card to draw, which is where the player metaphysics comesfrom.</p><p>If the referenced data is the current system time, then there is apossibility that "the card draw rate is high at a certain time in themorning, or the rate is high in the first 10 minutes of every hour".</p><p>Although the result is decided in the server at the moment you drawthe card, it has nothing to do with what pattern is drawn or whichmethod is used, but the game makers are still happy to leave aplayer-led process, so that players believe that it is the card drawingprocess that affects the result of card drawing, and the process is fullof rituals.</p><h3id="probability-increment-i-dont-know-if-the-industry-is-called-water-level">③Probabilityincrement (I don't know if the industry is called water level)</h3><p>Incremental probability method, refers to the card draw, the moretimes the card is drawn, the higher the burst rate of card draw method.If you have drawn before you have accumulated this value, then theprobability is returned to zero.</p><p>It can keep the player's game experience in a more balancedposition.</p><h3 id="prize-pool-division">④ Prize pool division</h3><p>This method of card drawing is more complicated and is more common ingames that frequently release new cards.</p><p>When a player draws, it is determined which prize pool the playerenters (R,SR,SSR) and then which card the player draws in that pool. Ifa new card is officially added, a single pool will be created and an oldcard will be implicitly removed, so players will not be too concernedabout the rate of old cards and will be happy to draw more newcards.</p><h3 id="scripted-card-draw">⑤ Scripted card draw</h3><p>All of the decks in Air Dangling Solitaire are already written, andeach time you start a game, you pick one from the deck script.</p><p>The game "Landlord" is officially written to have multiple pairs,planes and bombs, and randomly dealt cards are likely to appear as loosecards.</p><h3 id="kryptonite-distinguishes-card-draw">⑥Kryptonite distinguishescard draw</h3><p>The original game is to recharge how much to send a lottery, andgenerally get very precious game props. Now a data bar will be addedimplicitly to calculate the amount of player recharge and divide thelevel to adjust the probability to improve the game experience forkryptonite players.</p><p>If a certain currency can be obtained both from in-game liver and theoption to recharge, then the official can secretly set a status bar todistinguish between the activity liver and the recharge, and each time alottery is drawn, it will identify which type of diamond is used forthis lottery. If you use both types of diamonds at the same time, thedefault may be the one you got by recharging, and then the probabilitywill be greater than the one you got by using the liver.</p><h3 id="other-ways-to-play-with-card-draw-promotions">⑦ Other ways toplay with card draw promotions</h3><p>A common way to show this is to enter the game and just give theplayer a sum of money enough for the first draw, guiding the player todo the draw and then get precious props.</p><p>Or when drawing, the system suddenly reminds you: you get a chance tobuy rare props with an added time limit.</p><p>There is also a way to adjust the burst rate of different itemsaccording to the prop needs of new players. For example, if thecollection set is missing that one part, it is likely to pop out whenthe lottery is drawn.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;write-in-front&quot;&gt;Write in front&lt;/h2&gt;
&lt;p&gt;Card games are very good at carrying the core element of acg -
&quot;character&quot;, card draws have</summary>
      
    
    
    
    <category term="collection" scheme="https://serika-onoe.github.io/categories/collection/"/>
    
    
    <category term="acg" scheme="https://serika-onoe.github.io/tags/acg/"/>
    
    <category term="card draw" scheme="https://serika-onoe.github.io/tags/card-draw/"/>
    
    <category term="game" scheme="https://serika-onoe.github.io/tags/game/"/>
    
  </entry>
  
  <entry>
    <title>My first blog</title>
    <link href="https://serika-onoe.github.io/2020/02/11/My%20first%20blog/"/>
    <id>https://serika-onoe.github.io/2020/02/11/My%20first%20blog/</id>
    <published>2020-02-11T04:14:00.000Z</published>
    <updated>2022-12-12T14:43:01.233Z</updated>
    
    <content type="html"><![CDATA[<h1 id="why-i-make-this-blog">Why I make this blog</h1><p>Blogging is an idea that has been brewing for a long time, and Ibelieve that most people have been procrastinating for a long time tomake this decision hh. However, besides habitual laziness, there is alsothe consideration that they are not confident of their technical level,after all, the big cows are very few, and most people are just hoveringaround the average line.</p><p>But the brain does not make decisions purely rational, but mainlybased on emotion. After setting up a target and setting down adirection, the rational mind will actively rationalize the behavior.</p><p>I have summarized the following motivations as to why I startedblogging on a whim.</p><ul><li><p>I have developed the habit of consulting a lot of informationbefore I start writing, both inside and outside the classroom. I have alot of respect and gratitude for those who have the spirit of opensource, the seniors. Many times, a concise and clear conclusion, a lineof highly generalized code, often rely on their own exploration to halfthe effort, and may even be in the knowledge of the blind (UnknownUnknown) and make unnecessary suffering, was left by the seniors in theblog article inadvertently a break, such moments simply not toomuch.</p></li><li><p>Evolved from a pure white to now a in many areas have someexperience in the beginning of the .... For the white guy, I also hopeto make up for the pit that I fell into at that time, at least to make awarning in front that there is no need for newcomers to take detours inthe environment building stage, and to focus on the debugging stage ofthe program to solve the needs and achieve higher self-improvementefficiency.</p></li><li><p>As the saying goes: "Good memory is better than bad penmanship."Before reading a book on how to take notes efficiently, but the papernotes are also often impossible to flip through. Nowadays, I often usemy cell phone to browse many fragmented knowledge points, which are noteffectively organized. The existence of blogs also has a kind ofdemocratic supervision in it than private notes, to avoid personalcognitive bias and limitations.</p></li><li><p>I often imagine how to explain the knowledge to a novice when Istudy, and blogging is equivalent to instantiating and visualizing thisprocess.</p></li></ul><h1 id="what-to-record">What to record</h1><p>During my bachelor years, I learned a lot of things at the principlelevel in class, and I have a wide range of interests outside of class.In order to avoid the problem of making a slapdash approach, I summarizethe knowledge and techniques I learned in the following areas and takethe time to record them.</p><ul><li>Programming languages: C, Python, JAVA, etc.</li><li>Software installation classes: Android Studio, WordPress, etc.</li><li>Audio editing: pr, ps, au, etc.</li></ul><p>Blog update frequency try to keep in a week or two, here first for amemorial, later if you need to add changes.</p><p>There is a poem: "green hills together with the clouds and rain, themoon has been two hometowns."</p><p>I hope the content in my blog may help you.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;why-i-make-this-blog&quot;&gt;Why I make this blog&lt;/h1&gt;
&lt;p&gt;Blogging is an idea that has been brewing for a long time, and I
believe that m</summary>
      
    
    
    
    <category term="summary" scheme="https://serika-onoe.github.io/categories/summary/"/>
    
    
    <category term="first" scheme="https://serika-onoe.github.io/tags/first/"/>
    
    <category term="introduction" scheme="https://serika-onoe.github.io/tags/introduction/"/>
    
  </entry>
  
</feed>
