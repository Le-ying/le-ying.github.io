<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Develop Web Crawling in A National Statistic Institute | Kung's Blog</title><meta name="author" content="Richard KUNG"><meta name="copyright" content="Richard KUNG"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Develop Web Crawling in A National Statistic Institute ** This experiment is to crawl the home page of &quot;National Bureau of Statistics&quot; for the example of [Shanghai urban and rural residents income">
<meta property="og:type" content="article">
<meta property="og:title" content="Develop Web Crawling in A National Statistic Institute">
<meta property="og:url" content="https://serika-onoe.github.io/2021/01/13/Develop%20Web%20Crawling%20in%20A%20National%20Statistic%20Institute/index.html">
<meta property="og:site_name" content="Kung&#39;s Blog">
<meta property="og:description" content="Develop Web Crawling in A National Statistic Institute ** This experiment is to crawl the home page of &quot;National Bureau of Statistics&quot; for the example of [Shanghai urban and rural residents income">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/8.jpg">
<meta property="article:published_time" content="2021-01-12T16:12:47.000Z">
<meta property="article:modified_time" content="2022-12-12T14:38:42.128Z">
<meta property="article:author" content="Richard KUNG">
<meta property="article:tag" content="python">
<meta property="article:tag" content="crawler">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/8.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://serika-onoe.github.io/2021/01/13/Develop%20Web%20Crawling%20in%20A%20National%20Statistic%20Institute/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"W5J7GO3HT8","apiKey":"53b7d5d068605c78d1a20d7f3671629a","indexName":"test_serika","hits":{"per_page":3},"languages":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}.","hits_stats":"${hits} results found in ${time} ms"}},
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Develop Web Crawling in A National Statistic Institute',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-12-12 22:38:42'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/CodeByZach/pace/themes/green/pace-theme-flash.css"><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Kung's Blog" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">9</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archive</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Links</span></a></div><div class="menus_item"><a class="site-page" href="/../"><i class="fa-fw fas fa-language"></i><span> 中文</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://github.com/serika-onoe/web-img/raw/main/Python_crawler/8.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Kung's Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archive</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Links</span></a></div><div class="menus_item"><a class="site-page" href="/../"><i class="fa-fw fas fa-language"></i><span> 中文</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Develop Web Crawling in A National Statistic Institute</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2021-01-12T16:12:47.000Z" title="Created 2021-01-13 00:12:47">2021-01-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-12-12T14:38:42.128Z" title="Updated 2022-12-12 22:38:42">2022-12-12</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/project/">project</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Develop Web Crawling in A National Statistic Institute"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="develop-web-crawling-in-a-national-statistic-institute">Develop
Web Crawling in A National Statistic Institute</h1>
<p>** This experiment is to crawl the home page of "<a
target="_blank" rel="noopener" href="https://data.stats.gov.cn/index.htm">National Bureau of
Statistics</a>" for the example of [Shanghai urban and rural residents
income and expenditure basic information], other pages of the National
Bureau of Statistics crawl in a similar way **</p>
<h2 id="crawler-basic-process">1. Crawler basic process</h2>
<ol type="1">
<li>initiate a request: launch a request to the target site through the
http/https library, that is, send a request, the request can contain
additional information such as headers, waiting for the server to
respond</li>
<li>get the corresponding content: if the server can respond normally,
it will get a response, the content of the response is the content of
the page to be obtained, the type may be HTML, json string, binary data
(such as pictures and videos) and other types</li>
<li>parsing content: the content may be HTML, you can use regular
expressions, web parsing library to parse, may be json, can be directly
converted to json objects, may be binary data, you can do to save or
further processing ** (The parsed content of this experiment is
json)**</li>
<li>save data: can be saved as text, can also be saved to the database,
or a specific format file</li>
</ol>
<h2 id="open-the-web-page-and-analyze">2. Open the web page and
analyze</h2>
<p>The website of the National Bureau of Statistics is very strange, it
is obviously https but it warns of insecurity, the first time the
interface is opened as follows (I use Google Chrome)</p>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/1.jpg" /></p>
<p>Click on "Advanced" - "Continue to" to enter the home page</p>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/2.jpg" /></p>
<p>Select "Quarterly Data" - "Quarterly Data by Province"</p>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/3.jpg" /></p>
<p>Select "People's Life" - "Urban and Rural Income and Expenditure"</p>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/4.jpg" /></p>
<p>Change the region to "Shanghai"</p>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/5.jpg" /></p>
<p>Press F12 to enter browser debugging mode</p>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/6.jpg" /></p>
<p>Refresh and re-fetch the page information, find easyquery.htm?m=Query
Data&amp;dbc... file. You can check the "XHR" filter first to narrow the
search</p>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/7.jpg" /></p>
<p>How can we make sure that this file contains the data we are looking
for? By clicking on the "response" panel and dragging the slider to the
right, you can see that the table data corresponds to each other (but
the data does not appear consecutively)</p>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/8.jpg" /></p>
<p>** Note: here data and strdata look the same, but the actual format
is not the same, data is int or double format, strdata is str format,
this table has some empty data lines, string format is convenient to do
judgment, string to digital use eval () **</p>
<h2 id="full-code-and-parsing">3. Full code and parsing</h2>
<p>** Note: the missing libraries can be installed at the command line
using the pip command, such as the lack of requests library, you can
enter the command at the command line **</p>
<p>`<code>pip install requests</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib3 </span><br><span class="line"></span><br><span class="line"><span class="comment"># use urllib3.disable_warnings() with SSL authentication turned off (verify=False)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Disable secure request warnings for requests</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests <span class="comment"># Use Requests to send network requests</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time <span class="comment"># used to get timestamp (calculate current time for web validation)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json <span class="comment"># Process json files</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># Process arrays</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># np.array() to pd.DataFrame format, then use to_excel() to write to excel tables</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get millisecond timestamp for web validation</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getTime</span>():</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">int</span>(<span class="built_in">round</span>(time.time() * <span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># data preprocessing, get the srdata elements (data) wrapped in layers in a json list</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getList</span>(<span class="params">length</span>):</span><br><span class="line"></span><br><span class="line">  <span class="type">List</span>=[]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(length):</span><br><span class="line"></span><br><span class="line">temp = js[<span class="string">&#x27;returndata&#x27;</span>][<span class="string">&#x27;datanodes&#x27;</span>][i][<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;strdata&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># urban and rural residents income and expenditure list, the original site has a year-on-year growth data is empty, if you directly use eval() will report an error, you need to determine first</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(<span class="built_in">len</span>(temp)! =<span class="number">0</span>):</span><br><span class="line"></span><br><span class="line"><span class="comment"># eval() number to string</span></span><br><span class="line"></span><br><span class="line"><span class="type">List</span>.append(<span class="built_in">eval</span>(temp))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="type">List</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">  <span class="comment"># request target URL (link? preceded by something)</span></span><br><span class="line"></span><br><span class="line">  url=<span class="string">&#x27;https://data.stats.gov.cn/easyquery.htm&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># request headers, User-Agent: used to prove you are a browser, just meet a certain format, not necessarily the same as your own browser</span></span><br><span class="line"></span><br><span class="line">  headers=&#123;<span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0(Windows;U;Windows NT6.1;en-US;rv:1.9.1.6) Geko/20091201 Firefox/3.5.6&#x27;</span>&#125;<span class="comment"># browser agent</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Construct parameter key-value pairs, with specific values obtained from the page structure parameters</span></span><br><span class="line"></span><br><span class="line">  key=&#123;&#125;</span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;m&#x27;</span>]=<span class="string">&#x27;QueryData&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;dbcode&#x27;</span>]=<span class="string">&#x27;fsjd&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;rowcode&#x27;</span>]=<span class="string">&#x27;zb&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;colcode&#x27;</span>]=<span class="string">&#x27;sj&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;wds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;: &quot;reg&quot;, &quot;valuecode&quot;: &quot;310000&quot;&#125;]&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;k1&#x27;</span>]=<span class="built_in">str</span>(getTime()) </span><br><span class="line"></span><br><span class="line">  <span class="comment"># &quot;wdcode&quot;: &quot;reg&quot; region field</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Shanghai 310000 </span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;dfwds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;: &quot;zb&quot;, &quot;valuecode&quot;: &quot;A0300&quot;&#125;,&#123;&quot;wdcode&quot;: &quot;sj&quot;, &quot;valuecode&quot;: &quot;LAST6&quot;&#125;]&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># &quot;wdcode&quot;: &quot;zb&quot; select which entry on the left, &quot;wdcode&quot;: &quot;sj&quot; option box select &quot;LAST 6 QUARTERS&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Disable security request warnings</span></span><br><span class="line"></span><br><span class="line">  requests.packages.urllib3.disable_warnings()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Send the request, using the post method, here using the previous custom header and parameters</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># ! verify=False, the NSO switched to https protocol in the second half of 20 years, if not add the code can not pass SSL verification</span></span><br><span class="line"></span><br><span class="line">  r = requests.post(url, headers=headers, params=key,verify=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Use the json library loads function to parse the r.text string into a dict dictionary format and store it in js</span></span><br><span class="line"></span><br><span class="line">  js = json.loads(r.text)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># get the required data of a one-dimensional array, using np.array().reshape() to organize into two-dimensional arrays</span></span><br><span class="line"></span><br><span class="line">  length=<span class="built_in">len</span>(js[<span class="string">&#x27;returndata&#x27;</span>][<span class="string">&#x27;datanodes&#x27;</span>])</span><br><span class="line"></span><br><span class="line">  res=getList(length)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Total data divided into 6 rows of format</span></span><br><span class="line"></span><br><span class="line">  array=np.array(res).reshape(<span class="built_in">len</span>(res)//<span class="number">6</span>,<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># np.array() is converted to pd.DataFrame format, the subsequent can use to_excel() to write directly to excel tables</span></span><br><span class="line"></span><br><span class="line">  df_shanghai=pd.DataFrame(array)</span><br><span class="line"></span><br><span class="line">  df_shanghai.columns=[<span class="string">&#x27;2020 Q3&#x27;</span>,<span class="string">&#x27;2020 Q2&#x27;</span>,<span class="string">&#x27;2020 Q1&#x27;</span>,<span class="string">&#x27;2019 Q4&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;2019 third quarter&#x27;</span>,<span class="string">&#x27;2019 second quarter&#x27;</span>]</span><br><span class="line"></span><br><span class="line">  df_shanghai.index=[<span class="string">&#x27;Cumulative value of per capita disposable income of residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita disposable income of urban residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita disposable income of rural residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita consumption expenditure of residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita consumption expenditure of urban residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita consumption expenditure of rural residents (yuan)&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="built_in">print</span>(df_shanghai)</span><br></pre></td></tr></table></figure>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/9.jpg" /></p>
<h2 id="partial-code-description">4. Partial code description</h2>
<h3 id="data-extraction">data extraction</h3>
<p>Getting the data in the table requires first analyzing the extracted
js file, which prints the following.</p>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/10.jpg" /></p>
<p>Strip the five layers of the list layer by layer to get the required
srdata</p>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/11.jpg" /></p>
<h3 id="request-website">Request website</h3>
<p>Request target URL (''?'' preceded by something)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url=<span class="string">&#x27;https://data.stats.gov.cn/easyquery.htm&#x27;</span></span><br></pre></td></tr></table></figure>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/12.jpg" /></p>
<p>Request header, User-Agent: used to prove that you are a browser,
just meet a certain format, not necessarily the same as your own
browser</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">headers=&#123;<span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0(Windows;U;Windows NT6.1;en-US;rv:1.9.1.6) Geko/20091201 Firefox/3.5.6&#x27;</span>&#125;<span class="comment">#browser agent</span></span><br></pre></td></tr></table></figure>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/13.jpg" /></p>
<p>Construct the parameter key-value pairs, the following parameters
will be concatenated with &amp; and placed in the ''?'' of the link
followed by</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">key=&#123;&#125;</span><br><span class="line">key[<span class="string">&#x27;m&#x27;</span>]=<span class="string">&#x27;QueryData&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;dbcode&#x27;</span>]=<span class="string">&#x27;fsjd&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;rowcode&#x27;</span>]=<span class="string">&#x27;zb&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;colcode&#x27;</span>]=<span class="string">&#x27;sj&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;wds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;: &quot;reg&quot;, &quot;valuecode&quot;: &quot;310000&quot;&#125;]&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;k1&#x27;</span>]=<span class="built_in">str</span>(getTime())  </span><br><span class="line">key[<span class="string">&#x27;dfwds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;: &quot;zb&quot;, &quot;valuecode&quot;: &quot;A0300&quot;&#125;,&#123;&quot;wdcode&quot;: &quot;sj&quot;, &quot;valuecode&quot;: &quot;LAST6&quot;&#125;]&#x27;</span></span><br></pre></td></tr></table></figure>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/14.jpg" /></p>
<p>Some of the parameters can be seen in the position shown below, some
of them are not shown by default, if you need to show the same page, you
need to select the corresponding option in the option box</p>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/15.jpg" /></p>
<h2 id="save-data-to-excel-sheet">5. Save data to excel sheet</h2>
<p>The data crawled by the crawler is now stored in panda.dataframe
format, and can be saved directly in an excel table using the to_excel()
function</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># write object for this Excel workbook, use this method to save multiple worksheets</span></span><br><span class="line">    write = pd.ExcelWriter(<span class="string">&#x27;F:/Ivory_Tower/norm/provincial quarterly data_urban and rural residents income and expenditure.xls&#x27;</span>) <span class="comment"># The path can be set by yourself, there is no such file will create one on its own, if it exists, write will overwrite the original content</span></span><br><span class="line">    df_shanghai.to_excel(write,sheet_name=<span class="string">&#x27;Shanghai&#x27;</span>)</span><br><span class="line">    <span class="comment"># If you climb multiple provinces, you can write to multiple worksheets and must add save() to save the data</span></span><br><span class="line">    write.save()</span><br></pre></td></tr></table></figure>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/16.jpg" /></p>
<h2 id="table-optimization-optional">6. Table optimization
(optional)</h2>
<p>You can optimize the table format with the help of python code, as
shown above the results are not satisfactory, at least the need to
automatically adjust the column width.</p>
<p>Here I use xlwings library, you need to first download the
corresponding library in the command line</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install xlwings</span><br><span class="line">pip install pywin32</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Use the xlwings library to edit and organize Excel tables with python</span></span><br><span class="line"><span class="keyword">import</span> xlwings <span class="keyword">as</span> xw</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app=xw.App(visible=<span class="literal">False</span>,add_book=<span class="literal">False</span>) <span class="comment"># process is not visible, no new worksheet is added</span></span><br><span class="line">    wb=app.books.<span class="built_in">open</span>(<span class="string">r&#x27;F:/Ivory_Tower/norm/province_quarterly_income_and_expense_of_urban_rural_residents.xls&#x27;</span>)</span><br><span class="line">    <span class="comment"># wb is the new workbook (workbook)</span></span><br><span class="line">    <span class="comment"># For each of the 8 worksheets, do the following</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>): </span><br><span class="line">        rng=wb.sheets[i].<span class="built_in">range</span>(<span class="string">&#x27;A1:H20&#x27;</span>) <span class="comment"># select these cells</span></span><br><span class="line">        rng.api.HorizontalAlignment = -<span class="number">4108</span> <span class="comment"># center the text horizontally</span></span><br><span class="line">        rng.autofit() <span class="comment"># automatically adjust the row height and column width</span></span><br><span class="line">    wb.save()</span><br><span class="line">    wb.close()</span><br><span class="line">    app.quit()</span><br></pre></td></tr></table></figure>
<p>Run the code, you can get the following effect (subsequently crawled
some other provinces, modify the corresponding parameters at the key can
be)</p>
<p><img
src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/17.jpg" /></p>
<h2 id="references">7. References</h2>
<p>The history of super detailed python crawl the National Bureau of
Statistics data:
https://blog.csdn.net/qq_41988893/article/details/103017854</p>
<p>If you report a variety of other inexplicable errors, you can comment
or private letter to ask ~</p>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/python/">python</a><a class="post-meta__tags" href="/tags/crawler/">crawler</a></div><div class="post_share"><div class="social-share" data-image="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/8.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/12/09/My%20projects/"><img class="prev-cover" src="https://github.com/serika-onoe/web-img/raw/main/Experience/uav3(1).png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">My Projects</div></div></a></div><div class="next-post pull-right"><a href="/2020/09/06/In-game%20Card%20Draw%20Mechanism%20Summary/"><img class="next-cover" src="https://github.com/serika-onoe/web-img/raw/main/game/card.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">In-game Card Draw Mechanism Summary</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Richard KUNG</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">9</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/serika-onoe" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:zgong313@connect.hkust-gz.edu.cn" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Best wishes for the New Year！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#develop-web-crawling-in-a-national-statistic-institute"><span class="toc-number">1.</span> <span class="toc-text">Develop
Web Crawling in A National Statistic Institute</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#crawler-basic-process"><span class="toc-number">1.1.</span> <span class="toc-text">1. Crawler basic process</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#open-the-web-page-and-analyze"><span class="toc-number">1.2.</span> <span class="toc-text">2. Open the web page and
analyze</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#full-code-and-parsing"><span class="toc-number">1.3.</span> <span class="toc-text">3. Full code and parsing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#partial-code-description"><span class="toc-number">1.4.</span> <span class="toc-text">4. Partial code description</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#data-extraction"><span class="toc-number">1.4.1.</span> <span class="toc-text">data extraction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#request-website"><span class="toc-number">1.4.2.</span> <span class="toc-text">Request website</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#save-data-to-excel-sheet"><span class="toc-number">1.5.</span> <span class="toc-text">5. Save data to excel sheet</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#table-optimization-optional"><span class="toc-number">1.6.</span> <span class="toc-text">6. Table optimization
(optional)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#references"><span class="toc-number">1.7.</span> <span class="toc-text">7. References</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/12/20/CS231n-Assignment-1/" title="CS231n Assignment 1 (Updating)"><img src="https://github.com/serika-onoe/web-img/raw/main/CS231N/Assignment1/cs231n_assignment1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CS231n Assignment 1 (Updating)"/></a><div class="content"><a class="title" href="/2022/12/20/CS231n-Assignment-1/" title="CS231n Assignment 1 (Updating)">CS231n Assignment 1 (Updating)</a><time datetime="2022-12-20T14:49:13.000Z" title="Created 2022-12-20 22:49:13">2022-12-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/14/Transformer%E6%A8%A1%E5%9E%8B%E5%88%9D%E6%8E%A2/" title="Transformer模型初探"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Transformer模型初探"/></a><div class="content"><a class="title" href="/2022/12/14/Transformer%E6%A8%A1%E5%9E%8B%E5%88%9D%E6%8E%A2/" title="Transformer模型初探">Transformer模型初探</a><time datetime="2022-12-14T01:42:13.000Z" title="Created 2022-12-14 09:42:13">2022-12-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/14/Transformer%20Tutorial%20for%20Beginners%20A%20Comprehensive%20Guide/" title="No title"><img src="https://github.com/serika-onoe/web-img/raw/main/Transformer/attention.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="No title"/></a><div class="content"><a class="title" href="/2022/12/14/Transformer%20Tutorial%20for%20Beginners%20A%20Comprehensive%20Guide/" title="No title">No title</a><time datetime="2022-12-14T01:42:13.000Z" title="Created 2022-12-14 09:42:13">2022-12-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/14/1-4/" title="No title"><img src="https://github.com/serika-onoe/web-img/raw/main/Transformer/attention.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="No title"/></a><div class="content"><a class="title" href="/2022/12/14/1-4/" title="No title">No title</a><time datetime="2022-12-14T01:42:13.000Z" title="Created 2022-12-14 09:42:13">2022-12-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/12/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%9D%E6%8E%A2/" title="强化学习初探"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="强化学习初探"/></a><div class="content"><a class="title" href="/2022/12/12/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%88%9D%E6%8E%A2/" title="强化学习初探">强化学习初探</a><time datetime="2022-12-12T15:17:01.000Z" title="Created 2022-12-12 23:17:01">2022-12-12</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Richard KUNG</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="Switch Between Traditional Chinese And Simplified Chinese">繁</button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="algolia-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="search-wrap"><div id="algolia-search-input"></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-info"><div class="algolia-stats"></div><div class="algolia-poweredBy"></div></div></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/algoliasearch/dist/algoliasearch-lite.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instantsearch.js/dist/instantsearch.production.min.js"></script><script src="/js/search/algolia.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://rbmbrain.me/',
      region: 'ap-east-1',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://rbmbrain.me/',
      region: 'ap-east-1',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      countELement.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script defer src="https://cdn.jsdelivr.net/gh/CodeByZach/pace/pace.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>