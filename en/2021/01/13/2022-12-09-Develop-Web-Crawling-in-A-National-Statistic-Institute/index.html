<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Develop Web Crawling in A National Statistic Institute | Kung's Blog</title><meta name="author" content="Richard Kung"><meta name="copyright" content="Richard Kung"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Develop Web Crawling in A National Statistic Institute**  This experiment is to crawl the home page of “National Bureau of Statistics“ for the example of [Shanghai urban and rural residents income and">
<meta property="og:type" content="article">
<meta property="og:title" content="Develop Web Crawling in A National Statistic Institute">
<meta property="og:url" content="https://serika-onoe.github.io/en/2021/01/13/2022-12-09-Develop-Web-Crawling-in-A-National-Statistic-Institute/index.html">
<meta property="og:site_name" content="Kung&#39;s Blog">
<meta property="og:description" content="Develop Web Crawling in A National Statistic Institute**  This experiment is to crawl the home page of “National Bureau of Statistics“ for the example of [Shanghai urban and rural residents income and">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/8.jpg">
<meta property="article:published_time" content="2021-01-12T16:12:47.000Z">
<meta property="article:modified_time" content="2022-12-12T14:38:42.128Z">
<meta property="article:author" content="Richard Kung">
<meta property="article:tag" content="python">
<meta property="article:tag" content="crawler">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/8.jpg"><link rel="shortcut icon" href="/en/img/favicon.png"><link rel="canonical" href="https://serika-onoe.github.io/en/2021/01/13/2022-12-09-Develop-Web-Crawling-in-A-National-Statistic-Institute/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta/><link rel="stylesheet" href="/en/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/en/',
  algolia: {"appId":"W5J7GO3HT8","apiKey":"53b7d5d068605c78d1a20d7f3671629a","indexName":"test_serika","hits":{"per_page":3},"languages":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}.","hits_stats":"${hits} results found in ${time} ms"}},
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Develop Web Crawling in A National Statistic Institute',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-12-12 22:38:42'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/CodeByZach/pace/themes/green/pace-theme-flash.css"><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/en/atom.xml" title="Kung's Blog" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/en/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/en/archives/"><div class="headline">Articles</div><div class="length-num">4</div></a><a href="/en/tags/"><div class="headline">Tags</div><div class="length-num">9</div></a><a href="/en/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/en/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/en/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/en/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/en/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/en/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/en/../"><span> 中文</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://github.com/serika-onoe/web-img/raw/main/Python_crawler/8.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/en/">Kung's Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/en/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/en/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/en/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/en/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/en/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/en/../"><span> 中文</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Develop Web Crawling in A National Statistic Institute</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2021-01-12T16:12:47.000Z" title="Created 2021-01-13 00:12:47">2021-01-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-12-12T14:38:42.128Z" title="Updated 2022-12-12 22:38:42">2022-12-12</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/en/categories/project/">project</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Develop Web Crawling in A National Statistic Institute"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Develop-Web-Crawling-in-A-National-Statistic-Institute"><a href="#Develop-Web-Crawling-in-A-National-Statistic-Institute" class="headerlink" title="Develop Web Crawling in A National Statistic Institute"></a>Develop Web Crawling in A National Statistic Institute</h1><p>**  This experiment is to crawl the home page of “<a target="_blank" rel="noopener" href="https://data.stats.gov.cn/index.htm">National Bureau of Statistics</a>“ for the example of [Shanghai urban and rural residents income and expenditure basic information], other pages of the National Bureau of Statistics crawl in a similar way ** </p>
<h2 id="1-Crawler-basic-process"><a href="#1-Crawler-basic-process" class="headerlink" title="1. Crawler basic process"></a>1. Crawler basic process</h2><ol>
<li>initiate a request: launch a request to the target site through the http&#x2F;https library, that is, send a request, the request can contain additional information such as headers, waiting for the server to respond</li>
<li>get the corresponding content: if the server can respond normally, it will get a response, the content of the response is the content of the page to be obtained, the type may be HTML, json string, binary data (such as pictures and videos) and other types</li>
<li>parsing content: the content may be HTML, you can use regular expressions, web parsing library to parse, may be json, can be directly converted to json objects, may be binary data, you can do to save or further processing<br>** (The parsed content of this experiment is json)** </li>
<li>save data: can be saved as text, can also be saved to the database, or a specific format file</li>
</ol>
<h2 id="2-Open-the-web-page-and-analyze"><a href="#2-Open-the-web-page-and-analyze" class="headerlink" title="2. Open the web page and analyze"></a>2. Open the web page and analyze</h2><p>The website of the National Bureau of Statistics is very strange, it is obviously https but it warns of insecurity, the first time the interface is opened as follows (I use Google Chrome)</p>
<p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/1.jpg"></p>
<p>Click on “Advanced” - “Continue to” to enter the home page</p>
<p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/2.jpg"></p>
<p>Select “Quarterly Data” - “Quarterly Data by Province”</p>
<p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/3.jpg"></p>
<p>Select “People’s Life” - “Urban and Rural Income and Expenditure”</p>
<p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/4.jpg"></p>
<p>Change the region to “Shanghai”</p>
<p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/5.jpg"></p>
<p>Press F12 to enter browser debugging mode</p>
<p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/6.jpg"></p>
<p>Refresh and re-fetch the page information, find easyquery.htm?m&#x3D;Query Data&amp;dbc… file. You can check the “XHR” filter first to narrow the search</p>
<p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/7.jpg"></p>
<p>How can we make sure that this file contains the data we are looking for? By clicking on the “response” panel and dragging the slider to the right, you can see that the table data corresponds to each other (but the data does not appear consecutively)</p>
<p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/8.jpg"></p>
<p>** Note: here data and strdata look the same, but the actual format is not the same, data is int or double format, strdata is str format, this table has some empty data lines, string format is convenient to do judgment, string to digital use eval () ** </p>
<h2 id="3-Full-code-and-parsing"><a href="#3-Full-code-and-parsing" class="headerlink" title="3. Full code and parsing"></a>3. Full code and parsing</h2><p>** Note: the missing libraries can be installed at the command line using the pip command, such as the lack of requests library, you can enter the command at the command line ** </p>
<p>&#96;&#96;&#96;pip install requests&#96;&#96;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib3 </span><br><span class="line"></span><br><span class="line"><span class="comment"># use urllib3.disable_warnings() with SSL authentication turned off (verify=False)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Disable secure request warnings for requests</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests <span class="comment"># Use Requests to send network requests</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time <span class="comment"># used to get timestamp (calculate current time for web validation)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json <span class="comment"># Process json files</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># Process arrays</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># np.array() to pd.DataFrame format, then use to_excel() to write to excel tables</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get millisecond timestamp for web validation</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getTime</span>():</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">int</span>(<span class="built_in">round</span>(time.time() * <span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># data preprocessing, get the srdata elements (data) wrapped in layers in a json list</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getList</span>(<span class="params">length</span>):</span><br><span class="line"></span><br><span class="line">  <span class="type">List</span>=[]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(length):</span><br><span class="line"></span><br><span class="line">temp = js[<span class="string">&#x27;returndata&#x27;</span>][<span class="string">&#x27;datanodes&#x27;</span>][i][<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;strdata&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># urban and rural residents income and expenditure list, the original site has a year-on-year growth data is empty, if you directly use eval() will report an error, you need to determine first</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(<span class="built_in">len</span>(temp)! =<span class="number">0</span>):</span><br><span class="line"></span><br><span class="line"><span class="comment"># eval() number to string</span></span><br><span class="line"></span><br><span class="line"><span class="type">List</span>.append(<span class="built_in">eval</span>(temp))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="type">List</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">  <span class="comment"># request target URL (link? preceded by something)</span></span><br><span class="line"></span><br><span class="line">  url=<span class="string">&#x27;https://data.stats.gov.cn/easyquery.htm&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># request headers, User-Agent: used to prove you are a browser, just meet a certain format, not necessarily the same as your own browser</span></span><br><span class="line"></span><br><span class="line">  headers=&#123;<span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0(Windows;U;Windows NT6.1;en-US;rv:1.9.1.6) Geko/20091201 Firefox/3.5.6&#x27;</span>&#125;<span class="comment"># browser agent</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Construct parameter key-value pairs, with specific values obtained from the page structure parameters</span></span><br><span class="line"></span><br><span class="line">  key=&#123;&#125;</span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;m&#x27;</span>]=<span class="string">&#x27;QueryData&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;dbcode&#x27;</span>]=<span class="string">&#x27;fsjd&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;rowcode&#x27;</span>]=<span class="string">&#x27;zb&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;colcode&#x27;</span>]=<span class="string">&#x27;sj&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;wds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;: &quot;reg&quot;, &quot;valuecode&quot;: &quot;310000&quot;&#125;]&#x27;</span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;k1&#x27;</span>]=<span class="built_in">str</span>(getTime()) </span><br><span class="line"></span><br><span class="line">  <span class="comment"># &quot;wdcode&quot;: &quot;reg&quot; region field</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Shanghai 310000 </span></span><br><span class="line"></span><br><span class="line">  key[<span class="string">&#x27;dfwds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;: &quot;zb&quot;, &quot;valuecode&quot;: &quot;A0300&quot;&#125;,&#123;&quot;wdcode&quot;: &quot;sj&quot;, &quot;valuecode&quot;: &quot;LAST6&quot;&#125;]&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># &quot;wdcode&quot;: &quot;zb&quot; select which entry on the left, &quot;wdcode&quot;: &quot;sj&quot; option box select &quot;LAST 6 QUARTERS&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Disable security request warnings</span></span><br><span class="line"></span><br><span class="line">  requests.packages.urllib3.disable_warnings()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Send the request, using the post method, here using the previous custom header and parameters</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># ! verify=False, the NSO switched to https protocol in the second half of 20 years, if not add the code can not pass SSL verification</span></span><br><span class="line"></span><br><span class="line">  r = requests.post(url, headers=headers, params=key,verify=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Use the json library loads function to parse the r.text string into a dict dictionary format and store it in js</span></span><br><span class="line"></span><br><span class="line">  js = json.loads(r.text)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># get the required data of a one-dimensional array, using np.array().reshape() to organize into two-dimensional arrays</span></span><br><span class="line"></span><br><span class="line">  length=<span class="built_in">len</span>(js[<span class="string">&#x27;returndata&#x27;</span>][<span class="string">&#x27;datanodes&#x27;</span>])</span><br><span class="line"></span><br><span class="line">  res=getList(length)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Total data divided into 6 rows of format</span></span><br><span class="line"></span><br><span class="line">  array=np.array(res).reshape(<span class="built_in">len</span>(res)//<span class="number">6</span>,<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># np.array() is converted to pd.DataFrame format, the subsequent can use to_excel() to write directly to excel tables</span></span><br><span class="line"></span><br><span class="line">  df_shanghai=pd.DataFrame(array)</span><br><span class="line"></span><br><span class="line">  df_shanghai.columns=[<span class="string">&#x27;2020 Q3&#x27;</span>,<span class="string">&#x27;2020 Q2&#x27;</span>,<span class="string">&#x27;2020 Q1&#x27;</span>,<span class="string">&#x27;2019 Q4&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;2019 third quarter&#x27;</span>,<span class="string">&#x27;2019 second quarter&#x27;</span>]</span><br><span class="line"></span><br><span class="line">  df_shanghai.index=[<span class="string">&#x27;Cumulative value of per capita disposable income of residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita disposable income of urban residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita disposable income of rural residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita consumption expenditure of residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita consumption expenditure of urban residents (yuan)&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;Cumulative value of per capita consumption expenditure of rural residents (yuan)&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="built_in">print</span>(df_shanghai)</span><br></pre></td></tr></table></figure>

<p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/9.jpg"></p>
<h2 id="4-Partial-code-description"><a href="#4-Partial-code-description" class="headerlink" title="4. Partial code description"></a>4. Partial code description</h2><h3 id="data-extraction"><a href="#data-extraction" class="headerlink" title="data extraction"></a>data extraction</h3><p>Getting the data in the table requires first analyzing the extracted js file, which prints the following.</p>
<p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/10.jpg"></p>
<p>Strip the five layers of the list layer by layer to get the required srdata</p>
<p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/11.jpg"></p>
<h3 id="Request-website"><a href="#Request-website" class="headerlink" title="Request website"></a>Request website</h3><p>Request target URL (‘’?’’ preceded by something)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">url=<span class="string">&#x27;https://data.stats.gov.cn/easyquery.htm&#x27;</span></span><br></pre></td></tr></table></figure>

<p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/12.jpg"></p>
<p>Request header, User-Agent: used to prove that you are a browser, just meet a certain format, not necessarily the same as your own browser</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">headers=&#123;<span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0(Windows;U;Windows NT6.1;en-US;rv:1.9.1.6) Geko/20091201 Firefox/3.5.6&#x27;</span>&#125;<span class="comment">#browser agent</span></span><br></pre></td></tr></table></figure>

<p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/13.jpg"></p>
<p>Construct the parameter key-value pairs, the following parameters will be concatenated with &amp; and placed in the ‘’?’’ of the link followed by</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">key=&#123;&#125;</span><br><span class="line">key[<span class="string">&#x27;m&#x27;</span>]=<span class="string">&#x27;QueryData&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;dbcode&#x27;</span>]=<span class="string">&#x27;fsjd&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;rowcode&#x27;</span>]=<span class="string">&#x27;zb&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;colcode&#x27;</span>]=<span class="string">&#x27;sj&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;wds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;: &quot;reg&quot;, &quot;valuecode&quot;: &quot;310000&quot;&#125;]&#x27;</span></span><br><span class="line">key[<span class="string">&#x27;k1&#x27;</span>]=<span class="built_in">str</span>(getTime())  </span><br><span class="line">key[<span class="string">&#x27;dfwds&#x27;</span>]=<span class="string">&#x27;[&#123;&quot;wdcode&quot;: &quot;zb&quot;, &quot;valuecode&quot;: &quot;A0300&quot;&#125;,&#123;&quot;wdcode&quot;: &quot;sj&quot;, &quot;valuecode&quot;: &quot;LAST6&quot;&#125;]&#x27;</span></span><br></pre></td></tr></table></figure>

<p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/14.jpg"></p>
<p>Some of the parameters can be seen in the position shown below, some of them are not shown by default, if you need to show the same page, you need to select the corresponding option in the option box</p>
<p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/15.jpg"></p>
<h2 id="5-Save-data-to-excel-sheet"><a href="#5-Save-data-to-excel-sheet" class="headerlink" title="5. Save data to excel sheet"></a>5. Save data to excel sheet</h2><p>The data crawled by the crawler is now stored in panda.dataframe format, and can be saved directly in an excel table using the to_excel() function</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># write object for this Excel workbook, use this method to save multiple worksheets</span></span><br><span class="line">    write = pd.ExcelWriter(<span class="string">&#x27;F:/Ivory_Tower/norm/provincial quarterly data_urban and rural residents income and expenditure.xls&#x27;</span>) <span class="comment"># The path can be set by yourself, there is no such file will create one on its own, if it exists, write will overwrite the original content</span></span><br><span class="line">    df_shanghai.to_excel(write,sheet_name=<span class="string">&#x27;Shanghai&#x27;</span>)</span><br><span class="line">    <span class="comment"># If you climb multiple provinces, you can write to multiple worksheets and must add save() to save the data</span></span><br><span class="line">    write.save()</span><br></pre></td></tr></table></figure>

<p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/16.jpg"></p>
<h2 id="6-Table-optimization-optional"><a href="#6-Table-optimization-optional" class="headerlink" title="6. Table optimization (optional)"></a>6. Table optimization (optional)</h2><p>You can optimize the table format with the help of python code, as shown above the results are not satisfactory, at least the need to automatically adjust the column width.</p>
<p>Here I use xlwings library, you need to first download the corresponding library in the command line</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install xlwings</span><br><span class="line">pip install pywin32</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Use the xlwings library to edit and organize Excel tables with python</span></span><br><span class="line"><span class="keyword">import</span> xlwings <span class="keyword">as</span> xw</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app=xw.App(visible=<span class="literal">False</span>,add_book=<span class="literal">False</span>) <span class="comment"># process is not visible, no new worksheet is added</span></span><br><span class="line">    wb=app.books.<span class="built_in">open</span>(<span class="string">r&#x27;F:/Ivory_Tower/norm/province_quarterly_income_and_expense_of_urban_rural_residents.xls&#x27;</span>)</span><br><span class="line">    <span class="comment"># wb is the new workbook (workbook)</span></span><br><span class="line">    <span class="comment"># For each of the 8 worksheets, do the following</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>): </span><br><span class="line">        rng=wb.sheets[i].<span class="built_in">range</span>(<span class="string">&#x27;A1:H20&#x27;</span>) <span class="comment"># select these cells</span></span><br><span class="line">        rng.api.HorizontalAlignment = -<span class="number">4108</span> <span class="comment"># center the text horizontally</span></span><br><span class="line">        rng.autofit() <span class="comment"># automatically adjust the row height and column width</span></span><br><span class="line">    wb.save()</span><br><span class="line">    wb.close()</span><br><span class="line">    app.quit()</span><br></pre></td></tr></table></figure>

<p>Run the code, you can get the following effect (subsequently crawled some other provinces, modify the corresponding parameters at the key can be)</p>
<p><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/17.jpg"></p>
<h2 id="7-References"><a href="#7-References" class="headerlink" title="7. References"></a>7. References</h2><p>The history of super detailed python crawl the National Bureau of Statistics data: <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41988893/article/details/103017854">https://blog.csdn.net/qq_41988893/article/details/103017854</a></p>
<p>If you report a variety of other inexplicable errors, you can comment or private letter to ask ~</p>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/en/tags/python/">python</a><a class="post-meta__tags" href="/en/tags/crawler/">crawler</a></div><div class="post_share"><div class="social-share" data-image="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/8.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/en/2022/12/09/2022-12-09-My-projects/"><img class="prev-cover" src="https://github.com/serika-onoe/web-img/raw/main/Experience/uav3(1).png" onerror="onerror=null;src='/en/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">My Projects</div></div></a></div><div class="next-post pull-right"><a href="/en/2020/09/06/2022-12-09-In-game-Card-Draw-Mechanism-Summary/"><img class="next-cover" src="https://github.com/serika-onoe/web-img/raw/main/game/card.jpg" onerror="onerror=null;src='/en/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">In-game Card Draw Mechanism Summary</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div><div id="comment-switch"><span class="first-comment">Valine</span><span class="switch-btn"></span><span class="second-comment">Disqus</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/en/img/avatar.jpg" onerror="this.onerror=null;this.src='/en/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Richard Kung</div><div class="author-info__description">Writing is for better thinking.</div></div><div class="card-info-data site-data is-center"><a href="/en/archives/"><div class="headline">Articles</div><div class="length-num">4</div></a><a href="/en/tags/"><div class="headline">Tags</div><div class="length-num">9</div></a><a href="/en/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/serika-onoe" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:zgong313@connect.hkust-gz.edu.cn" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Develop-Web-Crawling-in-A-National-Statistic-Institute"><span class="toc-number">1.</span> <span class="toc-text">Develop Web Crawling in A National Statistic Institute</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Crawler-basic-process"><span class="toc-number">1.1.</span> <span class="toc-text">1. Crawler basic process</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Open-the-web-page-and-analyze"><span class="toc-number">1.2.</span> <span class="toc-text">2. Open the web page and analyze</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Full-code-and-parsing"><span class="toc-number">1.3.</span> <span class="toc-text">3. Full code and parsing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Partial-code-description"><span class="toc-number">1.4.</span> <span class="toc-text">4. Partial code description</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#data-extraction"><span class="toc-number">1.4.1.</span> <span class="toc-text">data extraction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Request-website"><span class="toc-number">1.4.2.</span> <span class="toc-text">Request website</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Save-data-to-excel-sheet"><span class="toc-number">1.5.</span> <span class="toc-text">5. Save data to excel sheet</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Table-optimization-optional"><span class="toc-number">1.6.</span> <span class="toc-text">6. Table optimization (optional)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-References"><span class="toc-number">1.7.</span> <span class="toc-text">7. References</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/en/2022/12/09/2022-12-09-My-projects/" title="My Projects"><img src="https://github.com/serika-onoe/web-img/raw/main/Experience/uav3(1).png" onerror="this.onerror=null;this.src='/en/img/404.jpg'" alt="My Projects"/></a><div class="content"><a class="title" href="/en/2022/12/09/2022-12-09-My-projects/" title="My Projects">My Projects</a><time datetime="2022-12-09T03:10:23.000Z" title="Created 2022-12-09 11:10:23">2022-12-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/en/2021/01/13/2022-12-09-Develop-Web-Crawling-in-A-National-Statistic-Institute/" title="Develop Web Crawling in A National Statistic Institute"><img src="https://github.com/serika-onoe/web-img/raw/main/Python_crawler/8.jpg" onerror="this.onerror=null;this.src='/en/img/404.jpg'" alt="Develop Web Crawling in A National Statistic Institute"/></a><div class="content"><a class="title" href="/en/2021/01/13/2022-12-09-Develop-Web-Crawling-in-A-National-Statistic-Institute/" title="Develop Web Crawling in A National Statistic Institute">Develop Web Crawling in A National Statistic Institute</a><time datetime="2021-01-12T16:12:47.000Z" title="Created 2021-01-13 00:12:47">2021-01-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/en/2020/09/06/2022-12-09-In-game-Card-Draw-Mechanism-Summary/" title="In-game Card Draw Mechanism Summary"><img src="https://github.com/serika-onoe/web-img/raw/main/game/card.jpg" onerror="this.onerror=null;this.src='/en/img/404.jpg'" alt="In-game Card Draw Mechanism Summary"/></a><div class="content"><a class="title" href="/en/2020/09/06/2022-12-09-In-game-Card-Draw-Mechanism-Summary/" title="In-game Card Draw Mechanism Summary">In-game Card Draw Mechanism Summary</a><time datetime="2020-09-06T03:00:00.000Z" title="Created 2020-09-06 11:00:00">2020-09-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/en/2020/02/11/2022-12-10-My-first-blog/" title="My first blog"><img src="https://github.com/serika-onoe/web-img/raw/main/background/wuming.jpg" onerror="this.onerror=null;this.src='/en/img/404.jpg'" alt="My first blog"/></a><div class="content"><a class="title" href="/en/2020/02/11/2022-12-10-My-first-blog/" title="My first blog">My first blog</a><time datetime="2020-02-11T04:14:00.000Z" title="Created 2020-02-11 12:14:00">2020-02-11</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Richard Kung</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="algolia-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="search-wrap"><div id="algolia-search-input"></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-info"><div class="algolia-stats"></div><div class="algolia-poweredBy"></div></div></div></div></div><div id="search-mask"></div></div><div><script src="/en/js/utils.js"></script><script src="/en/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/algoliasearch/dist/algoliasearch-lite.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instantsearch.js/dist/instantsearch.production.min.js"></script><script src="/en/js/search/algolia.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '',
      appKey: '',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script>function loadDisqus () {
  var disqus_config = function () {
    this.page.url = 'https://serika-onoe.github.io/en/2021/01/13/2022-12-09-Develop-Web-Crawling-in-A-National-Statistic-Institute/'
    this.page.identifier = '/en/2021/01/13/2022-12-09-Develop-Web-Crawling-in-A-National-Statistic-Institute/'
    this.page.title = 'Develop Web Crawling in A National Statistic Institute'
  };

  window.disqusReset = () => {
    DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  if (window.DISQUS) disqusReset()
  else {
    (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  }

  document.getElementById('darkmode').addEventListener('click', () => {
    setTimeout(() => window.disqusReset(), 200)
  })
}

if ('Valine' === 'Disqus' || !true) {
  if (true) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
  else loadDisqus()
} else {
  function loadOtherComment () {
    loadDisqus()
  }
}
</script></div><script defer src="https://cdn.jsdelivr.net/gh/CodeByZach/pace/pace.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>